{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries to be used\n",
    "\n",
    "# Warning messages display\n",
    "## import warnings\n",
    "## warnings.filterwarnings(action='ignore') # https://docs.python.org/3/library/warnings.html#the-warnings-filter\n",
    "\n",
    "# Directories/Files management\n",
    "import os.path\n",
    "## from zipfile import ZipFile # De momento no ha hecho falta \n",
    "\n",
    "# Timing\n",
    "import time\n",
    "\n",
    "# Data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None) # Show all columns in DataFrames\n",
    "pd.set_option('display.max_rows', 100) # If too high, it greatly slows down the output display and freezes the kernel\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot') # choose a style: 'plt.style.available'\n",
    "sns.set_theme(context='notebook',\n",
    "              style=\"darkgrid\") # {darkgrid, whitegrid, dark, white, ticks}\n",
    "palette = sns.color_palette(\"flare\", as_cmap=True);\n",
    "import altair as alt\n",
    "\n",
    "# Machine Learning\n",
    "## from sklearn.[...] import ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Windows.\n",
      "root path\t C:\\Users\\turge\\CompartidoVM\\0.TFM\n"
     ]
    }
   ],
   "source": [
    "# Detect Operating System running and manage paths accordingly\n",
    "\n",
    "if os.name == 'nt': # Windows\n",
    "    root = r\"C:\\Users\\turge\\CompartidoVM\\0.TFM\"\n",
    "    print(\"Running on Windows.\")\n",
    "elif os.name == 'posix': # Ubuntu\n",
    "    root = \"/home/dsc/shared/0.TFM\"\n",
    "    print(\"Running on Ubuntu.\")\n",
    "print(\"root path\\t\", root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \n",
    "### -----  < X > (PRE-FLIGHT DATA) -----\n",
    "\n",
    "# Time Period\n",
    "#  'YEAR', # Disregarded: for the time being, analysis limted to 2019\n",
    "#  'QUARTER', # Disregarded: redundant\n",
    " 'MONTH',\n",
    " 'DAY_OF_MONTH',\n",
    " 'DAY_OF_WEEK',\n",
    "#  'FL_DATE', # Disregarded: redundant\n",
    "# Airline / Aircraft\n",
    " 'OP_UNIQUE_CARRIER',\n",
    "#  'OP_CARRIER_AIRLINE_ID', # Disregarded: redundant\n",
    "#  'OP_CARRIER', # Disregarded: redundant\n",
    " 'TAIL_NUM',\n",
    "#  'OP_CARRIER_FL_NUM', # Unknown in advance?\n",
    "# Origin\n",
    "#  'ORIGIN_AIRPORT_ID', # Disregarded: redundant\n",
    "#  'ORIGIN_AIRPORT_SEQ_ID', # Disregarded: redundant\n",
    " 'ORIGIN_CITY_MARKET_ID',\n",
    " 'ORIGIN',\n",
    "#  'ORIGIN_CITY_NAME', # Disregarded: redundant\n",
    "#  'ORIGIN_STATE_ABR', # Disregarded: redundant\n",
    "#  'ORIGIN_STATE_FIPS', # Federal Information Processing Standards # Not used for the moment\n",
    "#  'ORIGIN_STATE_NM', # Disregarded: redundant\n",
    "#  'ORIGIN_WAC', # World Area Code # Not used for the moment\n",
    "# Destination\n",
    "#  'DEST_AIRPORT_ID', # Disregarded: redundant\n",
    "#  'DEST_AIRPORT_SEQ_ID', # Disregarded: redundant\n",
    " 'DEST_CITY_MARKET_ID',\n",
    " 'DEST',\n",
    "#  'DEST_CITY_NAME', # Disregarded: redundant\n",
    "#  'DEST_STATE_ABR', # Disregarded: redundant\n",
    "#  'DEST_STATE_FIPS', # Federal Information Processing Standards # Not used for the moment\n",
    "#  'DEST_STATE_NM', # Disregarded: redundant\n",
    "#  'DEST_WAC', # World Area Code # Not used for the moment\n",
    "# Departure Performance\n",
    " 'CRS_DEP_TIME',\n",
    "#  'TAXI_OUT_median', #  Output / However, the median for each airport could be used as input !! (explanation below)   \n",
    "# Arrival Performance\n",
    " 'CRS_ARR_TIME',\n",
    "#  'TAXI_IN_median', #  Output / However, the median for each airport could be used as input !! (explanation below) \n",
    "# Flight Summaries\n",
    " 'CRS_ELAPSED_TIME',\n",
    " 'FLIGHTS',\n",
    " 'DISTANCE',\n",
    " 'DISTANCE_GROUP',\n",
    "\n",
    "### ----- < y > (PRE-FLIGHT DATA) -----\n",
    "\n",
    "# Departure Performance\n",
    "#  'DEP_TIME', # Disregarded: redundant\n",
    "#  'DEP_DELAY', # Disregarded: other potentially useful target\n",
    "#  'DEP_DELAY_NEW', # Disregarded: redundant\n",
    "#  'DEP_DEL15', # Disregarded: other potentially useful target\n",
    "#  'DEP_DELAY_GROUP', # Disregarded: not relevant for this particular analysis\n",
    "#  'DEP_TIME_BLK', # Disregarded: redundant\n",
    "#  'TAXI_OUT', #  Output / However, the median for each airport could be used as input !! (explanation below)\n",
    "#  'WHEELS_OFF', # Disregarded: redundant\n",
    "# Arrival Performance\n",
    "#  'WHEELS_ON', # Disregarded: redundant\n",
    "#  'TAXI_IN', #  Output / However, the median for each airport could be used as input !! (explanation below)\n",
    "#  'ARR_TIME', # Disregarded: redundant\n",
    "#  'ARR_DELAY', # -------------------------------------------> MAIN TARGET !! (i.e. < y >)\n",
    "#  'ARR_DELAY_NEW', # Disregarded: redundant\n",
    " 'ARR_DEL15', # Disregarded: other potentially useful target\n",
    "#  'ARR_DELAY_GROUP', # Disregarded: not relevant for this particular analysis\n",
    "#  'ARR_TIME_BLK', # Disregarded: redundant\n",
    "# Cancellations and Diversions\n",
    "#  'CANCELLED', # Disregarded: not relevant for this particular analysis\n",
    "#  'CANCELLATION_CODE', # Disregarded: not relevant for this particular analysis\n",
    "#  'DIVERTED', # Disregarded: not relevant for this particular analysis\n",
    "# Flight Summaries\n",
    "#  'ACTUAL_ELAPSED_TIME', # Disregarded: redundant\n",
    "#  'AIR_TIME', # Disregarded: redundant\n",
    "# Cause of Delay\n",
    "#  'CARRIER_DELAY', # Disregarded: other potentially useful target\n",
    "#  'WEATHER_DELAY', # Disregarded: other potentially useful target\n",
    "#  'NAS_DELAY', # Disregarded: other potentially useful target\n",
    "#  'SECURITY_DELAY', # Disregarded: other potentially useful target\n",
    "#  'LATE_AIRCRAFT_DELAY', # Disregarded: other potentially useful target\n",
    "# Gate Return Information at Origin Airport (Data starts 10/2008)\n",
    "#  'FIRST_DEP_TIME', # Disregarded: not relevant for this particular analysis\n",
    "#  'TOTAL_ADD_GTIME', # Disregarded: not relevant for this particular analysis\n",
    "#  'LONGEST_ADD_GTIME', # Disregarded: not relevant for this particular analysis\n",
    "# Diverted Airport Information (Data starts 10/2008)\n",
    "#  'DIV_AIRPORT_LANDINGS', # Disregarded: not relevant for this particular analysis\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MONTH',\n",
       " 'DAY_OF_MONTH',\n",
       " 'DAY_OF_WEEK',\n",
       " 'OP_UNIQUE_CARRIER',\n",
       " 'TAIL_NUM',\n",
       " 'ORIGIN_CITY_MARKET_ID',\n",
       " 'ORIGIN',\n",
       " 'DEST_CITY_MARKET_ID',\n",
       " 'DEST',\n",
       " 'CRS_DEP_TIME',\n",
       " 'CRS_ARR_TIME',\n",
       " 'CRS_ELAPSED_TIME',\n",
       " 'FLIGHTS',\n",
       " 'DISTANCE',\n",
       " 'DISTANCE_GROUP',\n",
       " 'ARR_DEL15']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\turge\\\\CompartidoVM\\\\0.TFM\\\\Output_Data\\\\US_DoT\\\\AL_OTP_MVP_Preprocessed_19_v2_clean.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_input_csv_path = os.path.join(root,\n",
    "                                           \"Output_Data\",\n",
    "                                           \"US_DoT\",\n",
    "                                           \"AL_OTP_MVP_Preprocessed_19_v2_clean.csv\")\n",
    "preprocessed_input_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv(preprocessed_input_csv_path,\n",
    "                 encoding='latin1',\n",
    "#                  nrows=1e4,\n",
    "                 usecols=cols, # This way, the extra column is disregarded for the loading process\n",
    "                 low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7268232, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(int(1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>ORIGIN_CITY_MARKET_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST_CITY_MARKET_ID</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_DEL15</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>FLIGHTS</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5456320</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>UA</td>\n",
       "      <td>N66828</td>\n",
       "      <td>31703</td>\n",
       "      <td>EWR</td>\n",
       "      <td>32467</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1955</td>\n",
       "      <td>2257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582185</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>WN</td>\n",
       "      <td>N562WN</td>\n",
       "      <td>32457</td>\n",
       "      <td>SJC</td>\n",
       "      <td>32575</td>\n",
       "      <td>BUR</td>\n",
       "      <td>1915</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846651</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>OO</td>\n",
       "      <td>N194SY</td>\n",
       "      <td>32457</td>\n",
       "      <td>SJC</td>\n",
       "      <td>30713</td>\n",
       "      <td>BOI</td>\n",
       "      <td>1925</td>\n",
       "      <td>2215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018750</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>N932WN</td>\n",
       "      <td>30140</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>33198</td>\n",
       "      <td>MCI</td>\n",
       "      <td>1650</td>\n",
       "      <td>1935</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536298</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>DL</td>\n",
       "      <td>N972DL</td>\n",
       "      <td>30928</td>\n",
       "      <td>ICT</td>\n",
       "      <td>30397</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1400</td>\n",
       "      <td>1708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954182</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>OO</td>\n",
       "      <td>N938SW</td>\n",
       "      <td>34236</td>\n",
       "      <td>SBP</td>\n",
       "      <td>32457</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1615</td>\n",
       "      <td>1728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135856</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>UA</td>\n",
       "      <td>N814UA</td>\n",
       "      <td>33214</td>\n",
       "      <td>SAT</td>\n",
       "      <td>30852</td>\n",
       "      <td>IAD</td>\n",
       "      <td>1708</td>\n",
       "      <td>2111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306672</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>B6</td>\n",
       "      <td>N584JB</td>\n",
       "      <td>30559</td>\n",
       "      <td>SEA</td>\n",
       "      <td>32575</td>\n",
       "      <td>LGB</td>\n",
       "      <td>600</td>\n",
       "      <td>837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>965.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991496</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>EV</td>\n",
       "      <td>N14570</td>\n",
       "      <td>32884</td>\n",
       "      <td>LAN</td>\n",
       "      <td>30977</td>\n",
       "      <td>ORD</td>\n",
       "      <td>645</td>\n",
       "      <td>703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6348081</th>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>B6</td>\n",
       "      <td>N663JB</td>\n",
       "      <td>34819</td>\n",
       "      <td>SJU</td>\n",
       "      <td>32467</td>\n",
       "      <td>FLL</td>\n",
       "      <td>1930</td>\n",
       "      <td>2112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MONTH  DAY_OF_MONTH  DAY_OF_WEEK OP_UNIQUE_CARRIER TAIL_NUM  \\\n",
       "5456320     10            11            5                UA   N66828   \n",
       "582185       2            18            1                WN   N562WN   \n",
       "5846651     10             6            7                OO   N194SY   \n",
       "2018750      4            18            4                WN   N932WN   \n",
       "1536298      3             2            6                DL   N972DL   \n",
       "...        ...           ...          ...               ...      ...   \n",
       "2954182      6             1            6                OO   N938SW   \n",
       "6135856     11             4            1                UA   N814UA   \n",
       "306672       1            13            7                B6   N584JB   \n",
       "991496       2            17            7                EV   N14570   \n",
       "6348081     11            25            1                B6   N663JB   \n",
       "\n",
       "         ORIGIN_CITY_MARKET_ID ORIGIN  DEST_CITY_MARKET_ID DEST  CRS_DEP_TIME  \\\n",
       "5456320                  31703    EWR                32467  MIA          1955   \n",
       "582185                   32457    SJC                32575  BUR          1915   \n",
       "5846651                  32457    SJC                30713  BOI          1925   \n",
       "2018750                  30140    ABQ                33198  MCI          1650   \n",
       "1536298                  30928    ICT                30397  ATL          1400   \n",
       "...                        ...    ...                  ...  ...           ...   \n",
       "2954182                  34236    SBP                32457  SFO          1615   \n",
       "6135856                  33214    SAT                30852  IAD          1708   \n",
       "306672                   30559    SEA                32575  LGB           600   \n",
       "991496                   32884    LAN                30977  ORD           645   \n",
       "6348081                  34819    SJU                32467  FLL          1930   \n",
       "\n",
       "         CRS_ARR_TIME  ARR_DEL15  CRS_ELAPSED_TIME  FLIGHTS  DISTANCE  \\\n",
       "5456320          2257        0.0             182.0      1.0    1085.0   \n",
       "582185           2025        0.0              70.0      1.0     296.0   \n",
       "5846651          2215        0.0             110.0      1.0     523.0   \n",
       "2018750          1935        1.0             105.0      1.0     718.0   \n",
       "1536298          1708        0.0             128.0      1.0     782.0   \n",
       "...               ...        ...               ...      ...       ...   \n",
       "2954182          1728        0.0              73.0      1.0     190.0   \n",
       "6135856          2111        0.0             183.0      1.0    1362.0   \n",
       "306672            837        0.0             157.0      1.0     965.0   \n",
       "991496            703        0.0              78.0      1.0     179.0   \n",
       "6348081          2112        0.0             162.0      1.0    1046.0   \n",
       "\n",
       "         DISTANCE_GROUP  \n",
       "5456320               5  \n",
       "582185                2  \n",
       "5846651               3  \n",
       "2018750               3  \n",
       "1536298               4  \n",
       "...                 ...  \n",
       "2954182               1  \n",
       "6135856               6  \n",
       "306672                4  \n",
       "991496                1  \n",
       "6348081               5  \n",
       "\n",
       "[1000 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MONTH                      int64\n",
       "DAY_OF_MONTH               int64\n",
       "DAY_OF_WEEK                int64\n",
       "OP_UNIQUE_CARRIER         object\n",
       "TAIL_NUM                  object\n",
       "ORIGIN_CITY_MARKET_ID      int64\n",
       "ORIGIN                    object\n",
       "DEST_CITY_MARKET_ID        int64\n",
       "DEST                      object\n",
       "CRS_DEP_TIME               int64\n",
       "CRS_ARR_TIME               int64\n",
       "ARR_DEL15                float64\n",
       "CRS_ELAPSED_TIME         float64\n",
       "FLIGHTS                  float64\n",
       "DISTANCE                 float64\n",
       "DISTANCE_GROUP             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dealing with categorical features with high cardinality: Target Encoding](https://medium.com/@kr.vishwesh54/dealing-with-categorical-features-with-high-cardinality-target-encoding-baa9298bf257)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 'TAXI_OUT' time is not an input, since there is no way to predict its actual value in advance\n",
    "# However, there is indeed some prior knowledge about it, based on past data concerning to operations on each airport.\n",
    "# Therefore, let's see whether some value could be used as a baseline for each airport and hence use it as an input feature.\n",
    "\n",
    "DepDel_TaxOutTim = df.groupby(['ORIGIN'])['TAXI_OUT', 'DEP_DELAY'].agg({'TAXI_OUT' : ['count', 'mean', 'median', 'min', 'max'],\n",
    "                                                                        'DEP_DELAY' : ['mean', 'median', 'min', 'max']})\n",
    "DepDel_TaxOutTim\n",
    "\n",
    "# Based on the results, it is observed that the median is commonly close to the mean.\n",
    "# In cases where this assumption is not satisfied, it is normally due to outliers.\n",
    "# These extreme values significantly move the means to the right.\n",
    "# Nevertheless, these outliers are almost always accompanied by high 'DEP_DELAY' values.\n",
    "\n",
    "# In a nutshell, it is fair to assume the each airport median as the baseline value for an input feature."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Similarly to what happens with 'TAXI_OUT', 'TAXI_IN' time is not an input, (unpredictable actual value in advance)\n",
    "# However, there is indeed some prior knowledge about it, based on past data concerning to operations on each airport.\n",
    "# Therefore, let's see whether some value could be used as a baseline for each airport and hence use it as an input feature.\n",
    "\n",
    "TaxInTim_ArrDel = df.groupby(['DEST'])['TAXI_IN', 'ARR_DELAY'].agg({'TAXI_IN' : ['count', 'mean', 'median', 'min', 'max'],\n",
    "                                                                    'ARR_DELAY' : ['mean', 'median', 'min', 'max']})\n",
    "TaxInTim_ArrDel\n",
    "\n",
    "# Based on the results, the same results as for 'TAXI_OUT': it is observed that the median is commonly close to the mean.\n",
    "# In cases where this assumption is not satisfied, it is normally due to outliers.\n",
    "# These extreme values significantly move the means to the right.\n",
    "# Nevertheless, these outliers are almost always accompanied by high 'ARR_DELAY' values.\n",
    "\n",
    "# In a nutshell, it is fair to assume the each airport median as the baseline value for an input feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('ARR_DEL15', axis=1)\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = df['ARR_DEL15']\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Guide to Scikit-learn Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the pipeline, let's split the data into a train and test set so that the performance of the model can be validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first step in building the pipeline is to define each transformer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, let's use the ColumnTransformer to apply the transformations to the correct columns in the dataframe. Before building this, the numeric and categorical columns shall be listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).drop(['ARR_DEL15'], axis=1).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a pipeline that combines the preprocessor created above with a classifier. In this case a simple RandomForestClassifier has been used to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(random_state=0))])\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A pipeline can also be used during the model selection process**. The following example code loops through a number of scikit-learn classifiers applying the transformations and training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss, f1_score, recall_score, precision_score, roc_auc_score, roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True, random_state=0),\n",
    "#     NuSVC(probability=True), # ValueError: b'specified nu is infeasible'\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    AdaBoostClassifier(random_state=0),\n",
    "    GradientBoostingClassifier(random_state=0)\n",
    "    ]\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', classifier)])\n",
    "    pipe.fit(X_train, y_train)   \n",
    "    print(classifier)\n",
    "    \n",
    "    # TEST !!!     \n",
    "    predictions = pipe.predict(X_test)\n",
    "    print(f1_score(y_test, predictions), recall_score(y_test, predictions), precision_score(y_test, predictions), accuracy_score(y_test, predictions))\n",
    "    \n",
    "    print(\"model score: %.3f \\n\" % pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The pipeline can also be used in grid search** to find the best performing parameters. To do this, let's first create a parameter grid for the chosen model.\n",
    "\n",
    "*One important thing to note is that there is a need to append the name given to the classifier part of the pipeline to each parameter name. In the code above its name is ‘classifier’ so 'classifier__' has been added to each parameter.*\n",
    "\n",
    "Next a grid search object has been created, which includes the original pipeline. When fit is called, the transformations are applied to the data, before a cross-validated grid-search is performed over the parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = { \n",
    "    'classifier__n_estimators': [200, 500],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__max_depth' : [4,5,6,7,8],\n",
    "    'classifier__criterion' :['gini', 'entropy']}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
    "# parameter setting that has the best cross-validated AUC score.\n",
    "# That estimator is made available at ``gs.best_estimator_`` along with\n",
    "# parameters like ``gs.best_score_``, ``gs.best_params_`` and\n",
    "# ``gs.best_index_``\n",
    "scoring = {'AUC': 'roc_auc', 'F1': 'f1', 'Precision': 'precision',\n",
    "           'Recall': 'recall', 'Accuracy': 'accuracy'}\n",
    "CV = GridSearchCV(rf, param_grid, n_jobs= 1, scoring=scoring, refit='AUC') # change the scorer metric\n",
    "                  \n",
    "CV.fit(X_train, y_train)  \n",
    "print(CV.best_params_)    \n",
    "print(CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = CV.predict(X_test)\n",
    "probabilities = CV.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Classification Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)\n",
    "\n",
    "- Binary classification (only):\n",
    "    - [precision_recall_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve): Compute precision-recall pairs for different probability thresholds.\n",
    "        - The precision is the ratio `tp / (tp + fp)` where `tp` is the number of true positives and `fp` the number of false positives. The **precision** is intuitively the ability of the classifier **not to label as positive a sample that is negative**.\n",
    "        - The recall is the ratio `tp / (tp + fn)` where `tp` is the number of true positives and `fn` the number of false negatives. The **recall** is intuitively the ability of the classifier to **find all the positive samples**.\n",
    "\n",
    "    ### RECALL could be a potentially strong metric for this case; \"from all the flights classified as delayed, the actual (true) number delyed flights is as high as possible.\"\n",
    "\n",
    "    - [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve): A receiver operating characteristic (ROC), or simply ROC curve, is a graphical plot which illustrates the performance of a binary classifier system as its discrimination threshold is varied. It is created by plotting the fraction of true positives out of the positives (TPR = true positive rate) vs. the fraction of false positives out of the negatives (FPR = false positive rate), at various threshold settings. TPR is also known as sensitivity, and FPR is one minus the specificity or true negative rate.\n",
    "        \n",
    "- Multi-class classification (or binary):\n",
    "    - [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix): Compute confusion matrix to evaluate the accuracy of a classification.\n",
    "    ![IMG_Confusion_Matrix](https://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_0011.png)\n",
    "    - [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score): Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
    "\n",
    "- Multi-label classification (or binary or multi-class):\n",
    "    - [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score): Accuracy classification score.\n",
    "        - It is the ratio of number of correct predictions to the total number of input samples.\n",
    "        - **It works well only if there are equal number of samples belonging to each class.**\n",
    "    - [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report): Build a text report showing the main classification metrics.\n",
    "    - [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score): Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "        - The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal: `F1 = 2 * (precision * recall) / (precision + recall)`\n",
    "    - [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "    - [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which metric should be used then?\n",
    "##### Bear in mind that it's a clear case of imbalanced data\n",
    "\n",
    "Nomenclature:\n",
    "- Delayed = Positive\n",
    "- On-time = Negative \n",
    "\n",
    "Considering this:\n",
    "- False positive (Type I error) → Wrongly classifying an On-time flight as a Delayed flight → Not significantly relevant\n",
    "- **False negative (Type II error) → Wrongly classifying a Delayed flight as an On-time flight → Highly relevant**\n",
    "\n",
    "**F-beta** score (\\$ F_\\beta \\$):\n",
    "![F-beta score](https://wikimedia.org/api/rest_v1/media/math/render/svg/136f45612c08805f4254f63d2f2524bc25075fff)\n",
    "\n",
    "Two commonly used values for β are:\n",
    "- **2 : weighs recall higher than precision**\n",
    "- 0.5 : weighs recall lower than precision.\n",
    "\n",
    "\n",
    "*Probably most people in the industry would accept that an **OTP of 80%* or above is pretty good**. That’s 4 in 5 flights arriving within 15 minutes of their scheduled arrival time. The very best airlines and airports succeed in punctuality closer to 90% - but they remain the exception rather than the rule.* (Source: [OAG](https://www.oag.com/on-time-performance-airlines-airports))\n",
    "\n",
    "The actual data from the 7268232 records comprising the OTP dataset accurately confirm this hypothesis:\n",
    "```\n",
    "Delays: 5878979 (80.89%)\n",
    "On-time: 1389253 (19.11%)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "tpr, fpr, thresolds = roc_curve(y_test, probabilities[:, 1])\n",
    "plt.plot(tpr, fpr)\n",
    "f1_score(y_test, predictions), recall_score(y_test, predictions), precision_score(y_test, predictions), accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
