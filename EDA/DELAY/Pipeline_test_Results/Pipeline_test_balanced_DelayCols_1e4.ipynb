{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries to be used\n",
    "\n",
    "# Warning messages display\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action='once') # https://docs.python.org/3/library/warnings.html#the-warnings-filter\n",
    "\n",
    "# Directories/Files management\n",
    "import os.path\n",
    "## from zipfile import ZipFile # De momento no ha hecho falta \n",
    "\n",
    "# Timing\n",
    "import time\n",
    "\n",
    "# Data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None) # Show all columns in DataFrames\n",
    "pd.set_option('display.max_rows', 100) # If too high, it greatly slows down the output display and freezes the kernel\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot') # choose a style: 'plt.style.available'\n",
    "sns.set_theme(context='notebook',\n",
    "              style=\"darkgrid\") # {darkgrid, whitegrid, dark, white, ticks}\n",
    "palette = sns.color_palette(\"flare\", as_cmap=True);\n",
    "import altair as alt\n",
    "\n",
    "# Machine Learning\n",
    "## from sklearn.[...] import ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Windows.\n",
      "root path\t C:\\Users\\turge\\CompartidoVM\\0.TFM\n"
     ]
    }
   ],
   "source": [
    "# Detect Operating System running and manage paths accordingly\n",
    "\n",
    "if os.name == 'nt': # Windows\n",
    "    root = r\"C:\\Users\\turge\\CompartidoVM\\0.TFM\"\n",
    "    print(\"Running on Windows.\")\n",
    "elif os.name == 'posix': # Ubuntu\n",
    "    root = \"/home/dsc/shared/0.TFM\"\n",
    "    print(\"Running on Ubuntu.\")\n",
    "print(\"root path\\t\", root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cols = [\n",
    "    \n",
    "### -----  < X > (PRE-FLIGHT DATA) -----\n",
    "\n",
    "# Time Period\n",
    "#  'YEAR', # Disregarded: for the time being, analysis limted to 2019\n",
    "#  'QUARTER', # Disregarded: redundant\n",
    " 'MONTH',\n",
    " 'DAY_OF_MONTH',\n",
    " 'DAY_OF_WEEK',\n",
    "#  'FL_DATE', # Disregarded: redundant\n",
    "# Airline / Aircraft\n",
    " 'OP_UNIQUE_CARRIER',\n",
    "#  'OP_CARRIER_AIRLINE_ID', # Disregarded: redundant\n",
    "#  'OP_CARRIER', # Disregarded: redundant\n",
    " 'TAIL_NUM',\n",
    "#  'OP_CARRIER_FL_NUM', # Unknown in advance?\n",
    "# Origin\n",
    "#  'ORIGIN_AIRPORT_ID', # Disregarded: redundant\n",
    "#  'ORIGIN_AIRPORT_SEQ_ID', # Disregarded: redundant\n",
    " 'ORIGIN_CITY_MARKET_ID',\n",
    " 'ORIGIN',\n",
    "#  'ORIGIN_CITY_NAME', # Disregarded: redundant\n",
    "#  'ORIGIN_STATE_ABR', # Disregarded: redundant\n",
    "#  'ORIGIN_STATE_FIPS', # Federal Information Processing Standards # Not used for the moment\n",
    "#  'ORIGIN_STATE_NM', # Disregarded: redundant\n",
    "#  'ORIGIN_WAC', # World Area Code # Not used for the moment\n",
    "# Destination\n",
    "#  'DEST_AIRPORT_ID', # Disregarded: redundant\n",
    "#  'DEST_AIRPORT_SEQ_ID', # Disregarded: redundant\n",
    " 'DEST_CITY_MARKET_ID',\n",
    " 'DEST',\n",
    "#  'DEST_CITY_NAME', # Disregarded: redundant\n",
    "#  'DEST_STATE_ABR', # Disregarded: redundant\n",
    "#  'DEST_STATE_FIPS', # Federal Information Processing Standards # Not used for the moment\n",
    "#  'DEST_STATE_NM', # Disregarded: redundant\n",
    "#  'DEST_WAC', # World Area Code # Not used for the moment\n",
    "# Departure Performance\n",
    " 'CRS_DEP_TIME',\n",
    "#  'TAXI_OUT_median', #  Output / However, the median for each airport could be used as input !! (explanation below)   \n",
    "# Arrival Performance\n",
    " 'CRS_ARR_TIME',\n",
    "#  'TAXI_IN_median', #  Output / However, the median for each airport could be used as input !! (explanation below) \n",
    "# Flight Summaries\n",
    " 'CRS_ELAPSED_TIME',\n",
    " 'FLIGHTS',\n",
    " 'DISTANCE',\n",
    " 'DISTANCE_GROUP',\n",
    "\n",
    "### ----- < y > (PRE-FLIGHT DATA) -----\n",
    "\n",
    "# Departure Performance\n",
    "#  'DEP_TIME', # Disregarded: redundant\n",
    "#  'DEP_DELAY', # Disregarded: other potentially useful target\n",
    "#  'DEP_DELAY_NEW', # Disregarded: redundant\n",
    "#  'DEP_DEL15', # Disregarded: other potentially useful target\n",
    "#  'DEP_DELAY_GROUP', # Disregarded: not relevant for this particular analysis\n",
    "#  'DEP_TIME_BLK', # Disregarded: redundant\n",
    "#  'TAXI_OUT', #  Output / However, the median for each airport could be used as input !! (explanation below)\n",
    "#  'WHEELS_OFF', # Disregarded: redundant\n",
    "# Arrival Performance\n",
    "#  'WHEELS_ON', # Disregarded: redundant\n",
    "#  'TAXI_IN', #  Output / However, the median for each airport could be used as input !! (explanation below)\n",
    "#  'ARR_TIME', # Disregarded: redundant\n",
    "#  'ARR_DELAY', # -------------------------------------------> MAIN TARGET !! (i.e. < y >)\n",
    "#  'ARR_DELAY_NEW', # Disregarded: redundant\n",
    " 'ARR_DEL15', # Disregarded: other potentially useful target\n",
    "#  'ARR_DELAY_GROUP', # Disregarded: not relevant for this particular analysis\n",
    "#  'ARR_TIME_BLK', # Disregarded: redundant\n",
    "# Cancellations and Diversions\n",
    "#  'CANCELLED', # Disregarded: not relevant for this particular analysis\n",
    "#  'CANCELLATION_CODE', # Disregarded: not relevant for this particular analysis\n",
    "#  'DIVERTED', # Disregarded: not relevant for this particular analysis\n",
    "# Flight Summaries\n",
    "#  'ACTUAL_ELAPSED_TIME', # Disregarded: redundant\n",
    "#  'AIR_TIME', # Disregarded: redundant\n",
    "# Cause of Delay\n",
    "#  'CARRIER_DELAY', # Disregarded: other potentially useful target\n",
    "#  'WEATHER_DELAY', # Disregarded: other potentially useful target\n",
    "#  'NAS_DELAY', # Disregarded: other potentially useful target\n",
    "#  'SECURITY_DELAY', # Disregarded: other potentially useful target\n",
    "#  'LATE_AIRCRAFT_DELAY', # Disregarded: other potentially useful target\n",
    "# Gate Return Information at Origin Airport (Data starts 10/2008)\n",
    "#  'FIRST_DEP_TIME', # Disregarded: not relevant for this particular analysis\n",
    "#  'TOTAL_ADD_GTIME', # Disregarded: not relevant for this particular analysis\n",
    "#  'LONGEST_ADD_GTIME', # Disregarded: not relevant for this particular analysis\n",
    "# Diverted Airport Information (Data starts 10/2008)\n",
    "#  'DIV_AIRPORT_LANDINGS', # Disregarded: not relevant for this particular analysis\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "     'MONTH',\n",
    "     'DAY_OF_MONTH',\n",
    "     'DAY_OF_WEEK',\n",
    "     'OP_UNIQUE_CARRIER',\n",
    "     'TAIL_NUM',\n",
    "     'ORIGIN_CITY_MARKET_ID',\n",
    "     'ORIGIN',\n",
    "     'DEST_CITY_MARKET_ID',\n",
    "     'DEST',\n",
    "     'CRS_DEP_TIME',\n",
    "     'DEP_TIME',\n",
    "     'TAXI_OUT_median',\n",
    "     'TAXI_IN_median',\n",
    "#      'DEP_DELAY',\n",
    "#      'DEP_DEL15',\n",
    "#      'DEP_DELAY_GROUP',\n",
    "#      'TAXI_OUT',\n",
    "#      'TAXI_IN',\n",
    "     'CRS_ARR_TIME',\n",
    "#      'ARR_TIME',\n",
    "#      'ARR_DELAY',\n",
    "     'ARR_DEL15',\n",
    "#      'ARR_DELAY_GROUP',\n",
    "#      'CANCELLED',\n",
    "     'CRS_ELAPSED_TIME',\n",
    "     'DISTANCE',\n",
    "     'DISTANCE_GROUP',\n",
    "     'CARRIER_DELAY',\n",
    "     'WEATHER_DELAY',\n",
    "     'NAS_DELAY',\n",
    "     'SECURITY_DELAY',\n",
    "     'LATE_AIRCRAFT_DELAY',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\turge\\\\CompartidoVM\\\\0.TFM\\\\Output_Data\\\\US_DoT\\\\AL_OTP_MVP_Preprocessed_19_v2_clean.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_input_csv_path = os.path.join(root,\n",
    "                                           \"Output_Data\",\n",
    "                                           \"US_DoT\",\n",
    "                                           \"AL_OTP_MVP_Preprocessed_19_v2_clean.csv\")\n",
    "preprocessed_input_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_all = pd.read_csv(preprocessed_input_csv_path,\n",
    "                 encoding='latin1',\n",
    "#                  nrows=1e4,\n",
    "                 usecols=cols, # This way, the extra column is disregarded for the loading process\n",
    "                 low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7268232, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 23), (7258232, 23))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_length = int(1e4)\n",
    "delayed = df_all[df_all['ARR_DEL15'] == 1].sample(sample_length // 2)\n",
    "not_delayed = df_all[df_all['ARR_DEL15'] == 0].sample(sample_length // 2)\n",
    "df = delayed.append(not_delayed)\n",
    "\n",
    "df_validation = df_all.loc[set(df_all.index) - set(df.index), :]\n",
    "\n",
    "df.shape, df_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dealing with categorical features with high cardinality: Target Encoding](https://medium.com/@kr.vishwesh54/dealing-with-categorical-features-with-high-cardinality-target-encoding-baa9298bf257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>ORIGIN_CITY_MARKET_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST_CITY_MARKET_ID</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>TAXI_OUT_median</th>\n",
       "      <th>TAXI_IN_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>469826</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>N925AN</td>\n",
       "      <td>33570</td>\n",
       "      <td>SAN</td>\n",
       "      <td>31703</td>\n",
       "      <td>JFK</td>\n",
       "      <td>750</td>\n",
       "      <td>753.0</td>\n",
       "      <td>1608</td>\n",
       "      <td>318.0</td>\n",
       "      <td>2446.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6797575</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>UA</td>\n",
       "      <td>N458UA</td>\n",
       "      <td>31453</td>\n",
       "      <td>IAH</td>\n",
       "      <td>30325</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1300</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>1427</td>\n",
       "      <td>147.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986397</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>UA</td>\n",
       "      <td>N769UA</td>\n",
       "      <td>32575</td>\n",
       "      <td>LAX</td>\n",
       "      <td>31453</td>\n",
       "      <td>IAH</td>\n",
       "      <td>55</td>\n",
       "      <td>329.0</td>\n",
       "      <td>557</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6321088</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>F9</td>\n",
       "      <td>N719FR</td>\n",
       "      <td>30647</td>\n",
       "      <td>CLE</td>\n",
       "      <td>30466</td>\n",
       "      <td>PHX</td>\n",
       "      <td>604</td>\n",
       "      <td>734.0</td>\n",
       "      <td>836</td>\n",
       "      <td>272.0</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6929902</th>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7719A</td>\n",
       "      <td>30529</td>\n",
       "      <td>BDL</td>\n",
       "      <td>32467</td>\n",
       "      <td>FLL</td>\n",
       "      <td>500</td>\n",
       "      <td>500.0</td>\n",
       "      <td>820</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MONTH  DAY_OF_MONTH  DAY_OF_WEEK OP_UNIQUE_CARRIER TAIL_NUM  \\\n",
       "469826       1             3            4                AA   N925AN   \n",
       "6797575     12            13            5                UA   N458UA   \n",
       "1986397      4             8            1                UA   N769UA   \n",
       "6321088     11             7            4                F9   N719FR   \n",
       "6929902     12            29            7                WN   N7719A   \n",
       "\n",
       "         ORIGIN_CITY_MARKET_ID ORIGIN  DEST_CITY_MARKET_ID DEST  CRS_DEP_TIME  \\\n",
       "469826                   33570    SAN                31703  JFK           750   \n",
       "6797575                  31453    IAH                30325  DEN          1300   \n",
       "1986397                  32575    LAX                31453  IAH            55   \n",
       "6321088                  30647    CLE                30466  PHX           604   \n",
       "6929902                  30529    BDL                32467  FLL           500   \n",
       "\n",
       "         DEP_TIME  CRS_ARR_TIME  CRS_ELAPSED_TIME  DISTANCE  DISTANCE_GROUP  \\\n",
       "469826      753.0          1608             318.0    2446.0              10   \n",
       "6797575    1306.0          1427             147.0     862.0               4   \n",
       "1986397     329.0           557             182.0    1379.0               6   \n",
       "6321088     734.0           836             272.0    1737.0               7   \n",
       "6929902     500.0           820             200.0    1173.0               5   \n",
       "\n",
       "         CARRIER_DELAY  WEATHER_DELAY  NAS_DELAY  SECURITY_DELAY  \\\n",
       "469826             3.0            0.0       32.0             0.0   \n",
       "6797575            6.0            0.0       25.0             0.0   \n",
       "1986397            0.0            0.0        3.0             0.0   \n",
       "6321088           90.0            0.0        3.0             0.0   \n",
       "6929902            0.0            0.0        0.0             0.0   \n",
       "\n",
       "         LATE_AIRCRAFT_DELAY  TAXI_OUT_median  TAXI_IN_median  \n",
       "469826                   0.0             19.0            10.0  \n",
       "6797575                  0.0             18.0             8.0  \n",
       "1986397                154.0             18.0             7.0  \n",
       "6321088                  0.0             13.0             7.0  \n",
       "6929902                  0.0              9.0             7.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('ARR_DEL15', axis=1)\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3648963    1.0\n",
       "4678802    1.0\n",
       "7050305    0.0\n",
       "6037644    1.0\n",
       "2220959    1.0\n",
       "Name: ARR_DEL15, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['ARR_DEL15']\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_freq(col='', df=df):\n",
    "    i = 0\n",
    "    for v in df[col].value_counts().sort_index():\n",
    "        print(\"{} : {} records ({:.2f}%)\" \\\n",
    "              .format(df[col].value_counts().sort_index().index[i], v,  v / len(df) * 100))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONTH : 12 unique values\n",
      "1 : 792 records (7.92%)\n",
      "2 : 766 records (7.66%)\n",
      "3 : 829 records (8.29%)\n",
      "4 : 853 records (8.53%)\n",
      "5 : 864 records (8.64%)\n",
      "6 : 921 records (9.21%)\n",
      "7 : 925 records (9.25%)\n",
      "8 : 879 records (8.79%)\n",
      "9 : 739 records (7.39%)\n",
      "10 : 849 records (8.49%)\n",
      "11 : 709 records (7.09%)\n",
      "12 : 874 records (8.74%)\n",
      "\n",
      "DAY_OF_MONTH : 31 unique values\n",
      "1 : 327 records (3.27%)\n",
      "2 : 331 records (3.31%)\n",
      "3 : 308 records (3.08%)\n",
      "4 : 314 records (3.14%)\n",
      "5 : 299 records (2.99%)\n",
      "6 : 295 records (2.95%)\n",
      "7 : 342 records (3.42%)\n",
      "8 : 327 records (3.27%)\n",
      "9 : 306 records (3.06%)\n",
      "10 : 319 records (3.19%)\n",
      "11 : 365 records (3.65%)\n",
      "12 : 325 records (3.25%)\n",
      "13 : 367 records (3.67%)\n",
      "14 : 327 records (3.27%)\n",
      "15 : 336 records (3.36%)\n",
      "16 : 327 records (3.27%)\n",
      "17 : 313 records (3.13%)\n",
      "18 : 336 records (3.36%)\n",
      "19 : 326 records (3.26%)\n",
      "20 : 343 records (3.43%)\n",
      "21 : 359 records (3.59%)\n",
      "22 : 346 records (3.46%)\n",
      "23 : 337 records (3.37%)\n",
      "24 : 282 records (2.82%)\n",
      "25 : 334 records (3.34%)\n",
      "26 : 291 records (2.91%)\n",
      "27 : 335 records (3.35%)\n",
      "28 : 327 records (3.27%)\n",
      "29 : 309 records (3.09%)\n",
      "30 : 350 records (3.50%)\n",
      "31 : 197 records (1.97%)\n",
      "\n",
      "DAY_OF_WEEK : 7 unique values\n",
      "1 : 1532 records (15.32%)\n",
      "2 : 1424 records (14.24%)\n",
      "3 : 1389 records (13.89%)\n",
      "4 : 1511 records (15.11%)\n",
      "5 : 1524 records (15.24%)\n",
      "6 : 1178 records (11.78%)\n",
      "7 : 1442 records (14.42%)\n",
      "\n",
      "OP_UNIQUE_CARRIER : 17 unique values\n",
      "9E : 329 records (3.29%)\n",
      "AA : 1345 records (13.45%)\n",
      "AS : 357 records (3.57%)\n",
      "B6 : 468 records (4.68%)\n",
      "DL : 1263 records (12.63%)\n",
      "EV : 223 records (2.23%)\n",
      "F9 : 198 records (1.98%)\n",
      "G4 : 143 records (1.43%)\n",
      "HA : 85 records (0.85%)\n",
      "MQ : 400 records (4.00%)\n",
      "NK : 274 records (2.74%)\n",
      "OH : 382 records (3.82%)\n",
      "OO : 1100 records (11.00%)\n",
      "UA : 849 records (8.49%)\n",
      "WN : 1847 records (18.47%)\n",
      "YV : 289 records (2.89%)\n",
      "YX : 448 records (4.48%)\n",
      "\n",
      "TAIL_NUM : 4388 unique values\n",
      "\n",
      "ORIGIN_CITY_MARKET_ID : 281 unique values\n",
      "\n",
      "ORIGIN : 305 unique values\n",
      "\n",
      "DEST_CITY_MARKET_ID : 278 unique values\n",
      "\n",
      "DEST : 302 unique values\n",
      "\n",
      "CRS_DEP_TIME : 1070 unique values\n",
      "\n",
      "DEP_TIME : 1224 unique values\n",
      "\n",
      "CRS_ARR_TIME : 1193 unique values\n",
      "\n",
      "ARR_DEL15 : 2 unique values\n",
      "0.0 : 5000 records (50.00%)\n",
      "1.0 : 5000 records (50.00%)\n",
      "\n",
      "CRS_ELAPSED_TIME : 394 unique values\n",
      "\n",
      "DISTANCE : 1249 unique values\n",
      "\n",
      "DISTANCE_GROUP : 11 unique values\n",
      "1 : 1220 records (12.20%)\n",
      "2 : 2433 records (24.33%)\n",
      "3 : 1977 records (19.77%)\n",
      "4 : 1545 records (15.45%)\n",
      "5 : 1095 records (10.95%)\n",
      "6 : 478 records (4.78%)\n",
      "7 : 407 records (4.07%)\n",
      "8 : 230 records (2.30%)\n",
      "9 : 160 records (1.60%)\n",
      "10 : 286 records (2.86%)\n",
      "11 : 169 records (1.69%)\n",
      "\n",
      "CARRIER_DELAY : 240 unique values\n",
      "\n",
      "WEATHER_DELAY : 114 unique values\n",
      "\n",
      "NAS_DELAY : 186 unique values\n",
      "\n",
      "SECURITY_DELAY : 13 unique values\n",
      "0.0 : 9986 records (99.86%)\n",
      "1.0 : 1 records (0.01%)\n",
      "6.0 : 1 records (0.01%)\n",
      "7.0 : 1 records (0.01%)\n",
      "10.0 : 2 records (0.02%)\n",
      "11.0 : 1 records (0.01%)\n",
      "13.0 : 1 records (0.01%)\n",
      "14.0 : 1 records (0.01%)\n",
      "15.0 : 1 records (0.01%)\n",
      "19.0 : 2 records (0.02%)\n",
      "20.0 : 1 records (0.01%)\n",
      "21.0 : 1 records (0.01%)\n",
      "28.0 : 1 records (0.01%)\n",
      "\n",
      "LATE_AIRCRAFT_DELAY : 262 unique values\n",
      "\n",
      "TAXI_OUT_median : 28 unique values\n",
      "6.0 : 1 records (0.01%)\n",
      "7.0 : 5 records (0.05%)\n",
      "8.0 : 83 records (0.83%)\n",
      "8.5 : 1 records (0.01%)\n",
      "9.0 : 409 records (4.09%)\n",
      "9.5 : 1 records (0.01%)\n",
      "10.0 : 706 records (7.06%)\n",
      "10.5 : 1 records (0.01%)\n",
      "11.0 : 513 records (5.13%)\n",
      "12.0 : 818 records (8.18%)\n",
      "12.5 : 4 records (0.04%)\n",
      "13.0 : 790 records (7.90%)\n",
      "13.5 : 1 records (0.01%)\n",
      "14.0 : 924 records (9.24%)\n",
      "15.0 : 1064 records (10.64%)\n",
      "16.0 : 1226 records (12.26%)\n",
      "17.0 : 962 records (9.62%)\n",
      "17.5 : 3 records (0.03%)\n",
      "18.0 : 407 records (4.07%)\n",
      "19.0 : 529 records (5.29%)\n",
      "20.0 : 440 records (4.40%)\n",
      "21.0 : 461 records (4.61%)\n",
      "22.0 : 267 records (2.67%)\n",
      "23.0 : 179 records (1.79%)\n",
      "24.0 : 97 records (0.97%)\n",
      "25.0 : 62 records (0.62%)\n",
      "26.0 : 9 records (0.09%)\n",
      "27.0 : 37 records (0.37%)\n",
      "\n",
      "TAXI_IN_median : 17 unique values\n",
      "2.0 : 41 records (0.41%)\n",
      "3.0 : 590 records (5.90%)\n",
      "3.5 : 1 records (0.01%)\n",
      "4.0 : 1743 records (17.43%)\n",
      "5.0 : 1750 records (17.50%)\n",
      "5.5 : 2 records (0.02%)\n",
      "6.0 : 1470 records (14.70%)\n",
      "6.5 : 1 records (0.01%)\n",
      "7.0 : 1042 records (10.42%)\n",
      "8.0 : 1205 records (12.05%)\n",
      "9.0 : 811 records (8.11%)\n",
      "10.0 : 279 records (2.79%)\n",
      "11.0 : 402 records (4.02%)\n",
      "12.0 : 243 records (2.43%)\n",
      "13.0 : 317 records (3.17%)\n",
      "14.0 : 93 records (0.93%)\n",
      "15.0 : 10 records (0.10%)\n",
      "\n",
      "Wall time: 319 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for col in df.columns:\n",
    "    print(col, ':', df[col].nunique(), 'unique values')\n",
    "    if df[col].nunique() < 50:\n",
    "        val_freq(col)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for col in X.columns:\n",
    "    a = df.groupby([col], as_index=False).agg(['sum'])['ARR_DEL15']\n",
    "    a.plot(legend=True)\n",
    "    plt.title(col)\n",
    "    b = df.groupby([col], as_index=False).agg(['count'])['ARR_DEL15']\n",
    "    b.plot(legend=True)\n",
    "    plt.title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "- En junio se concentra el mayor número de retrasos. Curiosamente, hay notablemente más vuelos en mayo, julio, agosto y octubre.\n",
    "- Los D, L, X y J se concentra el mayor número de retrasos (especialmente X). D y X es cuando más vuelos hay con diferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3589.72 MiB, increment: 0.21 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Guide to Scikit-learn Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the pipeline, let's split the data into a train and test set so that the performance of the model can be validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first step in building the pipeline is to define each transformer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 162 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, let's use the ColumnTransformer to apply the transformations to the correct columns in the dataframe. Before building this, the numeric and categorical columns shall be listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).drop(['ARR_DEL15'], axis=1).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a pipeline that combines the preprocessor created above with a classifier. In this case a simple RandomForestClassifier has been used to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(random_state=0))])\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A pipeline can also be used during the model selection process**. The following example code loops through a number of scikit-learn classifiers applying the transformations and training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n",
      "model score: 0.697\n",
      "0.625 0.6625835189309577 0.6022267206477733 0.7363861386138614 0.697\n",
      "[[799 213]\n",
      " [393 595]] \n",
      "\n",
      "SVC(C=0.025, probability=True, random_state=0)\n",
      "model score: 0.803\n",
      "0.6946236559139786 0.7663107947805456 0.6538461538461539 0.9255014326647565 0.803\n",
      "[[960  52]\n",
      " [342 646]] \n",
      "\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "model score: 1.000\n",
      "1.0 1.0 1.0 1.0 1.0\n",
      "[[1012    0]\n",
      " [   0  988]] \n",
      "\n",
      "RandomForestClassifier(random_state=0)\n",
      "model score: 0.999\n",
      "0.9983799108950991 0.9989868287740628 0.9979757085020243 1.0 0.999\n",
      "[[1012    0]\n",
      " [   2  986]] \n",
      "\n",
      "AdaBoostClassifier(random_state=0)\n",
      "model score: 1.000\n",
      "1.0 1.0 1.0 1.0 1.0\n",
      "[[1012    0]\n",
      " [   0  988]] \n",
      "\n",
      "GradientBoostingClassifier(random_state=0)\n",
      "model score: 1.000\n",
      "1.0 1.0 1.0 1.0 1.0\n",
      "[[1012    0]\n",
      " [   0  988]] \n",
      "\n",
      "Wall time: 46.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss, f1_score, fbeta_score, recall_score, precision_score, roc_auc_score, roc_curve, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True, random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    AdaBoostClassifier(random_state=0),\n",
    "    GradientBoostingClassifier(random_state=0)\n",
    "    ]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', classifier)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))    \n",
    "    # TEST !!!     \n",
    "    predictions = pipe.predict(X_test)\n",
    "    print(fbeta_score(y_test, predictions, beta=2), f1_score(y_test, predictions), recall_score(y_test, predictions), precision_score(y_test, predictions), accuracy_score(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions), \"\\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The pipeline can also be used in grid search** to find the best performing parameters. To do this, let's first create a parameter grid for the chosen model.\n",
    "\n",
    "*One important thing to note is that there is a need to append the name given to the classifier part of the pipeline to each parameter name. In the code above its name is ‘classifier’ so 'classifier__' has been added to each parameter.*\n",
    "\n",
    "Next a grid search object has been created, which includes the original pipeline. When fit is called, the transformations are applied to the data, before a cross-validated grid-search is performed over the parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__criterion': 'gini', 'classifier__max_depth': 8, 'classifier__max_features': 'auto', 'classifier__n_estimators': 500}\n",
      "0.9465046573447063\n",
      "Wall time: 6min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = { \n",
    "    'classifier__n_estimators': [200, 500],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__max_depth' : [4,5,6,7,8],\n",
    "    'classifier__criterion' :['gini', 'entropy']}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'F1': 'f1', 'Precision': 'precision',\n",
    "           'Recall': 'recall', 'Accuracy': 'accuracy'}\n",
    "\n",
    "CV = GridSearchCV(rf, param_grid, n_jobs= 1, scoring=scoring, refit='F1')\n",
    "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
    "# parameter setting that has the best cross-validated AUC score.\n",
    "# That estimator is made available at ``gs.best_estimator_`` along with\n",
    "# parameters like ``gs.best_score_``, ``gs.best_params_`` and\n",
    "# ``gs.best_index_``\n",
    "\n",
    "CV.fit(X_train, y_train)  \n",
    "print(CV.best_params_)    \n",
    "print(CV.best_score_)\n",
    "CVscores = pd.DataFrame(CV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__criterion</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__max_features</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_AUC</th>\n",
       "      <th>split1_test_AUC</th>\n",
       "      <th>split2_test_AUC</th>\n",
       "      <th>split3_test_AUC</th>\n",
       "      <th>split4_test_AUC</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>std_test_AUC</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>split0_test_F1</th>\n",
       "      <th>split1_test_F1</th>\n",
       "      <th>split2_test_F1</th>\n",
       "      <th>split3_test_F1</th>\n",
       "      <th>split4_test_F1</th>\n",
       "      <th>mean_test_F1</th>\n",
       "      <th>std_test_F1</th>\n",
       "      <th>rank_test_F1</th>\n",
       "      <th>split0_test_Precision</th>\n",
       "      <th>split1_test_Precision</th>\n",
       "      <th>split2_test_Precision</th>\n",
       "      <th>split3_test_Precision</th>\n",
       "      <th>split4_test_Precision</th>\n",
       "      <th>mean_test_Precision</th>\n",
       "      <th>std_test_Precision</th>\n",
       "      <th>rank_test_Precision</th>\n",
       "      <th>split0_test_Recall</th>\n",
       "      <th>split1_test_Recall</th>\n",
       "      <th>split2_test_Recall</th>\n",
       "      <th>split3_test_Recall</th>\n",
       "      <th>split4_test_Recall</th>\n",
       "      <th>mean_test_Recall</th>\n",
       "      <th>std_test_Recall</th>\n",
       "      <th>rank_test_Recall</th>\n",
       "      <th>split0_test_Accuracy</th>\n",
       "      <th>split1_test_Accuracy</th>\n",
       "      <th>split2_test_Accuracy</th>\n",
       "      <th>split3_test_Accuracy</th>\n",
       "      <th>split4_test_Accuracy</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.642004</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>0.141113</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.986001</td>\n",
       "      <td>0.978519</td>\n",
       "      <td>0.971115</td>\n",
       "      <td>0.990119</td>\n",
       "      <td>0.988328</td>\n",
       "      <td>0.982816</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>37</td>\n",
       "      <td>0.928524</td>\n",
       "      <td>0.904054</td>\n",
       "      <td>0.903623</td>\n",
       "      <td>0.925753</td>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.918561</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>0.997060</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>35</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.834165</td>\n",
       "      <td>0.824190</td>\n",
       "      <td>0.861768</td>\n",
       "      <td>0.871731</td>\n",
       "      <td>0.851687</td>\n",
       "      <td>0.018913</td>\n",
       "      <td>49</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.911875</td>\n",
       "      <td>0.930625</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.924375</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.484060</td>\n",
       "      <td>0.047302</td>\n",
       "      <td>0.296817</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.985925</td>\n",
       "      <td>0.992420</td>\n",
       "      <td>0.991777</td>\n",
       "      <td>0.991264</td>\n",
       "      <td>0.997383</td>\n",
       "      <td>0.991754</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>25</td>\n",
       "      <td>0.936340</td>\n",
       "      <td>0.935889</td>\n",
       "      <td>0.922767</td>\n",
       "      <td>0.935719</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.936619</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>23</td>\n",
       "      <td>0.880299</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.856608</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.881599</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>33</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.954375</td>\n",
       "      <td>0.940250</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.632010</td>\n",
       "      <td>0.010124</td>\n",
       "      <td>0.143510</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.986001</td>\n",
       "      <td>0.978519</td>\n",
       "      <td>0.971115</td>\n",
       "      <td>0.990119</td>\n",
       "      <td>0.988328</td>\n",
       "      <td>0.982816</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>37</td>\n",
       "      <td>0.928524</td>\n",
       "      <td>0.904054</td>\n",
       "      <td>0.903623</td>\n",
       "      <td>0.925753</td>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.918561</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>0.997060</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>35</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.834165</td>\n",
       "      <td>0.824190</td>\n",
       "      <td>0.861768</td>\n",
       "      <td>0.871731</td>\n",
       "      <td>0.851687</td>\n",
       "      <td>0.018913</td>\n",
       "      <td>49</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>0.911250</td>\n",
       "      <td>0.911875</td>\n",
       "      <td>0.930625</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.924375</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.436512</td>\n",
       "      <td>0.016220</td>\n",
       "      <td>0.299215</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.985925</td>\n",
       "      <td>0.992420</td>\n",
       "      <td>0.991777</td>\n",
       "      <td>0.991264</td>\n",
       "      <td>0.997383</td>\n",
       "      <td>0.991754</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>25</td>\n",
       "      <td>0.936340</td>\n",
       "      <td>0.935889</td>\n",
       "      <td>0.922767</td>\n",
       "      <td>0.935719</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.936619</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>23</td>\n",
       "      <td>0.880299</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.856608</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.881599</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>33</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.954375</td>\n",
       "      <td>0.940250</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.554304</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.139913</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.988251</td>\n",
       "      <td>0.891746</td>\n",
       "      <td>0.820532</td>\n",
       "      <td>0.941191</td>\n",
       "      <td>0.985712</td>\n",
       "      <td>0.925487</td>\n",
       "      <td>0.063193</td>\n",
       "      <td>60</td>\n",
       "      <td>0.945170</td>\n",
       "      <td>0.830812</td>\n",
       "      <td>0.722128</td>\n",
       "      <td>0.861670</td>\n",
       "      <td>0.929186</td>\n",
       "      <td>0.857793</td>\n",
       "      <td>0.079849</td>\n",
       "      <td>60</td>\n",
       "      <td>0.991781</td>\n",
       "      <td>0.926380</td>\n",
       "      <td>0.661140</td>\n",
       "      <td>0.843675</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.882900</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>60</td>\n",
       "      <td>0.902743</td>\n",
       "      <td>0.753117</td>\n",
       "      <td>0.795511</td>\n",
       "      <td>0.880448</td>\n",
       "      <td>0.874222</td>\n",
       "      <td>0.841208</td>\n",
       "      <td>0.057034</td>\n",
       "      <td>56</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.846250</td>\n",
       "      <td>0.693125</td>\n",
       "      <td>0.858125</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>0.855625</td>\n",
       "      <td>0.090496</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.273214</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.335192</td>\n",
       "      <td>0.084821</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.993166</td>\n",
       "      <td>0.938545</td>\n",
       "      <td>0.927973</td>\n",
       "      <td>0.980148</td>\n",
       "      <td>0.993070</td>\n",
       "      <td>0.966580</td>\n",
       "      <td>0.027818</td>\n",
       "      <td>49</td>\n",
       "      <td>0.940092</td>\n",
       "      <td>0.870926</td>\n",
       "      <td>0.858736</td>\n",
       "      <td>0.933504</td>\n",
       "      <td>0.961340</td>\n",
       "      <td>0.912920</td>\n",
       "      <td>0.040512</td>\n",
       "      <td>50</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.912568</td>\n",
       "      <td>0.853448</td>\n",
       "      <td>0.959264</td>\n",
       "      <td>0.995995</td>\n",
       "      <td>0.943418</td>\n",
       "      <td>0.054419</td>\n",
       "      <td>49</td>\n",
       "      <td>0.890274</td>\n",
       "      <td>0.832918</td>\n",
       "      <td>0.864090</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.929016</td>\n",
       "      <td>0.885078</td>\n",
       "      <td>0.033750</td>\n",
       "      <td>25</td>\n",
       "      <td>0.943125</td>\n",
       "      <td>0.876250</td>\n",
       "      <td>0.857500</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.914875</td>\n",
       "      <td>0.040632</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.659393</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.144110</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.983953</td>\n",
       "      <td>0.980247</td>\n",
       "      <td>0.990515</td>\n",
       "      <td>0.990937</td>\n",
       "      <td>0.987176</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>33</td>\n",
       "      <td>0.939153</td>\n",
       "      <td>0.911409</td>\n",
       "      <td>0.914015</td>\n",
       "      <td>0.925033</td>\n",
       "      <td>0.931652</td>\n",
       "      <td>0.924253</td>\n",
       "      <td>0.010461</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997159</td>\n",
       "      <td>0.996816</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>39</td>\n",
       "      <td>0.885287</td>\n",
       "      <td>0.846633</td>\n",
       "      <td>0.841646</td>\n",
       "      <td>0.860523</td>\n",
       "      <td>0.874222</td>\n",
       "      <td>0.861662</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>45</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.920625</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.935625</td>\n",
       "      <td>0.929250</td>\n",
       "      <td>0.009265</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.600810</td>\n",
       "      <td>0.085273</td>\n",
       "      <td>0.314406</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.986883</td>\n",
       "      <td>0.993400</td>\n",
       "      <td>0.995227</td>\n",
       "      <td>0.994220</td>\n",
       "      <td>0.997428</td>\n",
       "      <td>0.993432</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>17</td>\n",
       "      <td>0.938451</td>\n",
       "      <td>0.939314</td>\n",
       "      <td>0.928524</td>\n",
       "      <td>0.944809</td>\n",
       "      <td>0.947575</td>\n",
       "      <td>0.939735</td>\n",
       "      <td>0.006553</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>19</td>\n",
       "      <td>0.884040</td>\n",
       "      <td>0.887781</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.895392</td>\n",
       "      <td>0.900374</td>\n",
       "      <td>0.886834</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>12</td>\n",
       "      <td>0.941875</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.943000</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.684377</td>\n",
       "      <td>0.027159</td>\n",
       "      <td>0.151107</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.983953</td>\n",
       "      <td>0.980247</td>\n",
       "      <td>0.990515</td>\n",
       "      <td>0.990937</td>\n",
       "      <td>0.987176</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>33</td>\n",
       "      <td>0.939153</td>\n",
       "      <td>0.911409</td>\n",
       "      <td>0.914015</td>\n",
       "      <td>0.925033</td>\n",
       "      <td>0.931652</td>\n",
       "      <td>0.924253</td>\n",
       "      <td>0.010461</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997159</td>\n",
       "      <td>0.996816</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>39</td>\n",
       "      <td>0.885287</td>\n",
       "      <td>0.846633</td>\n",
       "      <td>0.841646</td>\n",
       "      <td>0.860523</td>\n",
       "      <td>0.874222</td>\n",
       "      <td>0.861662</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>45</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.920625</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.935625</td>\n",
       "      <td>0.929250</td>\n",
       "      <td>0.009265</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.587619</td>\n",
       "      <td>0.071753</td>\n",
       "      <td>0.310408</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.986883</td>\n",
       "      <td>0.993400</td>\n",
       "      <td>0.995227</td>\n",
       "      <td>0.994220</td>\n",
       "      <td>0.997428</td>\n",
       "      <td>0.993432</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>17</td>\n",
       "      <td>0.938451</td>\n",
       "      <td>0.939314</td>\n",
       "      <td>0.928524</td>\n",
       "      <td>0.944809</td>\n",
       "      <td>0.947575</td>\n",
       "      <td>0.939735</td>\n",
       "      <td>0.006553</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999440</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>19</td>\n",
       "      <td>0.884040</td>\n",
       "      <td>0.887781</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.895392</td>\n",
       "      <td>0.900374</td>\n",
       "      <td>0.886834</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>12</td>\n",
       "      <td>0.941875</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.943000</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.575045</td>\n",
       "      <td>0.012380</td>\n",
       "      <td>0.143711</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.981544</td>\n",
       "      <td>0.953950</td>\n",
       "      <td>0.827882</td>\n",
       "      <td>0.952324</td>\n",
       "      <td>0.984440</td>\n",
       "      <td>0.940028</td>\n",
       "      <td>0.057650</td>\n",
       "      <td>54</td>\n",
       "      <td>0.934653</td>\n",
       "      <td>0.880442</td>\n",
       "      <td>0.729025</td>\n",
       "      <td>0.897933</td>\n",
       "      <td>0.930417</td>\n",
       "      <td>0.874494</td>\n",
       "      <td>0.075489</td>\n",
       "      <td>55</td>\n",
       "      <td>0.992987</td>\n",
       "      <td>0.987597</td>\n",
       "      <td>0.668399</td>\n",
       "      <td>0.932886</td>\n",
       "      <td>0.994334</td>\n",
       "      <td>0.915241</td>\n",
       "      <td>0.125521</td>\n",
       "      <td>54</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.794264</td>\n",
       "      <td>0.801746</td>\n",
       "      <td>0.865504</td>\n",
       "      <td>0.874222</td>\n",
       "      <td>0.843706</td>\n",
       "      <td>0.037787</td>\n",
       "      <td>54</td>\n",
       "      <td>0.938125</td>\n",
       "      <td>0.891875</td>\n",
       "      <td>0.701250</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.873375</td>\n",
       "      <td>0.087932</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.387562</td>\n",
       "      <td>0.118516</td>\n",
       "      <td>0.299815</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.989448</td>\n",
       "      <td>0.963287</td>\n",
       "      <td>0.932286</td>\n",
       "      <td>0.981500</td>\n",
       "      <td>0.993276</td>\n",
       "      <td>0.971959</td>\n",
       "      <td>0.022363</td>\n",
       "      <td>44</td>\n",
       "      <td>0.931743</td>\n",
       "      <td>0.897933</td>\n",
       "      <td>0.874289</td>\n",
       "      <td>0.932821</td>\n",
       "      <td>0.956634</td>\n",
       "      <td>0.918684</td>\n",
       "      <td>0.029025</td>\n",
       "      <td>41</td>\n",
       "      <td>0.994342</td>\n",
       "      <td>0.931635</td>\n",
       "      <td>0.886044</td>\n",
       "      <td>0.959211</td>\n",
       "      <td>0.995957</td>\n",
       "      <td>0.953438</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>46</td>\n",
       "      <td>0.876559</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.862843</td>\n",
       "      <td>0.907846</td>\n",
       "      <td>0.920299</td>\n",
       "      <td>0.886826</td>\n",
       "      <td>0.023033</td>\n",
       "      <td>18</td>\n",
       "      <td>0.935625</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.875625</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.958125</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>0.029052</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.696369</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.147709</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.976917</td>\n",
       "      <td>0.989586</td>\n",
       "      <td>0.995256</td>\n",
       "      <td>0.988547</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>31</td>\n",
       "      <td>0.944737</td>\n",
       "      <td>0.926246</td>\n",
       "      <td>0.909708</td>\n",
       "      <td>0.941332</td>\n",
       "      <td>0.943495</td>\n",
       "      <td>0.933104</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991465</td>\n",
       "      <td>0.998510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998609</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>31</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>0.835411</td>\n",
       "      <td>0.889166</td>\n",
       "      <td>0.894147</td>\n",
       "      <td>0.876613</td>\n",
       "      <td>0.022659</td>\n",
       "      <td>39</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.930625</td>\n",
       "      <td>0.916875</td>\n",
       "      <td>0.944375</td>\n",
       "      <td>0.946250</td>\n",
       "      <td>0.937125</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.658405</td>\n",
       "      <td>0.018582</td>\n",
       "      <td>0.329995</td>\n",
       "      <td>0.033584</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.989934</td>\n",
       "      <td>0.993545</td>\n",
       "      <td>0.994162</td>\n",
       "      <td>0.989428</td>\n",
       "      <td>0.998977</td>\n",
       "      <td>0.993209</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>19</td>\n",
       "      <td>0.939855</td>\n",
       "      <td>0.937128</td>\n",
       "      <td>0.924933</td>\n",
       "      <td>0.937128</td>\n",
       "      <td>0.955107</td>\n",
       "      <td>0.938830</td>\n",
       "      <td>0.009643</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>13</td>\n",
       "      <td>0.886534</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.881694</td>\n",
       "      <td>0.914072</td>\n",
       "      <td>0.885088</td>\n",
       "      <td>0.017152</td>\n",
       "      <td>23</td>\n",
       "      <td>0.943125</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.956875</td>\n",
       "      <td>0.942250</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.715393</td>\n",
       "      <td>0.027178</td>\n",
       "      <td>0.150706</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.987189</td>\n",
       "      <td>0.976917</td>\n",
       "      <td>0.989586</td>\n",
       "      <td>0.995256</td>\n",
       "      <td>0.988547</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>31</td>\n",
       "      <td>0.944737</td>\n",
       "      <td>0.926246</td>\n",
       "      <td>0.909708</td>\n",
       "      <td>0.941332</td>\n",
       "      <td>0.943495</td>\n",
       "      <td>0.933104</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991465</td>\n",
       "      <td>0.998510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998609</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>31</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>0.835411</td>\n",
       "      <td>0.889166</td>\n",
       "      <td>0.894147</td>\n",
       "      <td>0.876613</td>\n",
       "      <td>0.022659</td>\n",
       "      <td>39</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.930625</td>\n",
       "      <td>0.916875</td>\n",
       "      <td>0.944375</td>\n",
       "      <td>0.946250</td>\n",
       "      <td>0.937125</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.665844</td>\n",
       "      <td>0.058526</td>\n",
       "      <td>0.318358</td>\n",
       "      <td>0.019085</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.989934</td>\n",
       "      <td>0.993545</td>\n",
       "      <td>0.994162</td>\n",
       "      <td>0.989428</td>\n",
       "      <td>0.998977</td>\n",
       "      <td>0.993209</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>19</td>\n",
       "      <td>0.939855</td>\n",
       "      <td>0.937128</td>\n",
       "      <td>0.924933</td>\n",
       "      <td>0.937128</td>\n",
       "      <td>0.955107</td>\n",
       "      <td>0.938830</td>\n",
       "      <td>0.009643</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>13</td>\n",
       "      <td>0.886534</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.881694</td>\n",
       "      <td>0.914072</td>\n",
       "      <td>0.885088</td>\n",
       "      <td>0.017152</td>\n",
       "      <td>23</td>\n",
       "      <td>0.943125</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.956875</td>\n",
       "      <td>0.942250</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.600229</td>\n",
       "      <td>0.023858</td>\n",
       "      <td>0.145110</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.988814</td>\n",
       "      <td>0.900940</td>\n",
       "      <td>0.816572</td>\n",
       "      <td>0.949004</td>\n",
       "      <td>0.982628</td>\n",
       "      <td>0.927592</td>\n",
       "      <td>0.063673</td>\n",
       "      <td>58</td>\n",
       "      <td>0.939176</td>\n",
       "      <td>0.837113</td>\n",
       "      <td>0.729977</td>\n",
       "      <td>0.890188</td>\n",
       "      <td>0.931398</td>\n",
       "      <td>0.865571</td>\n",
       "      <td>0.076880</td>\n",
       "      <td>57</td>\n",
       "      <td>0.987620</td>\n",
       "      <td>0.932619</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.930707</td>\n",
       "      <td>0.990182</td>\n",
       "      <td>0.903109</td>\n",
       "      <td>0.117180</td>\n",
       "      <td>57</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.759352</td>\n",
       "      <td>0.795511</td>\n",
       "      <td>0.853051</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.836476</td>\n",
       "      <td>0.051347</td>\n",
       "      <td>59</td>\n",
       "      <td>0.941875</td>\n",
       "      <td>0.851875</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.894375</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.086537</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.405132</td>\n",
       "      <td>0.059735</td>\n",
       "      <td>0.321201</td>\n",
       "      <td>0.013507</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.991995</td>\n",
       "      <td>0.967031</td>\n",
       "      <td>0.937109</td>\n",
       "      <td>0.977873</td>\n",
       "      <td>0.994917</td>\n",
       "      <td>0.973785</td>\n",
       "      <td>0.020908</td>\n",
       "      <td>41</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.905100</td>\n",
       "      <td>0.878421</td>\n",
       "      <td>0.930529</td>\n",
       "      <td>0.960569</td>\n",
       "      <td>0.922679</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>37</td>\n",
       "      <td>0.994421</td>\n",
       "      <td>0.938420</td>\n",
       "      <td>0.897269</td>\n",
       "      <td>0.953003</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.956354</td>\n",
       "      <td>0.037583</td>\n",
       "      <td>45</td>\n",
       "      <td>0.889027</td>\n",
       "      <td>0.874065</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.925280</td>\n",
       "      <td>0.891563</td>\n",
       "      <td>0.023371</td>\n",
       "      <td>9</td>\n",
       "      <td>0.941875</td>\n",
       "      <td>0.908125</td>\n",
       "      <td>0.880625</td>\n",
       "      <td>0.931875</td>\n",
       "      <td>0.961875</td>\n",
       "      <td>0.924875</td>\n",
       "      <td>0.028091</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.739143</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.149508</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.994178</td>\n",
       "      <td>0.989056</td>\n",
       "      <td>0.988111</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>0.995692</td>\n",
       "      <td>0.992627</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>21</td>\n",
       "      <td>0.945502</td>\n",
       "      <td>0.926441</td>\n",
       "      <td>0.924212</td>\n",
       "      <td>0.938533</td>\n",
       "      <td>0.946335</td>\n",
       "      <td>0.936205</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>25</td>\n",
       "      <td>0.998613</td>\n",
       "      <td>0.988685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>0.996908</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>37</td>\n",
       "      <td>0.897756</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.859102</td>\n",
       "      <td>0.884184</td>\n",
       "      <td>0.900374</td>\n",
       "      <td>0.882597</td>\n",
       "      <td>0.015633</td>\n",
       "      <td>29</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.930625</td>\n",
       "      <td>0.929375</td>\n",
       "      <td>0.941875</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>0.939750</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.762312</td>\n",
       "      <td>0.027679</td>\n",
       "      <td>0.319401</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.993055</td>\n",
       "      <td>0.994119</td>\n",
       "      <td>0.995606</td>\n",
       "      <td>0.997219</td>\n",
       "      <td>0.998798</td>\n",
       "      <td>0.995759</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>7</td>\n",
       "      <td>0.941953</td>\n",
       "      <td>0.937831</td>\n",
       "      <td>0.933511</td>\n",
       "      <td>0.948265</td>\n",
       "      <td>0.955107</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.007637</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>9</td>\n",
       "      <td>0.890274</td>\n",
       "      <td>0.884040</td>\n",
       "      <td>0.875312</td>\n",
       "      <td>0.901619</td>\n",
       "      <td>0.914072</td>\n",
       "      <td>0.893063</td>\n",
       "      <td>0.013556</td>\n",
       "      <td>5</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.941250</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.950625</td>\n",
       "      <td>0.956875</td>\n",
       "      <td>0.946250</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.747139</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.156902</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.994178</td>\n",
       "      <td>0.989056</td>\n",
       "      <td>0.988111</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>0.995692</td>\n",
       "      <td>0.992627</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>21</td>\n",
       "      <td>0.945502</td>\n",
       "      <td>0.926441</td>\n",
       "      <td>0.924212</td>\n",
       "      <td>0.938533</td>\n",
       "      <td>0.946335</td>\n",
       "      <td>0.936205</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>25</td>\n",
       "      <td>0.998613</td>\n",
       "      <td>0.988685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>0.996908</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>37</td>\n",
       "      <td>0.897756</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.859102</td>\n",
       "      <td>0.884184</td>\n",
       "      <td>0.900374</td>\n",
       "      <td>0.882597</td>\n",
       "      <td>0.015633</td>\n",
       "      <td>29</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.930625</td>\n",
       "      <td>0.929375</td>\n",
       "      <td>0.941875</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>0.939750</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.761710</td>\n",
       "      <td>0.057063</td>\n",
       "      <td>0.374169</td>\n",
       "      <td>0.079850</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.993055</td>\n",
       "      <td>0.994119</td>\n",
       "      <td>0.995606</td>\n",
       "      <td>0.997219</td>\n",
       "      <td>0.998798</td>\n",
       "      <td>0.995759</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>7</td>\n",
       "      <td>0.941953</td>\n",
       "      <td>0.937831</td>\n",
       "      <td>0.933511</td>\n",
       "      <td>0.948265</td>\n",
       "      <td>0.955107</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.007637</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>9</td>\n",
       "      <td>0.890274</td>\n",
       "      <td>0.884040</td>\n",
       "      <td>0.875312</td>\n",
       "      <td>0.901619</td>\n",
       "      <td>0.914072</td>\n",
       "      <td>0.893063</td>\n",
       "      <td>0.013556</td>\n",
       "      <td>5</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.941250</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.950625</td>\n",
       "      <td>0.956875</td>\n",
       "      <td>0.946250</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.615020</td>\n",
       "      <td>0.015347</td>\n",
       "      <td>0.154105</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.993628</td>\n",
       "      <td>0.906390</td>\n",
       "      <td>0.855901</td>\n",
       "      <td>0.948493</td>\n",
       "      <td>0.986229</td>\n",
       "      <td>0.938128</td>\n",
       "      <td>0.051517</td>\n",
       "      <td>56</td>\n",
       "      <td>0.946209</td>\n",
       "      <td>0.859097</td>\n",
       "      <td>0.757808</td>\n",
       "      <td>0.879897</td>\n",
       "      <td>0.930784</td>\n",
       "      <td>0.874759</td>\n",
       "      <td>0.066623</td>\n",
       "      <td>54</td>\n",
       "      <td>0.985155</td>\n",
       "      <td>0.951515</td>\n",
       "      <td>0.718436</td>\n",
       "      <td>0.908488</td>\n",
       "      <td>0.988796</td>\n",
       "      <td>0.910478</td>\n",
       "      <td>0.100278</td>\n",
       "      <td>56</td>\n",
       "      <td>0.910224</td>\n",
       "      <td>0.783042</td>\n",
       "      <td>0.801746</td>\n",
       "      <td>0.853051</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.845453</td>\n",
       "      <td>0.047323</td>\n",
       "      <td>53</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.871250</td>\n",
       "      <td>0.743125</td>\n",
       "      <td>0.883125</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.072579</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.510265</td>\n",
       "      <td>0.066950</td>\n",
       "      <td>0.335593</td>\n",
       "      <td>0.019060</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.992630</td>\n",
       "      <td>0.969284</td>\n",
       "      <td>0.934351</td>\n",
       "      <td>0.965101</td>\n",
       "      <td>0.995780</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.022189</td>\n",
       "      <td>45</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.914698</td>\n",
       "      <td>0.876276</td>\n",
       "      <td>0.905950</td>\n",
       "      <td>0.950327</td>\n",
       "      <td>0.917205</td>\n",
       "      <td>0.025964</td>\n",
       "      <td>47</td>\n",
       "      <td>0.994421</td>\n",
       "      <td>0.965374</td>\n",
       "      <td>0.896867</td>\n",
       "      <td>0.931579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957648</td>\n",
       "      <td>0.038935</td>\n",
       "      <td>42</td>\n",
       "      <td>0.889027</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>0.856608</td>\n",
       "      <td>0.881694</td>\n",
       "      <td>0.905355</td>\n",
       "      <td>0.880352</td>\n",
       "      <td>0.016692</td>\n",
       "      <td>35</td>\n",
       "      <td>0.941875</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.878750</td>\n",
       "      <td>0.908125</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.822691</td>\n",
       "      <td>0.026399</td>\n",
       "      <td>0.155305</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.994397</td>\n",
       "      <td>0.986405</td>\n",
       "      <td>0.982886</td>\n",
       "      <td>0.998383</td>\n",
       "      <td>0.997556</td>\n",
       "      <td>0.991925</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>23</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.933068</td>\n",
       "      <td>0.921529</td>\n",
       "      <td>0.957820</td>\n",
       "      <td>0.946194</td>\n",
       "      <td>0.939272</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995757</td>\n",
       "      <td>0.997097</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998571</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>29</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.877805</td>\n",
       "      <td>0.856608</td>\n",
       "      <td>0.919054</td>\n",
       "      <td>0.897883</td>\n",
       "      <td>0.886829</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>16</td>\n",
       "      <td>0.941250</td>\n",
       "      <td>0.936875</td>\n",
       "      <td>0.926875</td>\n",
       "      <td>0.959375</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>0.942625</td>\n",
       "      <td>0.010964</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.898672</td>\n",
       "      <td>0.056129</td>\n",
       "      <td>0.335392</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.993734</td>\n",
       "      <td>0.995206</td>\n",
       "      <td>0.995186</td>\n",
       "      <td>0.997183</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>0.996059</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>3</td>\n",
       "      <td>0.941953</td>\n",
       "      <td>0.942650</td>\n",
       "      <td>0.937044</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.958495</td>\n",
       "      <td>0.946505</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.890274</td>\n",
       "      <td>0.891521</td>\n",
       "      <td>0.881546</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.920299</td>\n",
       "      <td>0.898546</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>1</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.954375</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.949125</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.837575</td>\n",
       "      <td>0.036708</td>\n",
       "      <td>0.167858</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.994397</td>\n",
       "      <td>0.986405</td>\n",
       "      <td>0.982886</td>\n",
       "      <td>0.998383</td>\n",
       "      <td>0.997556</td>\n",
       "      <td>0.991925</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>23</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.933068</td>\n",
       "      <td>0.921529</td>\n",
       "      <td>0.957820</td>\n",
       "      <td>0.946194</td>\n",
       "      <td>0.939272</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995757</td>\n",
       "      <td>0.997097</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998571</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>29</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.877805</td>\n",
       "      <td>0.856608</td>\n",
       "      <td>0.919054</td>\n",
       "      <td>0.897883</td>\n",
       "      <td>0.886829</td>\n",
       "      <td>0.020840</td>\n",
       "      <td>16</td>\n",
       "      <td>0.941250</td>\n",
       "      <td>0.936875</td>\n",
       "      <td>0.926875</td>\n",
       "      <td>0.959375</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>0.942625</td>\n",
       "      <td>0.010964</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.863345</td>\n",
       "      <td>0.068130</td>\n",
       "      <td>0.335392</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.993734</td>\n",
       "      <td>0.995206</td>\n",
       "      <td>0.995186</td>\n",
       "      <td>0.997183</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>0.996059</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>3</td>\n",
       "      <td>0.941953</td>\n",
       "      <td>0.942650</td>\n",
       "      <td>0.937044</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.958495</td>\n",
       "      <td>0.946505</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.890274</td>\n",
       "      <td>0.891521</td>\n",
       "      <td>0.881546</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.920299</td>\n",
       "      <td>0.898546</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>1</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.954375</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.949125</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.665790</td>\n",
       "      <td>0.064307</td>\n",
       "      <td>0.157901</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.997811</td>\n",
       "      <td>0.937859</td>\n",
       "      <td>0.864898</td>\n",
       "      <td>0.936419</td>\n",
       "      <td>0.992092</td>\n",
       "      <td>0.945816</td>\n",
       "      <td>0.048051</td>\n",
       "      <td>52</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.877241</td>\n",
       "      <td>0.776190</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.946545</td>\n",
       "      <td>0.884776</td>\n",
       "      <td>0.066733</td>\n",
       "      <td>51</td>\n",
       "      <td>0.997326</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.742597</td>\n",
       "      <td>0.880364</td>\n",
       "      <td>0.993160</td>\n",
       "      <td>0.918986</td>\n",
       "      <td>0.098132</td>\n",
       "      <td>53</td>\n",
       "      <td>0.930175</td>\n",
       "      <td>0.793017</td>\n",
       "      <td>0.812968</td>\n",
       "      <td>0.843088</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>0.856672</td>\n",
       "      <td>0.052535</td>\n",
       "      <td>47</td>\n",
       "      <td>0.963750</td>\n",
       "      <td>0.888750</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.863750</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.070889</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.500939</td>\n",
       "      <td>0.112894</td>\n",
       "      <td>0.341389</td>\n",
       "      <td>0.025788</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.995958</td>\n",
       "      <td>0.973787</td>\n",
       "      <td>0.937271</td>\n",
       "      <td>0.951004</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>0.970847</td>\n",
       "      <td>0.023680</td>\n",
       "      <td>48</td>\n",
       "      <td>0.951697</td>\n",
       "      <td>0.917925</td>\n",
       "      <td>0.884049</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.959223</td>\n",
       "      <td>0.920357</td>\n",
       "      <td>0.031007</td>\n",
       "      <td>39</td>\n",
       "      <td>0.998630</td>\n",
       "      <td>0.969487</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.912189</td>\n",
       "      <td>0.998652</td>\n",
       "      <td>0.957610</td>\n",
       "      <td>0.039813</td>\n",
       "      <td>43</td>\n",
       "      <td>0.908978</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.866750</td>\n",
       "      <td>0.922790</td>\n",
       "      <td>0.886087</td>\n",
       "      <td>0.024973</td>\n",
       "      <td>22</td>\n",
       "      <td>0.953750</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.886875</td>\n",
       "      <td>0.891250</td>\n",
       "      <td>0.960625</td>\n",
       "      <td>0.922875</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.677383</td>\n",
       "      <td>0.018377</td>\n",
       "      <td>0.151505</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.988191</td>\n",
       "      <td>0.976401</td>\n",
       "      <td>0.957987</td>\n",
       "      <td>0.994645</td>\n",
       "      <td>0.988655</td>\n",
       "      <td>0.981176</td>\n",
       "      <td>0.013016</td>\n",
       "      <td>39</td>\n",
       "      <td>0.928524</td>\n",
       "      <td>0.890261</td>\n",
       "      <td>0.907483</td>\n",
       "      <td>0.929333</td>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.917290</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>45</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989329</td>\n",
       "      <td>0.998503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>0.997281</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>33</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.809227</td>\n",
       "      <td>0.831671</td>\n",
       "      <td>0.867995</td>\n",
       "      <td>0.871731</td>\n",
       "      <td>0.849441</td>\n",
       "      <td>0.024771</td>\n",
       "      <td>51</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.933750</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.923375</td>\n",
       "      <td>0.013816</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.570995</td>\n",
       "      <td>0.046298</td>\n",
       "      <td>0.320003</td>\n",
       "      <td>0.016642</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.986056</td>\n",
       "      <td>0.988398</td>\n",
       "      <td>0.990698</td>\n",
       "      <td>0.993389</td>\n",
       "      <td>0.995716</td>\n",
       "      <td>0.990851</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>27</td>\n",
       "      <td>0.937044</td>\n",
       "      <td>0.933599</td>\n",
       "      <td>0.926372</td>\n",
       "      <td>0.935719</td>\n",
       "      <td>0.946194</td>\n",
       "      <td>0.935786</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>15</td>\n",
       "      <td>0.881546</td>\n",
       "      <td>0.876559</td>\n",
       "      <td>0.862843</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.897883</td>\n",
       "      <td>0.879607</td>\n",
       "      <td>0.011209</td>\n",
       "      <td>36</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>0.939500</td>\n",
       "      <td>0.005637</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.685977</td>\n",
       "      <td>0.017224</td>\n",
       "      <td>0.154904</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.988191</td>\n",
       "      <td>0.976401</td>\n",
       "      <td>0.957987</td>\n",
       "      <td>0.994645</td>\n",
       "      <td>0.988655</td>\n",
       "      <td>0.981176</td>\n",
       "      <td>0.013016</td>\n",
       "      <td>39</td>\n",
       "      <td>0.928524</td>\n",
       "      <td>0.890261</td>\n",
       "      <td>0.907483</td>\n",
       "      <td>0.929333</td>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.917290</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>45</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989329</td>\n",
       "      <td>0.998503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>0.997281</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>33</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>0.809227</td>\n",
       "      <td>0.831671</td>\n",
       "      <td>0.867995</td>\n",
       "      <td>0.871731</td>\n",
       "      <td>0.849441</td>\n",
       "      <td>0.024771</td>\n",
       "      <td>51</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.933750</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.923375</td>\n",
       "      <td>0.013816</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.545644</td>\n",
       "      <td>0.027944</td>\n",
       "      <td>0.312206</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.986056</td>\n",
       "      <td>0.988398</td>\n",
       "      <td>0.990698</td>\n",
       "      <td>0.993389</td>\n",
       "      <td>0.995716</td>\n",
       "      <td>0.990851</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>27</td>\n",
       "      <td>0.937044</td>\n",
       "      <td>0.933599</td>\n",
       "      <td>0.926372</td>\n",
       "      <td>0.935719</td>\n",
       "      <td>0.946194</td>\n",
       "      <td>0.935786</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>15</td>\n",
       "      <td>0.881546</td>\n",
       "      <td>0.876559</td>\n",
       "      <td>0.862843</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.897883</td>\n",
       "      <td>0.879607</td>\n",
       "      <td>0.011209</td>\n",
       "      <td>36</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>0.939500</td>\n",
       "      <td>0.005637</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.587438</td>\n",
       "      <td>0.027137</td>\n",
       "      <td>0.140712</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.988137</td>\n",
       "      <td>0.893336</td>\n",
       "      <td>0.823493</td>\n",
       "      <td>0.944857</td>\n",
       "      <td>0.986144</td>\n",
       "      <td>0.927194</td>\n",
       "      <td>0.062292</td>\n",
       "      <td>59</td>\n",
       "      <td>0.946475</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.718064</td>\n",
       "      <td>0.869084</td>\n",
       "      <td>0.927056</td>\n",
       "      <td>0.858252</td>\n",
       "      <td>0.081306</td>\n",
       "      <td>59</td>\n",
       "      <td>0.993151</td>\n",
       "      <td>0.927692</td>\n",
       "      <td>0.654359</td>\n",
       "      <td>0.858010</td>\n",
       "      <td>0.991489</td>\n",
       "      <td>0.884940</td>\n",
       "      <td>0.125525</td>\n",
       "      <td>59</td>\n",
       "      <td>0.903990</td>\n",
       "      <td>0.751870</td>\n",
       "      <td>0.795511</td>\n",
       "      <td>0.880448</td>\n",
       "      <td>0.870486</td>\n",
       "      <td>0.840461</td>\n",
       "      <td>0.057280</td>\n",
       "      <td>58</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>0.846250</td>\n",
       "      <td>0.686875</td>\n",
       "      <td>0.866875</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.092824</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.336574</td>\n",
       "      <td>0.050304</td>\n",
       "      <td>0.303212</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.993606</td>\n",
       "      <td>0.938986</td>\n",
       "      <td>0.926251</td>\n",
       "      <td>0.979589</td>\n",
       "      <td>0.993714</td>\n",
       "      <td>0.966429</td>\n",
       "      <td>0.028368</td>\n",
       "      <td>50</td>\n",
       "      <td>0.942105</td>\n",
       "      <td>0.874189</td>\n",
       "      <td>0.853432</td>\n",
       "      <td>0.937659</td>\n",
       "      <td>0.959381</td>\n",
       "      <td>0.913353</td>\n",
       "      <td>0.041618</td>\n",
       "      <td>49</td>\n",
       "      <td>0.997214</td>\n",
       "      <td>0.910811</td>\n",
       "      <td>0.846626</td>\n",
       "      <td>0.958388</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.941538</td>\n",
       "      <td>0.056846</td>\n",
       "      <td>50</td>\n",
       "      <td>0.892768</td>\n",
       "      <td>0.840399</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.926526</td>\n",
       "      <td>0.887570</td>\n",
       "      <td>0.032939</td>\n",
       "      <td>11</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.878750</td>\n",
       "      <td>0.851875</td>\n",
       "      <td>0.938750</td>\n",
       "      <td>0.960625</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.042058</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.704365</td>\n",
       "      <td>0.033580</td>\n",
       "      <td>0.148907</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.990881</td>\n",
       "      <td>0.991719</td>\n",
       "      <td>0.956975</td>\n",
       "      <td>0.991845</td>\n",
       "      <td>0.996423</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>0.014428</td>\n",
       "      <td>35</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.917790</td>\n",
       "      <td>0.906993</td>\n",
       "      <td>0.927904</td>\n",
       "      <td>0.935719</td>\n",
       "      <td>0.925231</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998534</td>\n",
       "      <td>0.995529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998813</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>27</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.849127</td>\n",
       "      <td>0.832918</td>\n",
       "      <td>0.865504</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.861909</td>\n",
       "      <td>0.018719</td>\n",
       "      <td>43</td>\n",
       "      <td>0.941250</td>\n",
       "      <td>0.923750</td>\n",
       "      <td>0.914375</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.930250</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.626394</td>\n",
       "      <td>0.072866</td>\n",
       "      <td>0.340789</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.995777</td>\n",
       "      <td>0.992020</td>\n",
       "      <td>0.995464</td>\n",
       "      <td>0.997441</td>\n",
       "      <td>0.993557</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>13</td>\n",
       "      <td>0.935634</td>\n",
       "      <td>0.942650</td>\n",
       "      <td>0.929953</td>\n",
       "      <td>0.945574</td>\n",
       "      <td>0.944116</td>\n",
       "      <td>0.939585</td>\n",
       "      <td>0.005902</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>7</td>\n",
       "      <td>0.879052</td>\n",
       "      <td>0.891521</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>0.897883</td>\n",
       "      <td>0.894147</td>\n",
       "      <td>0.886336</td>\n",
       "      <td>0.010697</td>\n",
       "      <td>19</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.942875</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.728148</td>\n",
       "      <td>0.020583</td>\n",
       "      <td>0.160503</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.990881</td>\n",
       "      <td>0.991719</td>\n",
       "      <td>0.956975</td>\n",
       "      <td>0.991845</td>\n",
       "      <td>0.996423</td>\n",
       "      <td>0.985569</td>\n",
       "      <td>0.014428</td>\n",
       "      <td>35</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.917790</td>\n",
       "      <td>0.906993</td>\n",
       "      <td>0.927904</td>\n",
       "      <td>0.935719</td>\n",
       "      <td>0.925231</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998534</td>\n",
       "      <td>0.995529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998813</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>27</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.849127</td>\n",
       "      <td>0.832918</td>\n",
       "      <td>0.865504</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.861909</td>\n",
       "      <td>0.018719</td>\n",
       "      <td>43</td>\n",
       "      <td>0.941250</td>\n",
       "      <td>0.923750</td>\n",
       "      <td>0.914375</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.930250</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.593016</td>\n",
       "      <td>0.055836</td>\n",
       "      <td>0.345986</td>\n",
       "      <td>0.067265</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.987086</td>\n",
       "      <td>0.995777</td>\n",
       "      <td>0.992020</td>\n",
       "      <td>0.995464</td>\n",
       "      <td>0.997441</td>\n",
       "      <td>0.993557</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>13</td>\n",
       "      <td>0.935634</td>\n",
       "      <td>0.942650</td>\n",
       "      <td>0.929953</td>\n",
       "      <td>0.945574</td>\n",
       "      <td>0.944116</td>\n",
       "      <td>0.939585</td>\n",
       "      <td>0.005902</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>7</td>\n",
       "      <td>0.879052</td>\n",
       "      <td>0.891521</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>0.897883</td>\n",
       "      <td>0.894147</td>\n",
       "      <td>0.886336</td>\n",
       "      <td>0.010697</td>\n",
       "      <td>19</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.942875</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.614022</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.146710</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.982055</td>\n",
       "      <td>0.956186</td>\n",
       "      <td>0.826208</td>\n",
       "      <td>0.954634</td>\n",
       "      <td>0.985374</td>\n",
       "      <td>0.940891</td>\n",
       "      <td>0.058734</td>\n",
       "      <td>53</td>\n",
       "      <td>0.933862</td>\n",
       "      <td>0.878285</td>\n",
       "      <td>0.723692</td>\n",
       "      <td>0.902139</td>\n",
       "      <td>0.928904</td>\n",
       "      <td>0.873376</td>\n",
       "      <td>0.077458</td>\n",
       "      <td>56</td>\n",
       "      <td>0.994366</td>\n",
       "      <td>0.986025</td>\n",
       "      <td>0.659487</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.915229</td>\n",
       "      <td>0.129460</td>\n",
       "      <td>55</td>\n",
       "      <td>0.880299</td>\n",
       "      <td>0.791771</td>\n",
       "      <td>0.801746</td>\n",
       "      <td>0.866750</td>\n",
       "      <td>0.870486</td>\n",
       "      <td>0.842210</td>\n",
       "      <td>0.037507</td>\n",
       "      <td>55</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.693125</td>\n",
       "      <td>0.905625</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>0.091079</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.342570</td>\n",
       "      <td>0.031328</td>\n",
       "      <td>0.308608</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.990294</td>\n",
       "      <td>0.964745</td>\n",
       "      <td>0.925234</td>\n",
       "      <td>0.981508</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.971144</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>47</td>\n",
       "      <td>0.933775</td>\n",
       "      <td>0.899609</td>\n",
       "      <td>0.857858</td>\n",
       "      <td>0.934017</td>\n",
       "      <td>0.954486</td>\n",
       "      <td>0.915949</td>\n",
       "      <td>0.033973</td>\n",
       "      <td>48</td>\n",
       "      <td>0.995763</td>\n",
       "      <td>0.942623</td>\n",
       "      <td>0.861635</td>\n",
       "      <td>0.961741</td>\n",
       "      <td>0.998639</td>\n",
       "      <td>0.952080</td>\n",
       "      <td>0.049878</td>\n",
       "      <td>48</td>\n",
       "      <td>0.879052</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.854115</td>\n",
       "      <td>0.907846</td>\n",
       "      <td>0.914072</td>\n",
       "      <td>0.883087</td>\n",
       "      <td>0.024272</td>\n",
       "      <td>28</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.858125</td>\n",
       "      <td>0.935625</td>\n",
       "      <td>0.956250</td>\n",
       "      <td>0.918250</td>\n",
       "      <td>0.034472</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.762328</td>\n",
       "      <td>0.012362</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.010869</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.995898</td>\n",
       "      <td>0.994086</td>\n",
       "      <td>0.971212</td>\n",
       "      <td>0.995608</td>\n",
       "      <td>0.997247</td>\n",
       "      <td>0.990810</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>29</td>\n",
       "      <td>0.944042</td>\n",
       "      <td>0.932091</td>\n",
       "      <td>0.901505</td>\n",
       "      <td>0.940633</td>\n",
       "      <td>0.945502</td>\n",
       "      <td>0.932755</td>\n",
       "      <td>0.016303</td>\n",
       "      <td>31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999697</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>17</td>\n",
       "      <td>0.894015</td>\n",
       "      <td>0.872818</td>\n",
       "      <td>0.821696</td>\n",
       "      <td>0.887920</td>\n",
       "      <td>0.896638</td>\n",
       "      <td>0.874617</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>41</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.014117</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.784296</td>\n",
       "      <td>0.046253</td>\n",
       "      <td>0.348185</td>\n",
       "      <td>0.023840</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.990002</td>\n",
       "      <td>0.994461</td>\n",
       "      <td>0.993748</td>\n",
       "      <td>0.993714</td>\n",
       "      <td>0.998755</td>\n",
       "      <td>0.994136</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>11</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.941953</td>\n",
       "      <td>0.929953</td>\n",
       "      <td>0.937211</td>\n",
       "      <td>0.946885</td>\n",
       "      <td>0.938750</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>9</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.890274</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>0.882939</td>\n",
       "      <td>0.899128</td>\n",
       "      <td>0.884842</td>\n",
       "      <td>0.009899</td>\n",
       "      <td>26</td>\n",
       "      <td>0.941250</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.949375</td>\n",
       "      <td>0.942125</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.769724</td>\n",
       "      <td>0.028606</td>\n",
       "      <td>0.155304</td>\n",
       "      <td>0.007140</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.995898</td>\n",
       "      <td>0.994086</td>\n",
       "      <td>0.971212</td>\n",
       "      <td>0.995608</td>\n",
       "      <td>0.997247</td>\n",
       "      <td>0.990810</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>29</td>\n",
       "      <td>0.944042</td>\n",
       "      <td>0.932091</td>\n",
       "      <td>0.901505</td>\n",
       "      <td>0.940633</td>\n",
       "      <td>0.945502</td>\n",
       "      <td>0.932755</td>\n",
       "      <td>0.016303</td>\n",
       "      <td>31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999697</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>17</td>\n",
       "      <td>0.894015</td>\n",
       "      <td>0.872818</td>\n",
       "      <td>0.821696</td>\n",
       "      <td>0.887920</td>\n",
       "      <td>0.896638</td>\n",
       "      <td>0.874617</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>41</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.014117</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.735927</td>\n",
       "      <td>0.036090</td>\n",
       "      <td>0.325798</td>\n",
       "      <td>0.023130</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.990002</td>\n",
       "      <td>0.994461</td>\n",
       "      <td>0.993748</td>\n",
       "      <td>0.993714</td>\n",
       "      <td>0.998755</td>\n",
       "      <td>0.994136</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>11</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.941953</td>\n",
       "      <td>0.929953</td>\n",
       "      <td>0.937211</td>\n",
       "      <td>0.946885</td>\n",
       "      <td>0.938750</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>9</td>\n",
       "      <td>0.882793</td>\n",
       "      <td>0.890274</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>0.882939</td>\n",
       "      <td>0.899128</td>\n",
       "      <td>0.884842</td>\n",
       "      <td>0.009899</td>\n",
       "      <td>26</td>\n",
       "      <td>0.941250</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.949375</td>\n",
       "      <td>0.942125</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.583440</td>\n",
       "      <td>0.006238</td>\n",
       "      <td>0.142911</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.989361</td>\n",
       "      <td>0.900243</td>\n",
       "      <td>0.815711</td>\n",
       "      <td>0.949696</td>\n",
       "      <td>0.983704</td>\n",
       "      <td>0.927743</td>\n",
       "      <td>0.064370</td>\n",
       "      <td>57</td>\n",
       "      <td>0.939869</td>\n",
       "      <td>0.831834</td>\n",
       "      <td>0.716939</td>\n",
       "      <td>0.895561</td>\n",
       "      <td>0.931398</td>\n",
       "      <td>0.863120</td>\n",
       "      <td>0.082405</td>\n",
       "      <td>58</td>\n",
       "      <td>0.987637</td>\n",
       "      <td>0.934681</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.941015</td>\n",
       "      <td>0.990182</td>\n",
       "      <td>0.901370</td>\n",
       "      <td>0.126122</td>\n",
       "      <td>58</td>\n",
       "      <td>0.896509</td>\n",
       "      <td>0.749377</td>\n",
       "      <td>0.794264</td>\n",
       "      <td>0.854296</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0.834730</td>\n",
       "      <td>0.054954</td>\n",
       "      <td>60</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.848125</td>\n",
       "      <td>0.685625</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.862250</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.320384</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>0.306610</td>\n",
       "      <td>0.006819</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.992861</td>\n",
       "      <td>0.970215</td>\n",
       "      <td>0.930879</td>\n",
       "      <td>0.977150</td>\n",
       "      <td>0.995573</td>\n",
       "      <td>0.973336</td>\n",
       "      <td>0.023249</td>\n",
       "      <td>42</td>\n",
       "      <td>0.937294</td>\n",
       "      <td>0.906391</td>\n",
       "      <td>0.866834</td>\n",
       "      <td>0.929073</td>\n",
       "      <td>0.959223</td>\n",
       "      <td>0.919763</td>\n",
       "      <td>0.031405</td>\n",
       "      <td>40</td>\n",
       "      <td>0.995792</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.954068</td>\n",
       "      <td>0.998652</td>\n",
       "      <td>0.952338</td>\n",
       "      <td>0.045657</td>\n",
       "      <td>47</td>\n",
       "      <td>0.885287</td>\n",
       "      <td>0.875312</td>\n",
       "      <td>0.860349</td>\n",
       "      <td>0.905355</td>\n",
       "      <td>0.922790</td>\n",
       "      <td>0.889818</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>10</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.930625</td>\n",
       "      <td>0.960625</td>\n",
       "      <td>0.921750</td>\n",
       "      <td>0.031757</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.742341</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>0.152106</td>\n",
       "      <td>0.004442</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.997781</td>\n",
       "      <td>0.995344</td>\n",
       "      <td>0.988041</td>\n",
       "      <td>0.997036</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>0.994612</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>9</td>\n",
       "      <td>0.944042</td>\n",
       "      <td>0.933687</td>\n",
       "      <td>0.919137</td>\n",
       "      <td>0.944116</td>\n",
       "      <td>0.944116</td>\n",
       "      <td>0.937020</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>21</td>\n",
       "      <td>0.894015</td>\n",
       "      <td>0.877805</td>\n",
       "      <td>0.850374</td>\n",
       "      <td>0.894147</td>\n",
       "      <td>0.894147</td>\n",
       "      <td>0.882098</td>\n",
       "      <td>0.017072</td>\n",
       "      <td>31</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.008615</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.754515</td>\n",
       "      <td>0.047562</td>\n",
       "      <td>0.329397</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.992808</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.996319</td>\n",
       "      <td>0.997356</td>\n",
       "      <td>0.997958</td>\n",
       "      <td>0.996014</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942650</td>\n",
       "      <td>0.942650</td>\n",
       "      <td>0.932091</td>\n",
       "      <td>0.950327</td>\n",
       "      <td>0.947575</td>\n",
       "      <td>0.943059</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.891521</td>\n",
       "      <td>0.891521</td>\n",
       "      <td>0.872818</td>\n",
       "      <td>0.905355</td>\n",
       "      <td>0.900374</td>\n",
       "      <td>0.892318</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>7</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.756533</td>\n",
       "      <td>0.019998</td>\n",
       "      <td>0.153704</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.997781</td>\n",
       "      <td>0.995344</td>\n",
       "      <td>0.988041</td>\n",
       "      <td>0.997036</td>\n",
       "      <td>0.994859</td>\n",
       "      <td>0.994612</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>9</td>\n",
       "      <td>0.944042</td>\n",
       "      <td>0.933687</td>\n",
       "      <td>0.919137</td>\n",
       "      <td>0.944116</td>\n",
       "      <td>0.944116</td>\n",
       "      <td>0.937020</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>21</td>\n",
       "      <td>0.894015</td>\n",
       "      <td>0.877805</td>\n",
       "      <td>0.850374</td>\n",
       "      <td>0.894147</td>\n",
       "      <td>0.894147</td>\n",
       "      <td>0.882098</td>\n",
       "      <td>0.017072</td>\n",
       "      <td>31</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.008615</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2.072319</td>\n",
       "      <td>0.461072</td>\n",
       "      <td>0.329996</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.992808</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.996319</td>\n",
       "      <td>0.997356</td>\n",
       "      <td>0.997958</td>\n",
       "      <td>0.996014</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942650</td>\n",
       "      <td>0.942650</td>\n",
       "      <td>0.932091</td>\n",
       "      <td>0.950327</td>\n",
       "      <td>0.947575</td>\n",
       "      <td>0.943059</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.891521</td>\n",
       "      <td>0.891521</td>\n",
       "      <td>0.872818</td>\n",
       "      <td>0.905355</td>\n",
       "      <td>0.900374</td>\n",
       "      <td>0.892318</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>7</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.611622</td>\n",
       "      <td>0.023557</td>\n",
       "      <td>0.149307</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.991878</td>\n",
       "      <td>0.906834</td>\n",
       "      <td>0.864630</td>\n",
       "      <td>0.948302</td>\n",
       "      <td>0.984678</td>\n",
       "      <td>0.939265</td>\n",
       "      <td>0.048030</td>\n",
       "      <td>55</td>\n",
       "      <td>0.945525</td>\n",
       "      <td>0.858127</td>\n",
       "      <td>0.774665</td>\n",
       "      <td>0.883842</td>\n",
       "      <td>0.928666</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.060388</td>\n",
       "      <td>53</td>\n",
       "      <td>0.985135</td>\n",
       "      <td>0.958462</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.988748</td>\n",
       "      <td>0.922450</td>\n",
       "      <td>0.085963</td>\n",
       "      <td>52</td>\n",
       "      <td>0.908978</td>\n",
       "      <td>0.776808</td>\n",
       "      <td>0.793017</td>\n",
       "      <td>0.848070</td>\n",
       "      <td>0.875467</td>\n",
       "      <td>0.840468</td>\n",
       "      <td>0.049559</td>\n",
       "      <td>57</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.871250</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.888125</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.881625</td>\n",
       "      <td>0.062958</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.356961</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>0.318003</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.989842</td>\n",
       "      <td>0.977050</td>\n",
       "      <td>0.931759</td>\n",
       "      <td>0.962987</td>\n",
       "      <td>0.995134</td>\n",
       "      <td>0.971354</td>\n",
       "      <td>0.022705</td>\n",
       "      <td>46</td>\n",
       "      <td>0.935099</td>\n",
       "      <td>0.920656</td>\n",
       "      <td>0.876448</td>\n",
       "      <td>0.905950</td>\n",
       "      <td>0.950392</td>\n",
       "      <td>0.917709</td>\n",
       "      <td>0.025377</td>\n",
       "      <td>44</td>\n",
       "      <td>0.997175</td>\n",
       "      <td>0.970954</td>\n",
       "      <td>0.905585</td>\n",
       "      <td>0.931579</td>\n",
       "      <td>0.998628</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.036769</td>\n",
       "      <td>41</td>\n",
       "      <td>0.880299</td>\n",
       "      <td>0.875312</td>\n",
       "      <td>0.849127</td>\n",
       "      <td>0.881694</td>\n",
       "      <td>0.906600</td>\n",
       "      <td>0.878606</td>\n",
       "      <td>0.018308</td>\n",
       "      <td>38</td>\n",
       "      <td>0.938750</td>\n",
       "      <td>0.924375</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.908125</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.920750</td>\n",
       "      <td>0.025160</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.854395</td>\n",
       "      <td>0.064728</td>\n",
       "      <td>0.155305</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.994475</td>\n",
       "      <td>0.995398</td>\n",
       "      <td>0.981034</td>\n",
       "      <td>0.998502</td>\n",
       "      <td>0.997889</td>\n",
       "      <td>0.993460</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>15</td>\n",
       "      <td>0.944737</td>\n",
       "      <td>0.936424</td>\n",
       "      <td>0.917172</td>\n",
       "      <td>0.953746</td>\n",
       "      <td>0.945502</td>\n",
       "      <td>0.939516</td>\n",
       "      <td>0.012445</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.997072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>25</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.881546</td>\n",
       "      <td>0.849127</td>\n",
       "      <td>0.911582</td>\n",
       "      <td>0.896638</td>\n",
       "      <td>0.886831</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>14</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.923125</td>\n",
       "      <td>0.955625</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.942875</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2.017821</td>\n",
       "      <td>0.135095</td>\n",
       "      <td>0.358180</td>\n",
       "      <td>0.028608</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.992577</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.998031</td>\n",
       "      <td>0.998828</td>\n",
       "      <td>0.996159</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944737</td>\n",
       "      <td>0.940555</td>\n",
       "      <td>0.931379</td>\n",
       "      <td>0.955844</td>\n",
       "      <td>0.953064</td>\n",
       "      <td>0.945116</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>5</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.887781</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.916563</td>\n",
       "      <td>0.910336</td>\n",
       "      <td>0.896303</td>\n",
       "      <td>0.016080</td>\n",
       "      <td>3</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>0.935625</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.947875</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.825889</td>\n",
       "      <td>0.019167</td>\n",
       "      <td>0.168096</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.994475</td>\n",
       "      <td>0.995398</td>\n",
       "      <td>0.981034</td>\n",
       "      <td>0.998502</td>\n",
       "      <td>0.997889</td>\n",
       "      <td>0.993460</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>15</td>\n",
       "      <td>0.944737</td>\n",
       "      <td>0.936424</td>\n",
       "      <td>0.917172</td>\n",
       "      <td>0.953746</td>\n",
       "      <td>0.945502</td>\n",
       "      <td>0.939516</td>\n",
       "      <td>0.012445</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.997072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>25</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.881546</td>\n",
       "      <td>0.849127</td>\n",
       "      <td>0.911582</td>\n",
       "      <td>0.896638</td>\n",
       "      <td>0.886831</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>14</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.923125</td>\n",
       "      <td>0.955625</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.942875</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.867655</td>\n",
       "      <td>0.048330</td>\n",
       "      <td>0.346785</td>\n",
       "      <td>0.016349</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.992577</td>\n",
       "      <td>0.996586</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.998031</td>\n",
       "      <td>0.998828</td>\n",
       "      <td>0.996159</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944737</td>\n",
       "      <td>0.940555</td>\n",
       "      <td>0.931379</td>\n",
       "      <td>0.955844</td>\n",
       "      <td>0.953064</td>\n",
       "      <td>0.945116</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>5</td>\n",
       "      <td>0.895262</td>\n",
       "      <td>0.887781</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.916563</td>\n",
       "      <td>0.910336</td>\n",
       "      <td>0.896303</td>\n",
       "      <td>0.016080</td>\n",
       "      <td>3</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>0.935625</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.947875</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.623814</td>\n",
       "      <td>0.038898</td>\n",
       "      <td>0.152107</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.997317</td>\n",
       "      <td>0.935661</td>\n",
       "      <td>0.864997</td>\n",
       "      <td>0.940310</td>\n",
       "      <td>0.992045</td>\n",
       "      <td>0.946066</td>\n",
       "      <td>0.047863</td>\n",
       "      <td>51</td>\n",
       "      <td>0.959897</td>\n",
       "      <td>0.874309</td>\n",
       "      <td>0.769593</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.942634</td>\n",
       "      <td>0.884287</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>52</td>\n",
       "      <td>0.997312</td>\n",
       "      <td>0.979876</td>\n",
       "      <td>0.729609</td>\n",
       "      <td>0.916780</td>\n",
       "      <td>0.989056</td>\n",
       "      <td>0.922527</td>\n",
       "      <td>0.100557</td>\n",
       "      <td>51</td>\n",
       "      <td>0.925187</td>\n",
       "      <td>0.789277</td>\n",
       "      <td>0.814214</td>\n",
       "      <td>0.836862</td>\n",
       "      <td>0.900374</td>\n",
       "      <td>0.853183</td>\n",
       "      <td>0.051537</td>\n",
       "      <td>48</td>\n",
       "      <td>0.961250</td>\n",
       "      <td>0.886250</td>\n",
       "      <td>0.755625</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.885625</td>\n",
       "      <td>0.072355</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.499872</td>\n",
       "      <td>0.076769</td>\n",
       "      <td>0.341188</td>\n",
       "      <td>0.028810</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.994648</td>\n",
       "      <td>0.980095</td>\n",
       "      <td>0.931028</td>\n",
       "      <td>0.959574</td>\n",
       "      <td>0.996412</td>\n",
       "      <td>0.972352</td>\n",
       "      <td>0.024523</td>\n",
       "      <td>43</td>\n",
       "      <td>0.946194</td>\n",
       "      <td>0.923784</td>\n",
       "      <td>0.870722</td>\n",
       "      <td>0.901282</td>\n",
       "      <td>0.959897</td>\n",
       "      <td>0.920376</td>\n",
       "      <td>0.031844</td>\n",
       "      <td>38</td>\n",
       "      <td>0.998615</td>\n",
       "      <td>0.976389</td>\n",
       "      <td>0.885309</td>\n",
       "      <td>0.928666</td>\n",
       "      <td>0.998654</td>\n",
       "      <td>0.957527</td>\n",
       "      <td>0.044235</td>\n",
       "      <td>44</td>\n",
       "      <td>0.899002</td>\n",
       "      <td>0.876559</td>\n",
       "      <td>0.856608</td>\n",
       "      <td>0.875467</td>\n",
       "      <td>0.924035</td>\n",
       "      <td>0.886334</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>21</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.961250</td>\n",
       "      <td>0.922750</td>\n",
       "      <td>0.031834</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.642004      0.021440         0.141113        0.002710   \n",
       "1        1.484060      0.047302         0.296817        0.003031   \n",
       "2        0.632010      0.010124         0.143510        0.005347   \n",
       "3        1.436512      0.016220         0.299215        0.003320   \n",
       "4        0.554304      0.007026         0.139913        0.004425   \n",
       "5        1.273214      0.014287         0.335192        0.084821   \n",
       "6        0.659393      0.006043         0.144110        0.003122   \n",
       "7        1.600810      0.085273         0.314406        0.015046   \n",
       "8        0.684377      0.027159         0.151107        0.006672   \n",
       "9        1.587619      0.071753         0.310408        0.007859   \n",
       "10       0.575045      0.012380         0.143711        0.003706   \n",
       "11       1.387562      0.118516         0.299815        0.004241   \n",
       "12       0.696369      0.009862         0.147709        0.003653   \n",
       "13       1.658405      0.018582         0.329995        0.033584   \n",
       "14       0.715393      0.027178         0.150706        0.002398   \n",
       "15       1.665844      0.058526         0.318358        0.019085   \n",
       "16       0.600229      0.023858         0.145110        0.003967   \n",
       "17       1.405132      0.059735         0.321201        0.013507   \n",
       "18       0.739143      0.005040         0.149508        0.001020   \n",
       "19       1.762312      0.027679         0.319401        0.004628   \n",
       "20       0.747139      0.005496         0.156902        0.009852   \n",
       "21       1.761710      0.057063         0.374169        0.079850   \n",
       "22       0.615020      0.015347         0.154105        0.005910   \n",
       "23       1.510265      0.066950         0.335593        0.019060   \n",
       "24       0.822691      0.026399         0.155305        0.004361   \n",
       "25       1.898672      0.056129         0.335392        0.005709   \n",
       "26       0.837575      0.036708         0.167858        0.022075   \n",
       "27       1.863345      0.068130         0.335392        0.013842   \n",
       "28       0.665790      0.064307         0.157901        0.008289   \n",
       "29       1.500939      0.112894         0.341389        0.025788   \n",
       "30       0.677383      0.018377         0.151505        0.012050   \n",
       "31       1.570995      0.046298         0.320003        0.016642   \n",
       "32       0.685977      0.017224         0.154904        0.008363   \n",
       "33       1.545644      0.027944         0.312206        0.007548   \n",
       "34       0.587438      0.027137         0.140712        0.002783   \n",
       "35       1.336574      0.050304         0.303212        0.006883   \n",
       "36       0.704365      0.033580         0.148907        0.003577   \n",
       "37       1.626394      0.072866         0.340789        0.043478   \n",
       "38       0.728148      0.020583         0.160503        0.013270   \n",
       "39       1.593016      0.055836         0.345986        0.067265   \n",
       "40       0.614022      0.016148         0.146710        0.004167   \n",
       "41       1.342570      0.031328         0.308608        0.003707   \n",
       "42       0.762328      0.012362         0.162300        0.010869   \n",
       "43       1.784296      0.046253         0.348185        0.023840   \n",
       "44       0.769724      0.028606         0.155304        0.007140   \n",
       "45       1.735927      0.036090         0.325798        0.023130   \n",
       "46       0.583440      0.006238         0.142911        0.004333   \n",
       "47       1.320384      0.017244         0.306610        0.006819   \n",
       "48       0.742341      0.005806         0.152106        0.004442   \n",
       "49       1.754515      0.047562         0.329397        0.008796   \n",
       "50       0.756533      0.019998         0.153704        0.004487   \n",
       "51       2.072319      0.461072         0.329996        0.009511   \n",
       "52       0.611622      0.023557         0.149307        0.006525   \n",
       "53       1.356961      0.009981         0.318003        0.009125   \n",
       "54       0.854395      0.064728         0.155305        0.003070   \n",
       "55       2.017821      0.135095         0.358180        0.028608   \n",
       "56       0.825889      0.019167         0.168096        0.006141   \n",
       "57       1.867655      0.048330         0.346785        0.016349   \n",
       "58       0.623814      0.038898         0.152107        0.008029   \n",
       "59       1.499872      0.076769         0.341188        0.028810   \n",
       "\n",
       "   param_classifier__criterion param_classifier__max_depth  \\\n",
       "0                         gini                           4   \n",
       "1                         gini                           4   \n",
       "2                         gini                           4   \n",
       "3                         gini                           4   \n",
       "4                         gini                           4   \n",
       "5                         gini                           4   \n",
       "6                         gini                           5   \n",
       "7                         gini                           5   \n",
       "8                         gini                           5   \n",
       "9                         gini                           5   \n",
       "10                        gini                           5   \n",
       "11                        gini                           5   \n",
       "12                        gini                           6   \n",
       "13                        gini                           6   \n",
       "14                        gini                           6   \n",
       "15                        gini                           6   \n",
       "16                        gini                           6   \n",
       "17                        gini                           6   \n",
       "18                        gini                           7   \n",
       "19                        gini                           7   \n",
       "20                        gini                           7   \n",
       "21                        gini                           7   \n",
       "22                        gini                           7   \n",
       "23                        gini                           7   \n",
       "24                        gini                           8   \n",
       "25                        gini                           8   \n",
       "26                        gini                           8   \n",
       "27                        gini                           8   \n",
       "28                        gini                           8   \n",
       "29                        gini                           8   \n",
       "30                     entropy                           4   \n",
       "31                     entropy                           4   \n",
       "32                     entropy                           4   \n",
       "33                     entropy                           4   \n",
       "34                     entropy                           4   \n",
       "35                     entropy                           4   \n",
       "36                     entropy                           5   \n",
       "37                     entropy                           5   \n",
       "38                     entropy                           5   \n",
       "39                     entropy                           5   \n",
       "40                     entropy                           5   \n",
       "41                     entropy                           5   \n",
       "42                     entropy                           6   \n",
       "43                     entropy                           6   \n",
       "44                     entropy                           6   \n",
       "45                     entropy                           6   \n",
       "46                     entropy                           6   \n",
       "47                     entropy                           6   \n",
       "48                     entropy                           7   \n",
       "49                     entropy                           7   \n",
       "50                     entropy                           7   \n",
       "51                     entropy                           7   \n",
       "52                     entropy                           7   \n",
       "53                     entropy                           7   \n",
       "54                     entropy                           8   \n",
       "55                     entropy                           8   \n",
       "56                     entropy                           8   \n",
       "57                     entropy                           8   \n",
       "58                     entropy                           8   \n",
       "59                     entropy                           8   \n",
       "\n",
       "   param_classifier__max_features param_classifier__n_estimators  \\\n",
       "0                            auto                            200   \n",
       "1                            auto                            500   \n",
       "2                            sqrt                            200   \n",
       "3                            sqrt                            500   \n",
       "4                            log2                            200   \n",
       "5                            log2                            500   \n",
       "6                            auto                            200   \n",
       "7                            auto                            500   \n",
       "8                            sqrt                            200   \n",
       "9                            sqrt                            500   \n",
       "10                           log2                            200   \n",
       "11                           log2                            500   \n",
       "12                           auto                            200   \n",
       "13                           auto                            500   \n",
       "14                           sqrt                            200   \n",
       "15                           sqrt                            500   \n",
       "16                           log2                            200   \n",
       "17                           log2                            500   \n",
       "18                           auto                            200   \n",
       "19                           auto                            500   \n",
       "20                           sqrt                            200   \n",
       "21                           sqrt                            500   \n",
       "22                           log2                            200   \n",
       "23                           log2                            500   \n",
       "24                           auto                            200   \n",
       "25                           auto                            500   \n",
       "26                           sqrt                            200   \n",
       "27                           sqrt                            500   \n",
       "28                           log2                            200   \n",
       "29                           log2                            500   \n",
       "30                           auto                            200   \n",
       "31                           auto                            500   \n",
       "32                           sqrt                            200   \n",
       "33                           sqrt                            500   \n",
       "34                           log2                            200   \n",
       "35                           log2                            500   \n",
       "36                           auto                            200   \n",
       "37                           auto                            500   \n",
       "38                           sqrt                            200   \n",
       "39                           sqrt                            500   \n",
       "40                           log2                            200   \n",
       "41                           log2                            500   \n",
       "42                           auto                            200   \n",
       "43                           auto                            500   \n",
       "44                           sqrt                            200   \n",
       "45                           sqrt                            500   \n",
       "46                           log2                            200   \n",
       "47                           log2                            500   \n",
       "48                           auto                            200   \n",
       "49                           auto                            500   \n",
       "50                           sqrt                            200   \n",
       "51                           sqrt                            500   \n",
       "52                           log2                            200   \n",
       "53                           log2                            500   \n",
       "54                           auto                            200   \n",
       "55                           auto                            500   \n",
       "56                           sqrt                            200   \n",
       "57                           sqrt                            500   \n",
       "58                           log2                            200   \n",
       "59                           log2                            500   \n",
       "\n",
       "                                               params  split0_test_AUC  \\\n",
       "0   {'classifier__criterion': 'gini', 'classifier_...         0.986001   \n",
       "1   {'classifier__criterion': 'gini', 'classifier_...         0.985925   \n",
       "2   {'classifier__criterion': 'gini', 'classifier_...         0.986001   \n",
       "3   {'classifier__criterion': 'gini', 'classifier_...         0.985925   \n",
       "4   {'classifier__criterion': 'gini', 'classifier_...         0.988251   \n",
       "5   {'classifier__criterion': 'gini', 'classifier_...         0.993166   \n",
       "6   {'classifier__criterion': 'gini', 'classifier_...         0.990227   \n",
       "7   {'classifier__criterion': 'gini', 'classifier_...         0.986883   \n",
       "8   {'classifier__criterion': 'gini', 'classifier_...         0.990227   \n",
       "9   {'classifier__criterion': 'gini', 'classifier_...         0.986883   \n",
       "10  {'classifier__criterion': 'gini', 'classifier_...         0.981544   \n",
       "11  {'classifier__criterion': 'gini', 'classifier_...         0.989448   \n",
       "12  {'classifier__criterion': 'gini', 'classifier_...         0.993789   \n",
       "13  {'classifier__criterion': 'gini', 'classifier_...         0.989934   \n",
       "14  {'classifier__criterion': 'gini', 'classifier_...         0.993789   \n",
       "15  {'classifier__criterion': 'gini', 'classifier_...         0.989934   \n",
       "16  {'classifier__criterion': 'gini', 'classifier_...         0.988814   \n",
       "17  {'classifier__criterion': 'gini', 'classifier_...         0.991995   \n",
       "18  {'classifier__criterion': 'gini', 'classifier_...         0.994178   \n",
       "19  {'classifier__criterion': 'gini', 'classifier_...         0.993055   \n",
       "20  {'classifier__criterion': 'gini', 'classifier_...         0.994178   \n",
       "21  {'classifier__criterion': 'gini', 'classifier_...         0.993055   \n",
       "22  {'classifier__criterion': 'gini', 'classifier_...         0.993628   \n",
       "23  {'classifier__criterion': 'gini', 'classifier_...         0.992630   \n",
       "24  {'classifier__criterion': 'gini', 'classifier_...         0.994397   \n",
       "25  {'classifier__criterion': 'gini', 'classifier_...         0.993734   \n",
       "26  {'classifier__criterion': 'gini', 'classifier_...         0.994397   \n",
       "27  {'classifier__criterion': 'gini', 'classifier_...         0.993734   \n",
       "28  {'classifier__criterion': 'gini', 'classifier_...         0.997811   \n",
       "29  {'classifier__criterion': 'gini', 'classifier_...         0.995958   \n",
       "30  {'classifier__criterion': 'entropy', 'classifi...         0.988191   \n",
       "31  {'classifier__criterion': 'entropy', 'classifi...         0.986056   \n",
       "32  {'classifier__criterion': 'entropy', 'classifi...         0.988191   \n",
       "33  {'classifier__criterion': 'entropy', 'classifi...         0.986056   \n",
       "34  {'classifier__criterion': 'entropy', 'classifi...         0.988137   \n",
       "35  {'classifier__criterion': 'entropy', 'classifi...         0.993606   \n",
       "36  {'classifier__criterion': 'entropy', 'classifi...         0.990881   \n",
       "37  {'classifier__criterion': 'entropy', 'classifi...         0.987086   \n",
       "38  {'classifier__criterion': 'entropy', 'classifi...         0.990881   \n",
       "39  {'classifier__criterion': 'entropy', 'classifi...         0.987086   \n",
       "40  {'classifier__criterion': 'entropy', 'classifi...         0.982055   \n",
       "41  {'classifier__criterion': 'entropy', 'classifi...         0.990294   \n",
       "42  {'classifier__criterion': 'entropy', 'classifi...         0.995898   \n",
       "43  {'classifier__criterion': 'entropy', 'classifi...         0.990002   \n",
       "44  {'classifier__criterion': 'entropy', 'classifi...         0.995898   \n",
       "45  {'classifier__criterion': 'entropy', 'classifi...         0.990002   \n",
       "46  {'classifier__criterion': 'entropy', 'classifi...         0.989361   \n",
       "47  {'classifier__criterion': 'entropy', 'classifi...         0.992861   \n",
       "48  {'classifier__criterion': 'entropy', 'classifi...         0.997781   \n",
       "49  {'classifier__criterion': 'entropy', 'classifi...         0.992808   \n",
       "50  {'classifier__criterion': 'entropy', 'classifi...         0.997781   \n",
       "51  {'classifier__criterion': 'entropy', 'classifi...         0.992808   \n",
       "52  {'classifier__criterion': 'entropy', 'classifi...         0.991878   \n",
       "53  {'classifier__criterion': 'entropy', 'classifi...         0.989842   \n",
       "54  {'classifier__criterion': 'entropy', 'classifi...         0.994475   \n",
       "55  {'classifier__criterion': 'entropy', 'classifi...         0.992577   \n",
       "56  {'classifier__criterion': 'entropy', 'classifi...         0.994475   \n",
       "57  {'classifier__criterion': 'entropy', 'classifi...         0.992577   \n",
       "58  {'classifier__criterion': 'entropy', 'classifi...         0.997317   \n",
       "59  {'classifier__criterion': 'entropy', 'classifi...         0.994648   \n",
       "\n",
       "    split1_test_AUC  split2_test_AUC  split3_test_AUC  split4_test_AUC  \\\n",
       "0          0.978519         0.971115         0.990119         0.988328   \n",
       "1          0.992420         0.991777         0.991264         0.997383   \n",
       "2          0.978519         0.971115         0.990119         0.988328   \n",
       "3          0.992420         0.991777         0.991264         0.997383   \n",
       "4          0.891746         0.820532         0.941191         0.985712   \n",
       "5          0.938545         0.927973         0.980148         0.993070   \n",
       "6          0.983953         0.980247         0.990515         0.990937   \n",
       "7          0.993400         0.995227         0.994220         0.997428   \n",
       "8          0.983953         0.980247         0.990515         0.990937   \n",
       "9          0.993400         0.995227         0.994220         0.997428   \n",
       "10         0.953950         0.827882         0.952324         0.984440   \n",
       "11         0.963287         0.932286         0.981500         0.993276   \n",
       "12         0.987189         0.976917         0.989586         0.995256   \n",
       "13         0.993545         0.994162         0.989428         0.998977   \n",
       "14         0.987189         0.976917         0.989586         0.995256   \n",
       "15         0.993545         0.994162         0.989428         0.998977   \n",
       "16         0.900940         0.816572         0.949004         0.982628   \n",
       "17         0.967031         0.937109         0.977873         0.994917   \n",
       "18         0.989056         0.988111         0.996100         0.995692   \n",
       "19         0.994119         0.995606         0.997219         0.998798   \n",
       "20         0.989056         0.988111         0.996100         0.995692   \n",
       "21         0.994119         0.995606         0.997219         0.998798   \n",
       "22         0.906390         0.855901         0.948493         0.986229   \n",
       "23         0.969284         0.934351         0.965101         0.995780   \n",
       "24         0.986405         0.982886         0.998383         0.997556   \n",
       "25         0.995206         0.995186         0.997183         0.998984   \n",
       "26         0.986405         0.982886         0.998383         0.997556   \n",
       "27         0.995206         0.995186         0.997183         0.998984   \n",
       "28         0.937859         0.864898         0.936419         0.992092   \n",
       "29         0.973787         0.937271         0.951004         0.996214   \n",
       "30         0.976401         0.957987         0.994645         0.988655   \n",
       "31         0.988398         0.990698         0.993389         0.995716   \n",
       "32         0.976401         0.957987         0.994645         0.988655   \n",
       "33         0.988398         0.990698         0.993389         0.995716   \n",
       "34         0.893336         0.823493         0.944857         0.986144   \n",
       "35         0.938986         0.926251         0.979589         0.993714   \n",
       "36         0.991719         0.956975         0.991845         0.996423   \n",
       "37         0.995777         0.992020         0.995464         0.997441   \n",
       "38         0.991719         0.956975         0.991845         0.996423   \n",
       "39         0.995777         0.992020         0.995464         0.997441   \n",
       "40         0.956186         0.826208         0.954634         0.985374   \n",
       "41         0.964745         0.925234         0.981508         0.993939   \n",
       "42         0.994086         0.971212         0.995608         0.997247   \n",
       "43         0.994461         0.993748         0.993714         0.998755   \n",
       "44         0.994086         0.971212         0.995608         0.997247   \n",
       "45         0.994461         0.993748         0.993714         0.998755   \n",
       "46         0.900243         0.815711         0.949696         0.983704   \n",
       "47         0.970215         0.930879         0.977150         0.995573   \n",
       "48         0.995344         0.988041         0.997036         0.994859   \n",
       "49         0.995628         0.996319         0.997356         0.997958   \n",
       "50         0.995344         0.988041         0.997036         0.994859   \n",
       "51         0.995628         0.996319         0.997356         0.997958   \n",
       "52         0.906834         0.864630         0.948302         0.984678   \n",
       "53         0.977050         0.931759         0.962987         0.995134   \n",
       "54         0.995398         0.981034         0.998502         0.997889   \n",
       "55         0.996586         0.994775         0.998031         0.998828   \n",
       "56         0.995398         0.981034         0.998502         0.997889   \n",
       "57         0.996586         0.994775         0.998031         0.998828   \n",
       "58         0.935661         0.864997         0.940310         0.992045   \n",
       "59         0.980095         0.931028         0.959574         0.996412   \n",
       "\n",
       "    mean_test_AUC  std_test_AUC  rank_test_AUC  split0_test_F1  \\\n",
       "0        0.982816      0.007060             37        0.928524   \n",
       "1        0.991754      0.003643             25        0.936340   \n",
       "2        0.982816      0.007060             37        0.928524   \n",
       "3        0.991754      0.003643             25        0.936340   \n",
       "4        0.925487      0.063193             60        0.945170   \n",
       "5        0.966580      0.027818             49        0.940092   \n",
       "6        0.987176      0.004313             33        0.939153   \n",
       "7        0.993432      0.003541             17        0.938451   \n",
       "8        0.987176      0.004313             33        0.939153   \n",
       "9        0.993432      0.003541             17        0.938451   \n",
       "10       0.940028      0.057650             54        0.934653   \n",
       "11       0.971959      0.022363             44        0.931743   \n",
       "12       0.988547      0.006491             31        0.944737   \n",
       "13       0.993209      0.003444             19        0.939855   \n",
       "14       0.988547      0.006491             31        0.944737   \n",
       "15       0.993209      0.003444             19        0.939855   \n",
       "16       0.927592      0.063673             58        0.939176   \n",
       "17       0.973785      0.020908             41        0.938776   \n",
       "18       0.992627      0.003377             21        0.945502   \n",
       "19       0.995759      0.002069              7        0.941953   \n",
       "20       0.992627      0.003377             21        0.945502   \n",
       "21       0.995759      0.002069              7        0.941953   \n",
       "22       0.938128      0.051517             56        0.946209   \n",
       "23       0.971429      0.022189             45        0.938776   \n",
       "24       0.991925      0.006192             23        0.937748   \n",
       "25       0.996059      0.001828              3        0.941953   \n",
       "26       0.991925      0.006192             23        0.937748   \n",
       "27       0.996059      0.001828              3        0.941953   \n",
       "28       0.945816      0.048051             52        0.962581   \n",
       "29       0.970847      0.023680             48        0.951697   \n",
       "30       0.981176      0.013016             39        0.928524   \n",
       "31       0.990851      0.003439             27        0.937044   \n",
       "32       0.981176      0.013016             39        0.928524   \n",
       "33       0.990851      0.003439             27        0.937044   \n",
       "34       0.927194      0.062292             59        0.946475   \n",
       "35       0.966429      0.028368             50        0.942105   \n",
       "36       0.985569      0.014428             35        0.937748   \n",
       "37       0.993557      0.003685             13        0.935634   \n",
       "38       0.985569      0.014428             35        0.937748   \n",
       "39       0.993557      0.003685             13        0.935634   \n",
       "40       0.940891      0.058734             53        0.933862   \n",
       "41       0.971144      0.025070             47        0.933775   \n",
       "42       0.990810      0.009850             29        0.944042   \n",
       "43       0.994136      0.002788             11        0.937748   \n",
       "44       0.990810      0.009850             29        0.944042   \n",
       "45       0.994136      0.002788             11        0.937748   \n",
       "46       0.927743      0.064370             57        0.939869   \n",
       "47       0.973336      0.023249             42        0.937294   \n",
       "48       0.994612      0.003455              9        0.944042   \n",
       "49       0.996014      0.001795              5        0.942650   \n",
       "50       0.994612      0.003455              9        0.944042   \n",
       "51       0.996014      0.001795              5        0.942650   \n",
       "52       0.939265      0.048030             55        0.945525   \n",
       "53       0.971354      0.022705             46        0.935099   \n",
       "54       0.993460      0.006391             15        0.944737   \n",
       "55       0.996159      0.002261              1        0.944737   \n",
       "56       0.993460      0.006391             15        0.944737   \n",
       "57       0.996159      0.002261              1        0.944737   \n",
       "58       0.946066      0.047863             51        0.959897   \n",
       "59       0.972352      0.024523             43        0.946194   \n",
       "\n",
       "    split1_test_F1  split2_test_F1  split3_test_F1  split4_test_F1  \\\n",
       "0         0.904054        0.903623        0.925753        0.930851   \n",
       "1         0.935889        0.922767        0.935719        0.952381   \n",
       "2         0.904054        0.903623        0.925753        0.930851   \n",
       "3         0.935889        0.922767        0.935719        0.952381   \n",
       "4         0.830812        0.722128        0.861670        0.929186   \n",
       "5         0.870926        0.858736        0.933504        0.961340   \n",
       "6         0.911409        0.914015        0.925033        0.931652   \n",
       "7         0.939314        0.928524        0.944809        0.947575   \n",
       "8         0.911409        0.914015        0.925033        0.931652   \n",
       "9         0.939314        0.928524        0.944809        0.947575   \n",
       "10        0.880442        0.729025        0.897933        0.930417   \n",
       "11        0.897933        0.874289        0.932821        0.956634   \n",
       "12        0.926246        0.909708        0.941332        0.943495   \n",
       "13        0.937128        0.924933        0.937128        0.955107   \n",
       "14        0.926246        0.909708        0.941332        0.943495   \n",
       "15        0.937128        0.924933        0.937128        0.955107   \n",
       "16        0.837113        0.729977        0.890188        0.931398   \n",
       "17        0.905100        0.878421        0.930529        0.960569   \n",
       "18        0.926441        0.924212        0.938533        0.946335   \n",
       "19        0.937831        0.933511        0.948265        0.955107   \n",
       "20        0.926441        0.924212        0.938533        0.946335   \n",
       "21        0.937831        0.933511        0.948265        0.955107   \n",
       "22        0.859097        0.757808        0.879897        0.930784   \n",
       "23        0.914698        0.876276        0.905950        0.950327   \n",
       "24        0.933068        0.921529        0.957820        0.946194   \n",
       "25        0.942650        0.937044        0.952381        0.958495   \n",
       "26        0.933068        0.921529        0.957820        0.946194   \n",
       "27        0.942650        0.937044        0.952381        0.958495   \n",
       "28        0.877241        0.776190        0.861323        0.946545   \n",
       "29        0.917925        0.884049        0.888889        0.959223   \n",
       "30        0.890261        0.907483        0.929333        0.930851   \n",
       "31        0.933599        0.926372        0.935719        0.946194   \n",
       "32        0.890261        0.907483        0.929333        0.930851   \n",
       "33        0.933599        0.926372        0.935719        0.946194   \n",
       "34        0.830579        0.718064        0.869084        0.927056   \n",
       "35        0.874189        0.853432        0.937659        0.959381   \n",
       "36        0.917790        0.906993        0.927904        0.935719   \n",
       "37        0.942650        0.929953        0.945574        0.944116   \n",
       "38        0.917790        0.906993        0.927904        0.935719   \n",
       "39        0.942650        0.929953        0.945574        0.944116   \n",
       "40        0.878285        0.723692        0.902139        0.928904   \n",
       "41        0.899609        0.857858        0.934017        0.954486   \n",
       "42        0.932091        0.901505        0.940633        0.945502   \n",
       "43        0.941953        0.929953        0.937211        0.946885   \n",
       "44        0.932091        0.901505        0.940633        0.945502   \n",
       "45        0.941953        0.929953        0.937211        0.946885   \n",
       "46        0.831834        0.716939        0.895561        0.931398   \n",
       "47        0.906391        0.866834        0.929073        0.959223   \n",
       "48        0.933687        0.919137        0.944116        0.944116   \n",
       "49        0.942650        0.932091        0.950327        0.947575   \n",
       "50        0.933687        0.919137        0.944116        0.944116   \n",
       "51        0.942650        0.932091        0.950327        0.947575   \n",
       "52        0.858127        0.774665        0.883842        0.928666   \n",
       "53        0.920656        0.876448        0.905950        0.950392   \n",
       "54        0.936424        0.917172        0.953746        0.945502   \n",
       "55        0.940555        0.931379        0.955844        0.953064   \n",
       "56        0.936424        0.917172        0.953746        0.945502   \n",
       "57        0.940555        0.931379        0.955844        0.953064   \n",
       "58        0.874309        0.769593        0.875000        0.942634   \n",
       "59        0.923784        0.870722        0.901282        0.959897   \n",
       "\n",
       "    mean_test_F1  std_test_F1  rank_test_F1  split0_test_Precision  \\\n",
       "0       0.918561     0.012129            42               1.000000   \n",
       "1       0.936619     0.009399            23               1.000000   \n",
       "2       0.918561     0.012129            42               1.000000   \n",
       "3       0.936619     0.009399            23               1.000000   \n",
       "4       0.857793     0.079849            60               0.991781   \n",
       "5       0.912920     0.040512            50               0.995816   \n",
       "6       0.924253     0.010461            35               1.000000   \n",
       "7       0.939735     0.006553             9               1.000000   \n",
       "8       0.924253     0.010461            35               1.000000   \n",
       "9       0.939735     0.006553             9               1.000000   \n",
       "10      0.874494     0.075489            55               0.992987   \n",
       "11      0.918684     0.029025            41               0.994342   \n",
       "12      0.933104     0.013457            29               1.000000   \n",
       "13      0.938830     0.009643            17               1.000000   \n",
       "14      0.933104     0.013457            29               1.000000   \n",
       "15      0.938830     0.009643            17               1.000000   \n",
       "16      0.865571     0.076880            57               0.987620   \n",
       "17      0.922679     0.028369            37               0.994421   \n",
       "18      0.936205     0.009313            25               0.998613   \n",
       "19      0.943333     0.007637             5               1.000000   \n",
       "20      0.936205     0.009313            25               0.998613   \n",
       "21      0.943333     0.007637             5               1.000000   \n",
       "22      0.874759     0.066623            54               0.985155   \n",
       "23      0.917205     0.025964            47               0.994421   \n",
       "24      0.939272     0.012227            15               1.000000   \n",
       "25      0.946505     0.007790             1               1.000000   \n",
       "26      0.939272     0.012227            15               1.000000   \n",
       "27      0.946505     0.007790             1               1.000000   \n",
       "28      0.884776     0.066733            51               0.997326   \n",
       "29      0.920357     0.031007            39               0.998630   \n",
       "30      0.917290     0.016012            45               1.000000   \n",
       "31      0.935786     0.006377            27               1.000000   \n",
       "32      0.917290     0.016012            45               1.000000   \n",
       "33      0.935786     0.006377            27               1.000000   \n",
       "34      0.858252     0.081306            59               0.993151   \n",
       "35      0.913353     0.041618            49               0.997214   \n",
       "36      0.925231     0.011505            33               1.000000   \n",
       "37      0.939585     0.005902            11               1.000000   \n",
       "38      0.925231     0.011505            33               1.000000   \n",
       "39      0.939585     0.005902            11               1.000000   \n",
       "40      0.873376     0.077458            56               0.994366   \n",
       "41      0.915949     0.033973            48               0.995763   \n",
       "42      0.932755     0.016303            31               1.000000   \n",
       "43      0.938750     0.005607            19               1.000000   \n",
       "44      0.932755     0.016303            31               1.000000   \n",
       "45      0.938750     0.005607            19               1.000000   \n",
       "46      0.863120     0.082405            58               0.987637   \n",
       "47      0.919763     0.031405            40               0.995792   \n",
       "48      0.937020     0.009807            21               1.000000   \n",
       "49      0.943059     0.006227             7               1.000000   \n",
       "50      0.937020     0.009807            21               1.000000   \n",
       "51      0.943059     0.006227             7               1.000000   \n",
       "52      0.878165     0.060388            53               0.985135   \n",
       "53      0.917709     0.025377            44               0.997175   \n",
       "54      0.939516     0.012445            13               1.000000   \n",
       "55      0.945116     0.008808             3               1.000000   \n",
       "56      0.939516     0.012445            13               1.000000   \n",
       "57      0.945116     0.008808             3               1.000000   \n",
       "58      0.884287     0.067025            52               0.997312   \n",
       "59      0.920376     0.031844            38               0.998615   \n",
       "\n",
       "    split1_test_Precision  split2_test_Precision  split3_test_Precision  \\\n",
       "0                0.986726               1.000000               1.000000   \n",
       "1                0.995781               1.000000               1.000000   \n",
       "2                0.986726               1.000000               1.000000   \n",
       "3                0.995781               1.000000               1.000000   \n",
       "4                0.926380               0.661140               0.843675   \n",
       "5                0.912568               0.853448               0.959264   \n",
       "6                0.986919               1.000000               1.000000   \n",
       "7                0.997199               1.000000               1.000000   \n",
       "8                0.986919               1.000000               1.000000   \n",
       "9                0.997199               1.000000               1.000000   \n",
       "10               0.987597               0.668399               0.932886   \n",
       "11               0.931635               0.886044               0.959211   \n",
       "12               0.991465               0.998510               1.000000   \n",
       "13               0.998590               1.000000               1.000000   \n",
       "14               0.991465               0.998510               1.000000   \n",
       "15               0.998590               1.000000               1.000000   \n",
       "16               0.932619               0.674419               0.930707   \n",
       "17               0.938420               0.897269               0.953003   \n",
       "18               0.988685               1.000000               1.000000   \n",
       "19               0.998592               1.000000               1.000000   \n",
       "20               0.988685               1.000000               1.000000   \n",
       "21               0.998592               1.000000               1.000000   \n",
       "22               0.951515               0.718436               0.908488   \n",
       "23               0.965374               0.896867               0.931579   \n",
       "24               0.995757               0.997097               1.000000   \n",
       "25               1.000000               1.000000               1.000000   \n",
       "26               0.995757               0.997097               1.000000   \n",
       "27               1.000000               1.000000               1.000000   \n",
       "28               0.981481               0.742597               0.880364   \n",
       "29               0.969487               0.909091               0.912189   \n",
       "30               0.989329               0.998503               1.000000   \n",
       "31               0.998580               1.000000               1.000000   \n",
       "32               0.989329               0.998503               1.000000   \n",
       "33               0.998580               1.000000               1.000000   \n",
       "34               0.927692               0.654359               0.858010   \n",
       "35               0.910811               0.846626               0.958388   \n",
       "36               0.998534               0.995529               1.000000   \n",
       "37               1.000000               1.000000               0.998615   \n",
       "38               0.998534               0.995529               1.000000   \n",
       "39               1.000000               1.000000               0.998615   \n",
       "40               0.986025               0.659487               0.940541   \n",
       "41               0.942623               0.861635               0.961741   \n",
       "42               1.000000               0.998485               1.000000   \n",
       "43               1.000000               1.000000               0.998592   \n",
       "44               1.000000               0.998485               1.000000   \n",
       "45               1.000000               1.000000               0.998592   \n",
       "46               0.934681               0.653333               0.941015   \n",
       "47               0.939759               0.873418               0.954068   \n",
       "48               0.997167               1.000000               1.000000   \n",
       "49               1.000000               1.000000               1.000000   \n",
       "50               0.997167               1.000000               1.000000   \n",
       "51               1.000000               1.000000               1.000000   \n",
       "52               0.958462               0.757143               0.922764   \n",
       "53               0.970954               0.905585               0.931579   \n",
       "54               0.998588               0.997072               1.000000   \n",
       "55               1.000000               1.000000               0.998643   \n",
       "56               0.998588               0.997072               1.000000   \n",
       "57               1.000000               1.000000               0.998643   \n",
       "58               0.979876               0.729609               0.916780   \n",
       "59               0.976389               0.885309               0.928666   \n",
       "\n",
       "    split4_test_Precision  mean_test_Precision  std_test_Precision  \\\n",
       "0                0.998573             0.997060            0.005197   \n",
       "1                1.000000             0.999156            0.001688   \n",
       "2                0.998573             0.997060            0.005197   \n",
       "3                1.000000             0.999156            0.001688   \n",
       "4                0.991525             0.882900            0.123500   \n",
       "5                0.995995             0.943418            0.054419   \n",
       "6                0.997159             0.996816            0.005069   \n",
       "7                1.000000             0.999440            0.001120   \n",
       "8                0.997159             0.996816            0.005069   \n",
       "9                1.000000             0.999440            0.001120   \n",
       "10               0.994334             0.915241            0.125521   \n",
       "11               0.995957             0.953438            0.041308   \n",
       "12               0.998609             0.997717            0.003192   \n",
       "13               1.000000             0.999718            0.000564   \n",
       "14               0.998609             0.997717            0.003192   \n",
       "15               1.000000             0.999718            0.000564   \n",
       "16               0.990182             0.903109            0.117180   \n",
       "17               0.998656             0.956354            0.037583   \n",
       "18               0.997241             0.996908            0.004237   \n",
       "19               1.000000             0.999718            0.000563   \n",
       "20               0.997241             0.996908            0.004237   \n",
       "21               1.000000             0.999718            0.000563   \n",
       "22               0.988796             0.910478            0.100278   \n",
       "23               1.000000             0.957648            0.038935   \n",
       "24               1.000000             0.998571            0.001801   \n",
       "25               1.000000             1.000000            0.000000   \n",
       "26               1.000000             0.998571            0.001801   \n",
       "27               1.000000             1.000000            0.000000   \n",
       "28               0.993160             0.918986            0.098132   \n",
       "29               0.998652             0.957610            0.039813   \n",
       "30               0.998573             0.997281            0.004029   \n",
       "31               1.000000             0.999716            0.000568   \n",
       "32               0.998573             0.997281            0.004029   \n",
       "33               1.000000             0.999716            0.000568   \n",
       "34               0.991489             0.884940            0.125525   \n",
       "35               0.994652             0.941538            0.056846   \n",
       "36               1.000000             0.998813            0.001737   \n",
       "37               1.000000             0.999723            0.000554   \n",
       "38               1.000000             0.998813            0.001737   \n",
       "39               1.000000             0.999723            0.000554   \n",
       "40               0.995726             0.915229            0.129460   \n",
       "41               0.998639             0.952080            0.049878   \n",
       "42               1.000000             0.999697            0.000606   \n",
       "43               1.000000             0.999718            0.000563   \n",
       "44               1.000000             0.999697            0.000606   \n",
       "45               1.000000             0.999718            0.000563   \n",
       "46               0.990182             0.901370            0.126122   \n",
       "47               0.998652             0.952338            0.045657   \n",
       "48               1.000000             0.999433            0.001133   \n",
       "49               1.000000             1.000000            0.000000   \n",
       "50               1.000000             0.999433            0.001133   \n",
       "51               1.000000             1.000000            0.000000   \n",
       "52               0.988748             0.922450            0.085963   \n",
       "53               0.998628             0.960784            0.036769   \n",
       "54               1.000000             0.999132            0.001166   \n",
       "55               1.000000             0.999729            0.000543   \n",
       "56               1.000000             0.999132            0.001166   \n",
       "57               1.000000             0.999729            0.000543   \n",
       "58               0.989056             0.922527            0.100557   \n",
       "59               0.998654             0.957527            0.044235   \n",
       "\n",
       "    rank_test_Precision  split0_test_Recall  split1_test_Recall  \\\n",
       "0                    35            0.866584            0.834165   \n",
       "1                    23            0.880299            0.882793   \n",
       "2                    35            0.866584            0.834165   \n",
       "3                    23            0.880299            0.882793   \n",
       "4                    60            0.902743            0.753117   \n",
       "5                    49            0.890274            0.832918   \n",
       "6                    39            0.885287            0.846633   \n",
       "7                    19            0.884040            0.887781   \n",
       "8                    39            0.885287            0.846633   \n",
       "9                    19            0.884040            0.887781   \n",
       "10                   54            0.882793            0.794264   \n",
       "11                   46            0.876559            0.866584   \n",
       "12                   31            0.895262            0.869077   \n",
       "13                   13            0.886534            0.882793   \n",
       "14                   31            0.895262            0.869077   \n",
       "15                   13            0.886534            0.882793   \n",
       "16                   57            0.895262            0.759352   \n",
       "17                   45            0.889027            0.874065   \n",
       "18                   37            0.897756            0.871571   \n",
       "19                    9            0.890274            0.884040   \n",
       "20                   37            0.897756            0.871571   \n",
       "21                    9            0.890274            0.884040   \n",
       "22                   56            0.910224            0.783042   \n",
       "23                   42            0.889027            0.869077   \n",
       "24                   29            0.882793            0.877805   \n",
       "25                    1            0.890274            0.891521   \n",
       "26                   29            0.882793            0.877805   \n",
       "27                    1            0.890274            0.891521   \n",
       "28                   53            0.930175            0.793017   \n",
       "29                   43            0.908978            0.871571   \n",
       "30                   33            0.866584            0.809227   \n",
       "31                   15            0.881546            0.876559   \n",
       "32                   33            0.866584            0.809227   \n",
       "33                   15            0.881546            0.876559   \n",
       "34                   59            0.903990            0.751870   \n",
       "35                   50            0.892768            0.840399   \n",
       "36                   27            0.882793            0.849127   \n",
       "37                    7            0.879052            0.891521   \n",
       "38                   27            0.882793            0.849127   \n",
       "39                    7            0.879052            0.891521   \n",
       "40                   55            0.880299            0.791771   \n",
       "41                   48            0.879052            0.860349   \n",
       "42                   17            0.894015            0.872818   \n",
       "43                    9            0.882793            0.890274   \n",
       "44                   17            0.894015            0.872818   \n",
       "45                    9            0.882793            0.890274   \n",
       "46                   58            0.896509            0.749377   \n",
       "47                   47            0.885287            0.875312   \n",
       "48                   21            0.894015            0.877805   \n",
       "49                    1            0.891521            0.891521   \n",
       "50                   21            0.894015            0.877805   \n",
       "51                    1            0.891521            0.891521   \n",
       "52                   52            0.908978            0.776808   \n",
       "53                   41            0.880299            0.875312   \n",
       "54                   25            0.895262            0.881546   \n",
       "55                    5            0.895262            0.887781   \n",
       "56                   25            0.895262            0.881546   \n",
       "57                    5            0.895262            0.887781   \n",
       "58                   51            0.925187            0.789277   \n",
       "59                   44            0.899002            0.876559   \n",
       "\n",
       "    split2_test_Recall  split3_test_Recall  split4_test_Recall  \\\n",
       "0             0.824190            0.861768            0.871731   \n",
       "1             0.856608            0.879203            0.909091   \n",
       "2             0.824190            0.861768            0.871731   \n",
       "3             0.856608            0.879203            0.909091   \n",
       "4             0.795511            0.880448            0.874222   \n",
       "5             0.864090            0.909091            0.929016   \n",
       "6             0.841646            0.860523            0.874222   \n",
       "7             0.866584            0.895392            0.900374   \n",
       "8             0.841646            0.860523            0.874222   \n",
       "9             0.866584            0.895392            0.900374   \n",
       "10            0.801746            0.865504            0.874222   \n",
       "11            0.862843            0.907846            0.920299   \n",
       "12            0.835411            0.889166            0.894147   \n",
       "13            0.860349            0.881694            0.914072   \n",
       "14            0.835411            0.889166            0.894147   \n",
       "15            0.860349            0.881694            0.914072   \n",
       "16            0.795511            0.853051            0.879203   \n",
       "17            0.860349            0.909091            0.925280   \n",
       "18            0.859102            0.884184            0.900374   \n",
       "19            0.875312            0.901619            0.914072   \n",
       "20            0.859102            0.884184            0.900374   \n",
       "21            0.875312            0.901619            0.914072   \n",
       "22            0.801746            0.853051            0.879203   \n",
       "23            0.856608            0.881694            0.905355   \n",
       "24            0.856608            0.919054            0.897883   \n",
       "25            0.881546            0.909091            0.920299   \n",
       "26            0.856608            0.919054            0.897883   \n",
       "27            0.881546            0.909091            0.920299   \n",
       "28            0.812968            0.843088            0.904110   \n",
       "29            0.860349            0.866750            0.922790   \n",
       "30            0.831671            0.867995            0.871731   \n",
       "31            0.862843            0.879203            0.897883   \n",
       "32            0.831671            0.867995            0.871731   \n",
       "33            0.862843            0.879203            0.897883   \n",
       "34            0.795511            0.880448            0.870486   \n",
       "35            0.860349            0.917808            0.926526   \n",
       "36            0.832918            0.865504            0.879203   \n",
       "37            0.869077            0.897883            0.894147   \n",
       "38            0.832918            0.865504            0.879203   \n",
       "39            0.869077            0.897883            0.894147   \n",
       "40            0.801746            0.866750            0.870486   \n",
       "41            0.854115            0.907846            0.914072   \n",
       "42            0.821696            0.887920            0.896638   \n",
       "43            0.869077            0.882939            0.899128   \n",
       "44            0.821696            0.887920            0.896638   \n",
       "45            0.869077            0.882939            0.899128   \n",
       "46            0.794264            0.854296            0.879203   \n",
       "47            0.860349            0.905355            0.922790   \n",
       "48            0.850374            0.894147            0.894147   \n",
       "49            0.872818            0.905355            0.900374   \n",
       "50            0.850374            0.894147            0.894147   \n",
       "51            0.872818            0.905355            0.900374   \n",
       "52            0.793017            0.848070            0.875467   \n",
       "53            0.849127            0.881694            0.906600   \n",
       "54            0.849127            0.911582            0.896638   \n",
       "55            0.871571            0.916563            0.910336   \n",
       "56            0.849127            0.911582            0.896638   \n",
       "57            0.871571            0.916563            0.910336   \n",
       "58            0.814214            0.836862            0.900374   \n",
       "59            0.856608            0.875467            0.924035   \n",
       "\n",
       "    mean_test_Recall  std_test_Recall  rank_test_Recall  split0_test_Accuracy  \\\n",
       "0           0.851687         0.018913                49              0.933125   \n",
       "1           0.881599         0.016668                33              0.940000   \n",
       "2           0.851687         0.018913                49              0.933125   \n",
       "3           0.881599         0.016668                33              0.940000   \n",
       "4           0.841208         0.057034                56              0.947500   \n",
       "5           0.885078         0.033750                25              0.943125   \n",
       "6           0.861662         0.016393                45              0.942500   \n",
       "7           0.886834         0.011622                12              0.941875   \n",
       "8           0.861662         0.016393                45              0.942500   \n",
       "9           0.886834         0.011622                12              0.941875   \n",
       "10          0.843706         0.037787                54              0.938125   \n",
       "11          0.886826         0.023033                18              0.935625   \n",
       "12          0.876613         0.022659                39              0.947500   \n",
       "13          0.885088         0.017152                23              0.943125   \n",
       "14          0.876613         0.022659                39              0.947500   \n",
       "15          0.885088         0.017152                23              0.943125   \n",
       "16          0.836476         0.051347                59              0.941875   \n",
       "17          0.891563         0.023371                 9              0.941875   \n",
       "18          0.882597         0.015633                29              0.948125   \n",
       "19          0.893063         0.013556                 5              0.945000   \n",
       "20          0.882597         0.015633                29              0.948125   \n",
       "21          0.893063         0.013556                 5              0.945000   \n",
       "22          0.845453         0.047323                53              0.948125   \n",
       "23          0.880352         0.016692                35              0.941875   \n",
       "24          0.886829         0.020840                16              0.941250   \n",
       "25          0.898546         0.014079                 1              0.945000   \n",
       "26          0.886829         0.020840                16              0.941250   \n",
       "27          0.898546         0.014079                 1              0.945000   \n",
       "28          0.856672         0.052535                47              0.963750   \n",
       "29          0.886087         0.024973                22              0.953750   \n",
       "30          0.849441         0.024771                51              0.933125   \n",
       "31          0.879607         0.011209                36              0.940625   \n",
       "32          0.849441         0.024771                51              0.933125   \n",
       "33          0.879607         0.011209                36              0.940625   \n",
       "34          0.840461         0.057280                58              0.948750   \n",
       "35          0.887570         0.032939                11              0.945000   \n",
       "36          0.861909         0.018719                43              0.941250   \n",
       "37          0.886336         0.010697                19              0.939375   \n",
       "38          0.861909         0.018719                43              0.941250   \n",
       "39          0.886336         0.010697                19              0.939375   \n",
       "40          0.842210         0.037507                55              0.937500   \n",
       "41          0.883087         0.024272                28              0.937500   \n",
       "42          0.874617         0.027720                41              0.946875   \n",
       "43          0.884842         0.009899                26              0.941250   \n",
       "44          0.874617         0.027720                41              0.946875   \n",
       "45          0.884842         0.009899                26              0.941250   \n",
       "46          0.834730         0.054954                60              0.942500   \n",
       "47          0.889818         0.022036                10              0.940625   \n",
       "48          0.882098         0.017072                31              0.946875   \n",
       "49          0.892318         0.011103                 7              0.945625   \n",
       "50          0.882098         0.017072                31              0.946875   \n",
       "51          0.892318         0.011103                 7              0.945625   \n",
       "52          0.840468         0.049559                57              0.947500   \n",
       "53          0.878606         0.018308                38              0.938750   \n",
       "54          0.886831         0.021116                14              0.947500   \n",
       "55          0.896303         0.016080                 3              0.947500   \n",
       "56          0.886831         0.021116                14              0.947500   \n",
       "57          0.896303         0.016080                 3              0.947500   \n",
       "58          0.853183         0.051537                48              0.961250   \n",
       "59          0.886334         0.023148                21              0.948750   \n",
       "\n",
       "    split1_test_Accuracy  split2_test_Accuracy  split3_test_Accuracy  \\\n",
       "0               0.911250              0.911875              0.930625   \n",
       "1               0.939375              0.928125              0.939375   \n",
       "2               0.911250              0.911875              0.930625   \n",
       "3               0.939375              0.928125              0.939375   \n",
       "4               0.846250              0.693125              0.858125   \n",
       "5               0.876250              0.857500              0.935000   \n",
       "6               0.917500              0.920625              0.930000   \n",
       "7               0.942500              0.933125              0.947500   \n",
       "8               0.917500              0.920625              0.930000   \n",
       "9               0.942500              0.933125              0.947500   \n",
       "10              0.891875              0.701250              0.901250   \n",
       "11              0.901250              0.875625              0.934375   \n",
       "12              0.930625              0.916875              0.944375   \n",
       "13              0.940625              0.930000              0.940625   \n",
       "14              0.930625              0.916875              0.944375   \n",
       "15              0.940625              0.930000              0.940625   \n",
       "16              0.851875              0.705000              0.894375   \n",
       "17              0.908125              0.880625              0.931875   \n",
       "18              0.930625              0.929375              0.941875   \n",
       "19              0.941250              0.937500              0.950625   \n",
       "20              0.930625              0.929375              0.941875   \n",
       "21              0.941250              0.937500              0.950625   \n",
       "22              0.871250              0.743125              0.883125   \n",
       "23              0.918750              0.878750              0.908125   \n",
       "24              0.936875              0.926875              0.959375   \n",
       "25              0.945625              0.940625              0.954375   \n",
       "26              0.936875              0.926875              0.959375   \n",
       "27              0.945625              0.940625              0.954375   \n",
       "28              0.888750              0.765000              0.863750   \n",
       "29              0.921875              0.886875              0.891250   \n",
       "30              0.900000              0.915000              0.933750   \n",
       "31              0.937500              0.931250              0.939375   \n",
       "32              0.900000              0.915000              0.933750   \n",
       "33              0.937500              0.931250              0.939375   \n",
       "34              0.846250              0.686875              0.866875   \n",
       "35              0.878750              0.851875              0.938750   \n",
       "36              0.923750              0.914375              0.932500   \n",
       "37              0.945625              0.934375              0.948125   \n",
       "38              0.923750              0.914375              0.932500   \n",
       "39              0.945625              0.934375              0.948125   \n",
       "40              0.890000              0.693125              0.905625   \n",
       "41              0.903750              0.858125              0.935625   \n",
       "42              0.936250              0.910000              0.943750   \n",
       "43              0.945000              0.934375              0.940625   \n",
       "44              0.936250              0.910000              0.943750   \n",
       "45              0.945000              0.934375              0.940625   \n",
       "46              0.848125              0.685625              0.900000   \n",
       "47              0.909375              0.867500              0.930625   \n",
       "48              0.937500              0.925000              0.946875   \n",
       "49              0.945625              0.936250              0.952500   \n",
       "50              0.937500              0.925000              0.946875   \n",
       "51              0.945625              0.936250              0.952500   \n",
       "52              0.871250              0.768750              0.888125   \n",
       "53              0.924375              0.880000              0.908125   \n",
       "54              0.940000              0.923125              0.955625   \n",
       "55              0.943750              0.935625              0.957500   \n",
       "56              0.940000              0.923125              0.955625   \n",
       "57              0.943750              0.935625              0.957500   \n",
       "58              0.886250              0.755625              0.880000   \n",
       "59              0.927500              0.872500              0.903750   \n",
       "\n",
       "    split4_test_Accuracy  mean_test_Accuracy  std_test_Accuracy  \\\n",
       "0               0.935000            0.924375           0.010555   \n",
       "1               0.954375            0.940250           0.008344   \n",
       "2               0.935000            0.924375           0.010555   \n",
       "3               0.954375            0.940250           0.008344   \n",
       "4               0.933125            0.855625           0.090496   \n",
       "5               0.962500            0.914875           0.040632   \n",
       "6               0.935625            0.929250           0.009265   \n",
       "7               0.950000            0.943000           0.005801   \n",
       "8               0.935625            0.929250           0.009265   \n",
       "9               0.950000            0.943000           0.005801   \n",
       "10              0.934375            0.873375           0.087932   \n",
       "11              0.958125            0.921000           0.029052   \n",
       "12              0.946250            0.937125           0.011796   \n",
       "13              0.956875            0.942250           0.008602   \n",
       "14              0.946250            0.937125           0.011796   \n",
       "15              0.956875            0.942250           0.008602   \n",
       "16              0.935000            0.865625           0.086537   \n",
       "17              0.961875            0.924875           0.028091   \n",
       "18              0.948750            0.939750           0.008325   \n",
       "19              0.956875            0.946250           0.006858   \n",
       "20              0.948750            0.939750           0.008325   \n",
       "21              0.956875            0.946250           0.006858   \n",
       "22              0.934375            0.876000           0.072579   \n",
       "23              0.952500            0.920000           0.025996   \n",
       "24              0.948750            0.942625           0.010964   \n",
       "25              0.960000            0.949125           0.007033   \n",
       "26              0.948750            0.942625           0.010964   \n",
       "27              0.960000            0.949125           0.007033   \n",
       "28              0.948750            0.886000           0.070889   \n",
       "29              0.960625            0.922875           0.030579   \n",
       "30              0.935000            0.923375           0.013816   \n",
       "31              0.948750            0.939500           0.005637   \n",
       "32              0.935000            0.923375           0.013816   \n",
       "33              0.948750            0.939500           0.005637   \n",
       "34              0.931250            0.856000           0.092824   \n",
       "35              0.960625            0.915000           0.042058   \n",
       "36              0.939375            0.930250           0.010036   \n",
       "37              0.946875            0.942875           0.005208   \n",
       "38              0.939375            0.930250           0.010036   \n",
       "39              0.946875            0.942875           0.005208   \n",
       "40              0.933125            0.871875           0.091079   \n",
       "41              0.956250            0.918250           0.034472   \n",
       "42              0.948125            0.937000           0.014117   \n",
       "43              0.949375            0.942125           0.004978   \n",
       "44              0.948125            0.937000           0.014117   \n",
       "45              0.949375            0.942125           0.004978   \n",
       "46              0.935000            0.862250           0.094397   \n",
       "47              0.960625            0.921750           0.031757   \n",
       "48              0.946875            0.940625           0.008615   \n",
       "49              0.950000            0.946000           0.005542   \n",
       "50              0.946875            0.940625           0.008615   \n",
       "51              0.950000            0.946000           0.005542   \n",
       "52              0.932500            0.881625           0.062958   \n",
       "53              0.952500            0.920750           0.025160   \n",
       "54              0.948125            0.942875           0.011044   \n",
       "55              0.955000            0.947875           0.007882   \n",
       "56              0.948125            0.942875           0.011044   \n",
       "57              0.955000            0.947875           0.007882   \n",
       "58              0.945000            0.885625           0.072355   \n",
       "59              0.961250            0.922750           0.031834   \n",
       "\n",
       "    rank_test_Accuracy  \n",
       "0                   38  \n",
       "1                   23  \n",
       "2                   38  \n",
       "3                   23  \n",
       "4                   60  \n",
       "5                   50  \n",
       "6                   35  \n",
       "7                    9  \n",
       "8                   35  \n",
       "9                    9  \n",
       "10                  55  \n",
       "11                  45  \n",
       "12                  29  \n",
       "13                  17  \n",
       "14                  29  \n",
       "15                  17  \n",
       "16                  57  \n",
       "17                  37  \n",
       "18                  25  \n",
       "19                   5  \n",
       "20                  25  \n",
       "21                   5  \n",
       "22                  54  \n",
       "23                  47  \n",
       "24                  15  \n",
       "25                   1  \n",
       "26                  15  \n",
       "27                   1  \n",
       "28                  51  \n",
       "29                  42  \n",
       "30                  40  \n",
       "31                  27  \n",
       "32                  40  \n",
       "33                  27  \n",
       "34                  59  \n",
       "35                  49  \n",
       "36                  33  \n",
       "37                  11  \n",
       "38                  33  \n",
       "39                  11  \n",
       "40                  56  \n",
       "41                  48  \n",
       "42                  31  \n",
       "43                  19  \n",
       "44                  31  \n",
       "45                  19  \n",
       "46                  58  \n",
       "47                  44  \n",
       "48                  21  \n",
       "49                   7  \n",
       "50                  21  \n",
       "51                   7  \n",
       "52                  53  \n",
       "53                  46  \n",
       "54                  13  \n",
       "55                   3  \n",
       "56                  13  \n",
       "57                   3  \n",
       "58                  52  \n",
       "59                  43  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = CV.predict(X_test)\n",
    "probabilities = CV.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8953053593685085, 0.9318918918918919, 0.8724696356275303, 1.0, 0.937)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD7CAYAAAB+B7/XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAATWUlEQVR4nO3dcUjc9/3H8deZJnb3S8Bgv6eQFSkb2NVq0t8GFVfsL6X1WuvZRgNtEmqhmWmWFZmDki5KHQybrCuzMPaPYSyUKUTGFuM/59EGC0NZaGhmfzZZll8oSUM9T+1SzXRV7/P7o7/cfleTfO/Mned97vmAQr/5fC95vys8e/mqiccYYwQAsEZepgcAAKQWYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALDMXZkeQJI+//y6otHkv5y+sHCjpqZm0zDR2sXOuYGdc8NKd87L82jz5v+45fmaCHs0alYU9huvzTXsnBvYOTekY2cexQCAZQg7AFiGsAOAZRIK++zsrOrq6vTpp58uOzt37pwaGhrk9/vV1tamxcXFlA8JAEica9j/+te/ateuXfrkk09uev7qq6/q9ddf1+DgoIwx6uvrS/WMAIAkuIa9r69PHR0d8vl8y86uXr2q+fl5bdu2TZLU0NCgYDCY8iEBAIlz/XLHzs7OW55NTEzIcZzYteM4CofDqZksRw2dvaq/jN36v+H6Deu08OXSKk6UeeycG3Jx59pH7lN5yeaU/7x39HXs0WhUHo8ndm2MibtOVGHhxhXP4DibVvzadAiOfKL3P1z+uYhE/ff/TEmSHvxW4S3vWb9h3Yp//mzFzrkhF3dOR8PuKOzFxcWKRCKx68nJyZs+snEzNTW7oi/Sd5xNikRmkn6dG7d3zbfztyv/kCSV3luwoteX3lugh8uK9F/bttz0PF07r2XsnBvYOXF5eZ7bviG+o7Bv2bJF+fn5OnPmjL773e+qv79f1dXVd/JTpl0i0b6TOLuFGQDSbUVhb25uVktLi8rLy/XWW2+pvb1ds7OzKisrU1NTU6pnvCNfD3ki0SbOALKZZy38ZdapeBRzq3fiNwt5Nkeb367mBnbODWvyUcxa8pexsP525R/L3onz7htArrEi7ENnr8aifnDPf2Z6HADIKCv+rJgbj2AeLivK8CQAkHlWhF366pELj1sAwIKw33gMAwD4StaHnccwABAvq8MeHPkk9klTHsMAwFeyOuw3/kwW3q0DwL9lddglPmkKAF+X9WEHAMQj7ABgGcIOAJYh7ABgGcIOAJYh7ABgGcIOAJbJ2rAPnb0a+4ufAQD/lrVh58+IAYCby9qwS9KD3yrku04B4GuyOuwAgOUIOwBYhrADgGUIOwBYhrADgGUIOwBYhrADgGUIOwBYhrADgGUIOwBYhrADgGUIOwBYJqGwDwwMqLa2VjU1Nerp6Vl2PjY2psbGRtXX1+vll1/WF198kfJBAQCJcQ17OBxWV1eXent7deLECR0/flwXL16Mu6ezs1MtLS06efKk7rvvPv32t79N28AAgNtzDfvw8LAqKytVUFAgr9crv9+vYDAYd080GtX169clSXNzc7r77rvTMy0AwNVdbjdMTEzIcZzYtc/n0+joaNw9r732ml566SW98cYb+sY3vqG+vr6khigs3JjU/ZK0fsM6SZLjbEr6tdmOnXMDO+eGdOzsGvZoNCqPxxO7NsbEXc/Pz6utrU3Hjh1TRUWFfve73+ngwYPq7u5OeIipqVlFoyapwRe+XNL6DesUicwk9bps5zib2DkHsHNuWOnOeXme274hdn0UU1xcrEgkEruORCLy+Xyx6wsXLig/P18VFRWSpOeee06nT59OelAAQGq4hr2qqkojIyOanp7W3NycQqGQqqurY+clJSUaHx/XpUuXJEnvvfeeysvL0zcxAOC2XB/FFBUVqbW1VU1NTVpYWNDOnTtVUVGh5uZmtbS0qLy8XIcPH9aPf/xjGWNUWFioN954YzVmBwDchGvYJSkQCCgQCMT92NGjR2P//uijj+rRRx9N7WQAgBXhO08BwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsQ9gBwDKEHQAsk1DYBwYGVFtbq5qaGvX09Cw7v3Tpkl544QXV19dr7969unbtWsoHBQAkxjXs4XBYXV1d6u3t1YkTJ3T8+HFdvHgxdm6M0Q9/+EM1Nzfr5MmT+s53vqPu7u60Dg0AuDXXsA8PD6uyslIFBQXyer3y+/0KBoOx87GxMXm9XlVXV0uS9u/frz179qRvYgDAbbmGfWJiQo7jxK59Pp/C4XDs+vLly7rnnnt06NAh7dixQx0dHfJ6vemZFgDg6i63G6LRqDweT+zaGBN3vbi4qNOnT+v3v/+9ysvL9fbbb+vIkSM6cuRIwkMUFm5Mcmxp/YZ1kiTH2ZT0a7MdO+cGds4N6djZNezFxcX64IMPYteRSEQ+n+//DeWopKRE5eXlkqS6ujq1tLQkNcTU1KyiUZPUaxa+XNL6DesUicwk9bps5zib2DkHsHNuWOnOeXme274hdn0UU1VVpZGREU1PT2tubk6hUCj2PF2SHnroIU1PT+v8+fOSpFOnTqmsrCzpQQEAqeH6jr2oqEitra1qamrSwsKCdu7cqYqKCjU3N6ulpUXl5eX6zW9+o/b2ds3Nzam4uFhvvvnmaswOALgJ17BLUiAQUCAQiPuxo0ePxv5969at+sMf/pDayQAAK8J3ngKAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZRIK+8DAgGpra1VTU6Oenp5b3jc0NKTHHnssZcMBAJJ3l9sN4XBYXV1d+uMf/6gNGzbo+eef18MPP6xvf/vbcfdNTk7qF7/4RdoGBQAkxvUd+/DwsCorK1VQUCCv1yu/369gMLjsvvb2dr3yyitpGRIAkDjXd+wTExNyHCd27fP5NDo6GnfPO++8owceeEBbt25d0RCFhRuTfs36DeskSY6zaUW/ZjZj59zAzrkhHTu7hj0ajcrj8cSujTFx1xcuXFAoFNKxY8c0Pj6+oiGmpmYVjZqkXrPw5ZLWb1inSGRmRb9mtnKcTeycA9g5N6x057w8z23fELs+iikuLlYkEoldRyIR+Xy+2HUwGFQkElFjY6P27duniYkJ7d69O+lBAQCp4Rr2qqoqjYyMaHp6WnNzcwqFQqquro6dt7S0aHBwUP39/eru7pbP51Nvb29ahwYA3Jpr2IuKitTa2qqmpiY9++yzqqurU0VFhZqbm/XRRx+txowAgCS4PmOXpEAgoEAgEPdjR48eXXbfN7/5TZ06dSo1kwEAVoTvPAUAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALAMYQcAyxB2ALBMQmEfGBhQbW2tampq1NPTs+z83Xff1TPPPKP6+nodOHBA165dS/mgAIDEuIY9HA6rq6tLvb29OnHihI4fP66LFy/GzmdnZ/Wzn/1M3d3dOnnypEpLS/XrX/86rUMDAG7NNezDw8OqrKxUQUGBvF6v/H6/gsFg7HxhYUEdHR0qKiqSJJWWluqzzz5L38QAgNtyDfvExIQcx4ld+3w+hcPh2PXmzZv1xBNPSJLm5+fV3d2txx9/PA2jAgAScZfbDdFoVB6PJ3ZtjIm7vmFmZkY/+tGPdP/992vHjh1JDVFYuDGp+yVp/YZ1kiTH2ZT0a7MdO+cGds4N6djZNezFxcX64IMPYteRSEQ+ny/unomJCe3du1eVlZU6dOhQ0kNMTc0qGjVJvWbhyyWt37BOkchM0r9eNnOcTeycA9g5N6x057w8z23fELs+iqmqqtLIyIimp6c1NzenUCik6urq2PnS0pL279+vp556Sm1tbTd9Nw8AWD2u79iLiorU2tqqpqYmLSwsaOfOnaqoqFBzc7NaWlo0Pj6ujz/+WEtLSxocHJQkPfjgg+rs7Ez78ACA5VzDLkmBQECBQCDux44ePSpJKi8v1/nz51M/GQBgRfjOUwCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwDGEHAMsQdgCwTEJhHxgYUG1trWpqatTT07Ps/Ny5c2poaJDf71dbW5sWFxdTPigAIDGuYQ+Hw+rq6lJvb69OnDih48eP6+LFi3H3vPrqq3r99dc1ODgoY4z6+vrSNjAA4PZcwz48PKzKykoVFBTI6/XK7/crGAzGzq9evar5+Xlt27ZNktTQ0BB3DgBYXXe53TAxMSHHcWLXPp9Po6Ojtzx3HEfhcDipIQoLNyZ1vyTVPnLf//16m5J+bbZj59zAzrkhHTu7hj0ajcrj8cSujTFx127niZiamlU0apJ6TXnJZjnOJkUiM0m9Ltuxc25g59yw0p3z8jy3fUPs+iimuLhYkUgkdh2JROTz+W55Pjk5GXcOAFhdrmGvqqrSyMiIpqenNTc3p1AopOrq6tj5li1blJ+frzNnzkiS+vv7484BAKvLNexFRUVqbW1VU1OTnn32WdXV1amiokLNzc366KOPJElvvfWWDh8+rCeffFL//Oc/1dTUlPbBAQA35zHGJPdwOw1W8oxd4plcrmDn3MDOibvjZ+wAgOxC2AHAMoQdACzj+nXsqyEvL7mve0/Va7MVO+cGds4NK9nZ7TVr4pOnAIDU4VEMAFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFiGsAOAZQg7AFgmK8I+MDCg2tpa1dTUqKenZ9n5uXPn1NDQIL/fr7a2Ni0uLmZgytRy2/ndd9/VM888o/r6eh04cEDXrl3LwJSp5bbzDUNDQ3rsscdWcbL0cdv50qVLeuGFF1RfX6+9e/fmxMd5bGxMjY2Nqq+v18svv6wvvvgiA1Om1uzsrOrq6vTpp58uO0tLv8waNz4+brZv324+//xzc/36dRMIBMzf//73uHuefvpp8+GHHxpjjPnpT39qenp6MjBp6rjtPDMzY77//e+b8fFxY4wxb7/9tvn5z3+eqXFTIpGPszHGRCIR8+STT5rt27dnYMrUcts5Go2ampoa8/777xtjjPnlL39p3nzzzUyNmxKJfJx37dplhoaGjDHGHD582PzqV7/KxKgpc/bsWVNXV2fKysrMlStXlp2no19r/h378PCwKisrVVBQIK/XK7/fr2AwGDu/evWq5ufntW3bNklSQ0ND3Hk2ctt5YWFBHR0dKioqkiSVlpbqs88+y9S4KeG28w3t7e165ZVXMjBh6rntPDY2Jq/XG/urJvfv3689e/ZkatyUSOTjHI1Gdf36dUnS3Nyc7r777kyMmjJ9fX3q6Oi46d8Fna5+rfmwT0xMyHGc2LXP51M4HL7lueM4cefZyG3nzZs364knnpAkzc/Pq7u7W48//viqz5lKbjtL0jvvvKMHHnhAW7duXe3x0sJt58uXL+uee+7RoUOHtGPHDnV0dMjr9WZi1JRJ5OP82muvqb29XY888oiGh4f1/PPPr/aYKdXZ2anvfe97Nz1LV7/WfNij0ag8nn//EZXGmLhrt/NslOhOMzMz2rdvn+6//37t2LFjNUdMObedL1y4oFAopAMHDmRivLRw23lxcVGnT5/Wrl279Kc//Un33nuvjhw5kolRU8Zt5/n5ebW1tenYsWP685//rN27d+vgwYOZGHVVpKtfaz7sxcXFikQisetIJBL3W5qvn09OTt70tzzZxG1n6av/0+/evVulpaXq7Oxc7RFTzm3nYDCoSCSixsZG7du3L7Z/NnPb2XEclZSUqLy8XJJUV1en0dHRVZ8zldx2vnDhgvLz81VRUSFJeu6553T69OlVn3O1pKtfaz7sVVVVGhkZ0fT0tObm5hQKhWLPHCVpy5Ytys/P15kzZyRJ/f39cefZyG3npaUl7d+/X0899ZTa2tqy/ncokvvOLS0tGhwcVH9/v7q7u+Xz+dTb25vBie+c284PPfSQpqendf78eUnSqVOnVFZWlqlxU8Jt55KSEo2Pj+vSpUuSpPfeey/2PzYbpa1fd/zp11Vw8uRJ8/TTT5uamhrT3d1tjDHmBz/4gRkdHTXGGHPu3DnT2Nho/H6/+clPfmL+9a9/ZXLclLjdzqFQyJSWlpr6+vrYP4cOHcrwxHfO7eN8w5UrV6z4qhhj3Hc+e/asaWxsNLW1teall14yk5OTmRw3Jdx2HhoaMoFAwNTV1ZkXX3zRXL58OZPjpsz27dtjXxWT7n7xNygBgGXW/KMYAEByCDsAWIawA4BlCDsAWIawA4BlCDsAWIawA4BlCDsAWOZ/AZBANWdPOcthAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, f1_score, recall_score, precision_score, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "tpr, fpr, thresolds = roc_curve(y_test, probabilities[:, 1])\n",
    "plt.plot(tpr, fpr)\n",
    "print(fbeta_score(y_test, predictions, beta=2), f1_score(y_test, predictions), recall_score(y_test, predictions), precision_score(y_test, predictions), accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>ORIGIN_CITY_MARKET_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST_CITY_MARKET_ID</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>TAXI_OUT_median</th>\n",
       "      <th>TAXI_IN_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>713341</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NK</td>\n",
       "      <td>N527NK</td>\n",
       "      <td>31453</td>\n",
       "      <td>IAH</td>\n",
       "      <td>30977</td>\n",
       "      <td>ORD</td>\n",
       "      <td>2000</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>2234</td>\n",
       "      <td>154.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842233</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>AA</td>\n",
       "      <td>N744P</td>\n",
       "      <td>30852</td>\n",
       "      <td>DCA</td>\n",
       "      <td>33195</td>\n",
       "      <td>TPA</td>\n",
       "      <td>1200</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>1432</td>\n",
       "      <td>152.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843015</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>AA</td>\n",
       "      <td>N537UW</td>\n",
       "      <td>30325</td>\n",
       "      <td>DEN</td>\n",
       "      <td>30466</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1500</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>1659</td>\n",
       "      <td>119.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652128</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>N37267</td>\n",
       "      <td>30325</td>\n",
       "      <td>DEN</td>\n",
       "      <td>33195</td>\n",
       "      <td>TPA</td>\n",
       "      <td>751</td>\n",
       "      <td>744.0</td>\n",
       "      <td>1314</td>\n",
       "      <td>203.0</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290497</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8307K</td>\n",
       "      <td>30466</td>\n",
       "      <td>PHX</td>\n",
       "      <td>31453</td>\n",
       "      <td>HOU</td>\n",
       "      <td>905</td>\n",
       "      <td>906.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MONTH  DAY_OF_MONTH  DAY_OF_WEEK OP_UNIQUE_CARRIER TAIL_NUM  \\\n",
       "713341       2             6            3                NK   N527NK   \n",
       "842233       2            10            7                AA    N744P   \n",
       "843015       2            20            3                AA   N537UW   \n",
       "1652128      3            28            4                UA   N37267   \n",
       "5290497      9            30            1                WN   N8307K   \n",
       "\n",
       "         ORIGIN_CITY_MARKET_ID ORIGIN  DEST_CITY_MARKET_ID DEST  CRS_DEP_TIME  \\\n",
       "713341                   31453    IAH                30977  ORD          2000   \n",
       "842233                   30852    DCA                33195  TPA          1200   \n",
       "843015                   30325    DEN                30466  PHX          1500   \n",
       "1652128                  30325    DEN                33195  TPA           751   \n",
       "5290497                  30466    PHX                31453  HOU           905   \n",
       "\n",
       "         DEP_TIME  CRS_ARR_TIME  CRS_ELAPSED_TIME  DISTANCE  DISTANCE_GROUP  \\\n",
       "713341     1958.0          2234             154.0     925.0               4   \n",
       "842233     1152.0          1432             152.0     814.0               4   \n",
       "843015     1513.0          1659             119.0     602.0               3   \n",
       "1652128     744.0          1314             203.0    1506.0               7   \n",
       "5290497     906.0          1345             160.0    1020.0               5   \n",
       "\n",
       "         CARRIER_DELAY  WEATHER_DELAY  NAS_DELAY  SECURITY_DELAY  \\\n",
       "713341             0.0            0.0        0.0             0.0   \n",
       "842233             0.0            0.0        0.0             0.0   \n",
       "843015            11.0            0.0        4.0             0.0   \n",
       "1652128            0.0            0.0        0.0             0.0   \n",
       "5290497            0.0            0.0        0.0             0.0   \n",
       "\n",
       "         LATE_AIRCRAFT_DELAY  TAXI_OUT_median  TAXI_IN_median  \n",
       "713341                   0.0             13.0            13.0  \n",
       "842233                   0.0             18.0             4.0  \n",
       "843015                   2.0             15.0             6.0  \n",
       "1652128                  0.0             16.0             5.0  \n",
       "5290497                  0.0             10.0             5.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation = df_validation.drop('ARR_DEL15', axis=1)\n",
    "X_validation.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2733467    0.0\n",
       "650427     0.0\n",
       "4935282    0.0\n",
       "6696522    0.0\n",
       "4678719    0.0\n",
       "Name: ARR_DEL15, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation = df_validation['ARR_DEL15']\n",
    "y_validation.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = CV.predict(X_validation)\n",
    "probabilities = CV.predict_proba(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9032789553508674 0.9371876548412564 0.8820042289957111 0.9997371519720153 0.977452222524714\n",
      "[[5873658     321]\n",
      " [ 163336 1220917]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, f1_score, recall_score, precision_score, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "tpr, fpr, thresolds = roc_curve(y_validation, probabilities[:, 1])\n",
    "plt.plot(tpr, fpr)\n",
    "print(fbeta_score(y_validation, predictions, beta=2), f1_score(y_validation, predictions), recall_score(y_validation, predictions), precision_score(y_validation, predictions), accuracy_score(y_validation, predictions))\n",
    "print(confusion_matrix(y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacer aquí la confusion plot matrix !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1d9a5aed490>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(rf, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1d9a5b152e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(rf, X_validation, y_validation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  2270.9865345000003\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter() - t0\n",
    "print(\"Time elapsed: \", t1) # CPU seconds elapsed (floating point)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Time elapsed:  548.8254737"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Classification Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)\n",
    "\n",
    "- Binary classification (only):\n",
    "    - [precision_recall_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve): Compute precision-recall pairs for different probability thresholds.\n",
    "        - The precision is the ratio `tp / (tp + fp)` where `tp` is the number of true positives and `fp` the number of false positives. The **precision** is intuitively the ability of the classifier **not to label as positive a sample that is negative**.\n",
    "        - The recall is the ratio `tp / (tp + fn)` where `tp` is the number of true positives and `fn` the number of false negatives. The **recall** is intuitively the ability of the classifier to **find all the positive samples**.\n",
    "\n",
    "    ### RECALL could be a potentially strong metric for this case; \"from all the flights classified as delayed, the actual (true) number delyed flights is as high as possible.\"\n",
    "\n",
    "    - [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve): A receiver operating characteristic (ROC), or simply ROC curve, is a graphical plot which illustrates the performance of a binary classifier system as its discrimination threshold is varied. It is created by plotting the fraction of true positives out of the positives (TPR = true positive rate) vs. the fraction of false positives out of the negatives (FPR = false positive rate), at various threshold settings. TPR is also known as sensitivity, and FPR is one minus the specificity or true negative rate.\n",
    "        \n",
    "- Multi-class classification (or binary):\n",
    "    - [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix): Compute confusion matrix to evaluate the accuracy of a classification.\n",
    "    ![IMG_Confusion_Matrix](https://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_0011.png)\n",
    "    - [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score): Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
    "\n",
    "- Multi-label classification (or binary or multi-class):\n",
    "    - [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score): Accuracy classification score.\n",
    "        - It is the ratio of number of correct predictions to the total number of input samples.\n",
    "        - **It works well only if there are equal number of samples belonging to each class.**\n",
    "    - [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report): Build a text report showing the main classification metrics.\n",
    "    - [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score): Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "        - The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal: `F1 = 2 * (precision * recall) / (precision + recall)`\n",
    "    - [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "    - [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which metric should be used then?\n",
    "##### Bear in mind that it's a clear case of imbalanced data\n",
    "\n",
    "Nomenclature:\n",
    "- Delayed = Positive\n",
    "- On-time = Negative \n",
    "\n",
    "Considering this:\n",
    "- False positive (Type I error) → Wrongly classifying an On-time flight as a Delayed flight → Not significantly relevant\n",
    "- **False negative (Type II error) → Wrongly classifying a Delayed flight as an On-time flight → Highly relevant**\n",
    "\n",
    "**F-beta** score (\\$ F_\\beta \\$):\n",
    "![F-beta score](https://wikimedia.org/api/rest_v1/media/math/render/svg/136f45612c08805f4254f63d2f2524bc25075fff)\n",
    "\n",
    "Two commonly used values for β are:\n",
    "- **2 : weighs recall higher than precision**\n",
    "- 0.5 : weighs recall lower than precision.\n",
    "\n",
    "\n",
    "<em>Probably most people in the industry would accept that an **OTP of 80%* or above is pretty good***. That’s 4 in 5 flights arriving within 15 minutes of their scheduled arrival time. The very best airlines and airports succeed in punctuality closer to 90% - but they remain the exception rather than the rule.</em>  \n",
    "(Source: [OAG](https://www.oag.com/on-time-performance-airlines-airports))\n",
    "\n",
    "The actual data from the 7268232 records comprising the OTP dataset accurately confirm this hypothesis:\n",
    "```\n",
    "Delays: 5878979 (80.89%)\n",
    "On-time: 1389253 (19.11%)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some rare cases, the calculation of Precision or Recall can cause a division by 0. Regarding the precision, this can happen if there are no results inside the answer of an annotator and, thus, the true as well as the false positives are 0. For these special cases, we have defined that **if the true positives, false positives and false negatives are all 0, the precision, recall and F1-measure are 1**. This might occur in cases in which the gold standard contains a document without any annotations and the annotator (correctly) returns no annotations. **If true positives are 0 and one of the two other counters is larger than 0, the precision, recall and F1-measure are 0.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A Gentle Introduction to Imbalanced Classification](https://machinelearningmastery.com/what-is-imbalanced-classification/)  \n",
    "**Imbalanced classifications** pose a challenge for predictive modeling as **most of the machine learning algorithms used for classification were designed around the assumption of an equal number of examples for each class**. This results in models that have poor predictive performance, specifically for the minority class. This is a problem because typically, the minority class is more important and therefore **the problem is more sensitive to classification errors for the minority class than the majority class**.\n",
    "\n",
    "[Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)  \n",
    "1. Try Changing Your Performance Metric:\n",
    "    - Confusion Matrix\n",
    "    - Precision: \n",
    "    - Recall: \n",
    "    - F1 Score\n",
    "    - Kappa\n",
    "    - ROC Curves\n",
    "2. Try Resampling Your Dataset:\n",
    "    - You can add copies of instances from the under-represented class called **over-sampling** (or more formally **sampling with replacement**) → when you don’t have a lot of data (tens of thousands of records or less)\n",
    "    - You can delete instances from the over-represented class, called **under-sampling** → when you have an a lot data (tens- or hundreds of thousands of instances or more)\n",
    "3. Try Different Algorithms:\n",
    "    - That being said, **decision trees often perform well on imbalanced datasets**. The splitting rules that look at the class variable used in the creation of the trees, can force both classes to be addressed.  \n",
    "    If in doubt, try a few popular decision tree algorithms like C4.5, C5.0, CART, and Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Guide to Classification on Imbalanced Datasets](https://towardsdatascience.com/guide-to-classification-on-imbalanced-datasets-d6653aa5fa23)  \n",
    "There are two main types of techniques to handle imbalanced datasets:\n",
    "- ### Sampling methods:\n",
    "    - #### Oversampling\n",
    "        - How do we generate these samples? The most common way is to generate points that are close in dataspace proximity to existing samples or are ‘between’ two samples, as illustrated below\n",
    "        - There are some downsides to adding false data points:\n",
    "            - **Overfitting** risk\n",
    "            - In addition, adding these values randomly can also contribute **additional noise to our model**\n",
    "        - Techniques:\n",
    "            - **SMOTE** (Synthetic minority oversampling technique) → SMOTE generates new samples in between existing data points based on their local density and their borders with the other class. Algorithm:\n",
    "                - Find its k-nearest minority neighbours\n",
    "                – Randomly select j of these neighbours\n",
    "                – Randomly generate synthetic samples along the lines joining the minority sample and its j selected neighbours (j depends on the amount of oversampling desired)\n",
    "    - #### Undersampling\n",
    "        - Is undersampling a good idea? Undersampling is recommended by many statistical researchers but is **only good if enough data points are available on the undersampled class**\n",
    "        - Is undersampling a good idea? Undersampling is recommended by many statistical researchers but is only good if enough data points are available on the undersampled class\n",
    "- ### Cost-sensitive methods\n",
    "    - #### Upweighting\n",
    "    Upweighting is analogous to over-sampling and works by increasing the weight of one of the classes keeping the weight of the other class at one\n",
    "    - #### Down-weighting\n",
    "    Down-weighting is analogous to under-sampling and works by decreasing the weight of one of the classes keeping the weight of the other class at one\n",
    "\n",
    "```python\n",
    "# Example of how to implement cost-sensitive learning:\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "model.fit(X_train, y_train, class_weight=class_weights)\n",
    "```\n",
    "\n",
    "- Benefits of cost-sensitive learning:\n",
    "    - It is much simpler to implement\n",
    "    - Easier to communicate to individuals\n",
    "\n",
    "### Assessment Metrics\n",
    "- #### F1-score\n",
    "    - What does a high F1 score mean? It suggests that both the precision and recall have high values — this is good and is what you would hope to see upon generating a well-functioning classification model on an imbalanced dataset. A low value indicates that either precision or recall is low, and maybe a call for concern\n",
    "    - Good F1 scores are generally lower than good accuracies (in many situations, an **F1 score of 0.5 would be considered pretty good**)\n",
    "\n",
    "- #### Receiver Operating Characteristic (ROC) Curve\n",
    "   - Depending on your application, you may be very averse to false positives as they may be very costly (e.g. launches of nuclear missiles) and thus **would like a classifier that has a very low false-positive rate**.\n",
    "\n",
    "- #### Area Under Curve (AUC)\n",
    "   - If a particular classifier has an ROC of 0.6 and another has an ROC of 0.8, the latter is clearly a better classifier. The AUC has the benefit that it is independent of the decision criteria — the classification threshold — and thus makes it easier to compare these classifiers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
