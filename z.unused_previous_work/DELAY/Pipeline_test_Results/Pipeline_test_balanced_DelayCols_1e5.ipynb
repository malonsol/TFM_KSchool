{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries to be used\n",
    "\n",
    "# Warning messages display\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action='once') # https://docs.python.org/3/library/warnings.html#the-warnings-filter\n",
    "\n",
    "# Directories/Files management\n",
    "import os.path\n",
    "## from zipfile import ZipFile # De momento no ha hecho falta \n",
    "\n",
    "# Timing\n",
    "import time\n",
    "\n",
    "# Data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None) # Show all columns in DataFrames\n",
    "pd.set_option('display.max_rows', 100) # If too high, it greatly slows down the output display and freezes the kernel\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot') # choose a style: 'plt.style.available'\n",
    "sns.set_theme(context='notebook',\n",
    "              style=\"darkgrid\") # {darkgrid, whitegrid, dark, white, ticks}\n",
    "palette = sns.color_palette(\"flare\", as_cmap=True);\n",
    "import altair as alt\n",
    "\n",
    "# Machine Learning\n",
    "## from sklearn.[...] import ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Windows.\n",
      "root path\t C:\\Users\\turge\\CompartidoVM\\0.TFM\n"
     ]
    }
   ],
   "source": [
    "# Detect Operating System running and manage paths accordingly\n",
    "\n",
    "if os.name == 'nt': # Windows\n",
    "    root = r\"C:\\Users\\turge\\CompartidoVM\\0.TFM\"\n",
    "    print(\"Running on Windows.\")\n",
    "elif os.name == 'posix': # Ubuntu\n",
    "    root = \"/home/dsc/shared/0.TFM\"\n",
    "    print(\"Running on Ubuntu.\")\n",
    "print(\"root path\\t\", root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cols = [\n",
    "    \n",
    "### -----  < X > (PRE-FLIGHT DATA) -----\n",
    "\n",
    "# Time Period\n",
    "#  'YEAR', # Disregarded: for the time being, analysis limted to 2019\n",
    "#  'QUARTER', # Disregarded: redundant\n",
    " 'MONTH',\n",
    " 'DAY_OF_MONTH',\n",
    " 'DAY_OF_WEEK',\n",
    "#  'FL_DATE', # Disregarded: redundant\n",
    "# Airline / Aircraft\n",
    " 'OP_UNIQUE_CARRIER',\n",
    "#  'OP_CARRIER_AIRLINE_ID', # Disregarded: redundant\n",
    "#  'OP_CARRIER', # Disregarded: redundant\n",
    " 'TAIL_NUM',\n",
    "#  'OP_CARRIER_FL_NUM', # Unknown in advance?\n",
    "# Origin\n",
    "#  'ORIGIN_AIRPORT_ID', # Disregarded: redundant\n",
    "#  'ORIGIN_AIRPORT_SEQ_ID', # Disregarded: redundant\n",
    " 'ORIGIN_CITY_MARKET_ID',\n",
    " 'ORIGIN',\n",
    "#  'ORIGIN_CITY_NAME', # Disregarded: redundant\n",
    "#  'ORIGIN_STATE_ABR', # Disregarded: redundant\n",
    "#  'ORIGIN_STATE_FIPS', # Federal Information Processing Standards # Not used for the moment\n",
    "#  'ORIGIN_STATE_NM', # Disregarded: redundant\n",
    "#  'ORIGIN_WAC', # World Area Code # Not used for the moment\n",
    "# Destination\n",
    "#  'DEST_AIRPORT_ID', # Disregarded: redundant\n",
    "#  'DEST_AIRPORT_SEQ_ID', # Disregarded: redundant\n",
    " 'DEST_CITY_MARKET_ID',\n",
    " 'DEST',\n",
    "#  'DEST_CITY_NAME', # Disregarded: redundant\n",
    "#  'DEST_STATE_ABR', # Disregarded: redundant\n",
    "#  'DEST_STATE_FIPS', # Federal Information Processing Standards # Not used for the moment\n",
    "#  'DEST_STATE_NM', # Disregarded: redundant\n",
    "#  'DEST_WAC', # World Area Code # Not used for the moment\n",
    "# Departure Performance\n",
    " 'CRS_DEP_TIME',\n",
    "#  'TAXI_OUT_median', #  Output / However, the median for each airport could be used as input !! (explanation below)   \n",
    "# Arrival Performance\n",
    " 'CRS_ARR_TIME',\n",
    "#  'TAXI_IN_median', #  Output / However, the median for each airport could be used as input !! (explanation below) \n",
    "# Flight Summaries\n",
    " 'CRS_ELAPSED_TIME',\n",
    " 'FLIGHTS',\n",
    " 'DISTANCE',\n",
    " 'DISTANCE_GROUP',\n",
    "\n",
    "### ----- < y > (PRE-FLIGHT DATA) -----\n",
    "\n",
    "# Departure Performance\n",
    "#  'DEP_TIME', # Disregarded: redundant\n",
    "#  'DEP_DELAY', # Disregarded: other potentially useful target\n",
    "#  'DEP_DELAY_NEW', # Disregarded: redundant\n",
    "#  'DEP_DEL15', # Disregarded: other potentially useful target\n",
    "#  'DEP_DELAY_GROUP', # Disregarded: not relevant for this particular analysis\n",
    "#  'DEP_TIME_BLK', # Disregarded: redundant\n",
    "#  'TAXI_OUT', #  Output / However, the median for each airport could be used as input !! (explanation below)\n",
    "#  'WHEELS_OFF', # Disregarded: redundant\n",
    "# Arrival Performance\n",
    "#  'WHEELS_ON', # Disregarded: redundant\n",
    "#  'TAXI_IN', #  Output / However, the median for each airport could be used as input !! (explanation below)\n",
    "#  'ARR_TIME', # Disregarded: redundant\n",
    "#  'ARR_DELAY', # -------------------------------------------> MAIN TARGET !! (i.e. < y >)\n",
    "#  'ARR_DELAY_NEW', # Disregarded: redundant\n",
    " 'ARR_DEL15', # Disregarded: other potentially useful target\n",
    "#  'ARR_DELAY_GROUP', # Disregarded: not relevant for this particular analysis\n",
    "#  'ARR_TIME_BLK', # Disregarded: redundant\n",
    "# Cancellations and Diversions\n",
    "#  'CANCELLED', # Disregarded: not relevant for this particular analysis\n",
    "#  'CANCELLATION_CODE', # Disregarded: not relevant for this particular analysis\n",
    "#  'DIVERTED', # Disregarded: not relevant for this particular analysis\n",
    "# Flight Summaries\n",
    "#  'ACTUAL_ELAPSED_TIME', # Disregarded: redundant\n",
    "#  'AIR_TIME', # Disregarded: redundant\n",
    "# Cause of Delay\n",
    "#  'CARRIER_DELAY', # Disregarded: other potentially useful target\n",
    "#  'WEATHER_DELAY', # Disregarded: other potentially useful target\n",
    "#  'NAS_DELAY', # Disregarded: other potentially useful target\n",
    "#  'SECURITY_DELAY', # Disregarded: other potentially useful target\n",
    "#  'LATE_AIRCRAFT_DELAY', # Disregarded: other potentially useful target\n",
    "# Gate Return Information at Origin Airport (Data starts 10/2008)\n",
    "#  'FIRST_DEP_TIME', # Disregarded: not relevant for this particular analysis\n",
    "#  'TOTAL_ADD_GTIME', # Disregarded: not relevant for this particular analysis\n",
    "#  'LONGEST_ADD_GTIME', # Disregarded: not relevant for this particular analysis\n",
    "# Diverted Airport Information (Data starts 10/2008)\n",
    "#  'DIV_AIRPORT_LANDINGS', # Disregarded: not relevant for this particular analysis\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "     'MONTH',\n",
    "     'DAY_OF_MONTH',\n",
    "     'DAY_OF_WEEK',\n",
    "     'OP_UNIQUE_CARRIER',\n",
    "     'TAIL_NUM',\n",
    "     'ORIGIN_CITY_MARKET_ID',\n",
    "     'ORIGIN',\n",
    "     'DEST_CITY_MARKET_ID',\n",
    "     'DEST',\n",
    "     'CRS_DEP_TIME',\n",
    "     'DEP_TIME',\n",
    "     'TAXI_OUT_median',\n",
    "     'TAXI_IN_median',\n",
    "#      'DEP_DELAY',\n",
    "#      'DEP_DEL15',\n",
    "#      'DEP_DELAY_GROUP',\n",
    "#      'TAXI_OUT',\n",
    "#      'TAXI_IN',\n",
    "     'CRS_ARR_TIME',\n",
    "#      'ARR_TIME',\n",
    "#      'ARR_DELAY',\n",
    "     'ARR_DEL15',\n",
    "#      'ARR_DELAY_GROUP',\n",
    "#      'CANCELLED',\n",
    "     'CRS_ELAPSED_TIME',\n",
    "     'DISTANCE',\n",
    "     'DISTANCE_GROUP',\n",
    "     'CARRIER_DELAY',\n",
    "     'WEATHER_DELAY',\n",
    "     'NAS_DELAY',\n",
    "     'SECURITY_DELAY',\n",
    "     'LATE_AIRCRAFT_DELAY',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\turge\\\\CompartidoVM\\\\0.TFM\\\\Output_Data\\\\US_DoT\\\\AL_OTP_MVP_Preprocessed_19_v2_clean.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_input_csv_path = os.path.join(root,\n",
    "                                           \"Output_Data\",\n",
    "                                           \"US_DoT\",\n",
    "                                           \"AL_OTP_MVP_Preprocessed_19_v2_clean.csv\")\n",
    "preprocessed_input_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_all = pd.read_csv(preprocessed_input_csv_path,\n",
    "                 encoding='latin1',\n",
    "#                  nrows=1e4,\n",
    "                 usecols=cols, # This way, the extra column is disregarded for the loading process\n",
    "                 low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7268232, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 23), (7168232, 23))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_length = int(1e5)\n",
    "delayed = df_all[df_all['ARR_DEL15'] == 1].sample(sample_length // 2)\n",
    "not_delayed = df_all[df_all['ARR_DEL15'] == 0].sample(sample_length // 2)\n",
    "df = delayed.append(not_delayed)\n",
    "\n",
    "df_validation = df_all.loc[set(df_all.index) - set(df.index), :]\n",
    "\n",
    "df.shape, df_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dealing with categorical features with high cardinality: Target Encoding](https://medium.com/@kr.vishwesh54/dealing-with-categorical-features-with-high-cardinality-target-encoding-baa9298bf257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 22), (100000,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>ORIGIN_CITY_MARKET_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST_CITY_MARKET_ID</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>TAXI_OUT_median</th>\n",
       "      <th>TAXI_IN_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64000</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>WN</td>\n",
       "      <td>N224WN</td>\n",
       "      <td>33195</td>\n",
       "      <td>TPA</td>\n",
       "      <td>31066</td>\n",
       "      <td>CMH</td>\n",
       "      <td>1615</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>1825</td>\n",
       "      <td>130.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6587376</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>B6</td>\n",
       "      <td>N554JB</td>\n",
       "      <td>31454</td>\n",
       "      <td>MCO</td>\n",
       "      <td>34254</td>\n",
       "      <td>PSE</td>\n",
       "      <td>2040</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>23</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848731</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8670A</td>\n",
       "      <td>30977</td>\n",
       "      <td>MDW</td>\n",
       "      <td>32575</td>\n",
       "      <td>ONT</td>\n",
       "      <td>1915</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>2150</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423645</th>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>MQ</td>\n",
       "      <td>N824AE</td>\n",
       "      <td>31057</td>\n",
       "      <td>CLT</td>\n",
       "      <td>34783</td>\n",
       "      <td>SGF</td>\n",
       "      <td>2209</td>\n",
       "      <td>2207.0</td>\n",
       "      <td>2325</td>\n",
       "      <td>136.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731167</th>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8531Q</td>\n",
       "      <td>32457</td>\n",
       "      <td>SFO</td>\n",
       "      <td>30977</td>\n",
       "      <td>MDW</td>\n",
       "      <td>1410</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1855.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MONTH  DAY_OF_MONTH  DAY_OF_WEEK OP_UNIQUE_CARRIER TAIL_NUM  \\\n",
       "64000        1             2            3                WN   N224WN   \n",
       "6587376     11             5            2                B6   N554JB   \n",
       "848731       2            21            4                WN   N8670A   \n",
       "4423645      8            26            1                MQ   N824AE   \n",
       "5731167     10            24            4                WN   N8531Q   \n",
       "\n",
       "         ORIGIN_CITY_MARKET_ID ORIGIN  DEST_CITY_MARKET_ID DEST  CRS_DEP_TIME  \\\n",
       "64000                    33195    TPA                31066  CMH          1615   \n",
       "6587376                  31454    MCO                34254  PSE          2040   \n",
       "848731                   30977    MDW                32575  ONT          1915   \n",
       "4423645                  31057    CLT                34783  SGF          2209   \n",
       "5731167                  32457    SFO                30977  MDW          1410   \n",
       "\n",
       "         DEP_TIME  CRS_ARR_TIME  CRS_ELAPSED_TIME  DISTANCE  DISTANCE_GROUP  \\\n",
       "64000      1708.0          1825             130.0     829.0               4   \n",
       "6587376    2040.0            23             163.0    1179.0               5   \n",
       "848731     1915.0          2150             275.0    1706.0               7   \n",
       "4423645    2207.0          2325             136.0     708.0               3   \n",
       "5731167    1424.0          2020             250.0    1855.0               8   \n",
       "\n",
       "         CARRIER_DELAY  WEATHER_DELAY  NAS_DELAY  SECURITY_DELAY  \\\n",
       "64000              4.0            0.0        0.0             0.0   \n",
       "6587376            0.0            0.0       15.0             0.0   \n",
       "848731             0.0            0.0        0.0             0.0   \n",
       "4423645            0.0            0.0       32.0             0.0   \n",
       "5731167            0.0            0.0        0.0             0.0   \n",
       "\n",
       "         LATE_AIRCRAFT_DELAY  TAXI_OUT_median  TAXI_IN_median  \n",
       "64000                   40.0             10.0             4.0  \n",
       "6587376                  0.0             15.0             5.0  \n",
       "848731                   0.0             10.0             4.0  \n",
       "4423645                  0.0             22.0             5.0  \n",
       "5731167                  0.0             14.0             4.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('ARR_DEL15', axis=1)\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2256637    0.0\n",
       "1611129    0.0\n",
       "4934618    1.0\n",
       "4793150    0.0\n",
       "5369030    0.0\n",
       "Name: ARR_DEL15, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['ARR_DEL15']\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_freq(col='', df=df):\n",
    "    i = 0\n",
    "    for v in df[col].value_counts().sort_index():\n",
    "        print(\"{} : {} records ({:.2f}%)\" \\\n",
    "              .format(df[col].value_counts().sort_index().index[i], v,  v / len(df) * 100))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONTH : 12 unique values\n",
      "1 : 7666 records (7.67%)\n",
      "2 : 7718 records (7.72%)\n",
      "3 : 8159 records (8.16%)\n",
      "4 : 8054 records (8.05%)\n",
      "5 : 8846 records (8.85%)\n",
      "6 : 9499 records (9.50%)\n",
      "7 : 9056 records (9.06%)\n",
      "8 : 9229 records (9.23%)\n",
      "9 : 7378 records (7.38%)\n",
      "10 : 8378 records (8.38%)\n",
      "11 : 7199 records (7.20%)\n",
      "12 : 8818 records (8.82%)\n",
      "\n",
      "DAY_OF_MONTH : 31 unique values\n",
      "1 : 3465 records (3.46%)\n",
      "2 : 3166 records (3.17%)\n",
      "3 : 3176 records (3.18%)\n",
      "4 : 3079 records (3.08%)\n",
      "5 : 3089 records (3.09%)\n",
      "6 : 3185 records (3.19%)\n",
      "7 : 3338 records (3.34%)\n",
      "8 : 3410 records (3.41%)\n",
      "9 : 3195 records (3.19%)\n",
      "10 : 3335 records (3.33%)\n",
      "11 : 3409 records (3.41%)\n",
      "12 : 3298 records (3.30%)\n",
      "13 : 3304 records (3.30%)\n",
      "14 : 3253 records (3.25%)\n",
      "15 : 3278 records (3.28%)\n",
      "16 : 3114 records (3.11%)\n",
      "17 : 3363 records (3.36%)\n",
      "18 : 3493 records (3.49%)\n",
      "19 : 3527 records (3.53%)\n",
      "20 : 3444 records (3.44%)\n",
      "21 : 3534 records (3.53%)\n",
      "22 : 3479 records (3.48%)\n",
      "23 : 3369 records (3.37%)\n",
      "24 : 3162 records (3.16%)\n",
      "25 : 3025 records (3.02%)\n",
      "26 : 3179 records (3.18%)\n",
      "27 : 3262 records (3.26%)\n",
      "28 : 3170 records (3.17%)\n",
      "29 : 3060 records (3.06%)\n",
      "30 : 3048 records (3.05%)\n",
      "31 : 1791 records (1.79%)\n",
      "\n",
      "DAY_OF_WEEK : 7 unique values\n",
      "1 : 15110 records (15.11%)\n",
      "2 : 14358 records (14.36%)\n",
      "3 : 14232 records (14.23%)\n",
      "4 : 15185 records (15.19%)\n",
      "5 : 15216 records (15.22%)\n",
      "6 : 11641 records (11.64%)\n",
      "7 : 14258 records (14.26%)\n",
      "\n",
      "OP_UNIQUE_CARRIER : 17 unique values\n",
      "9E : 3360 records (3.36%)\n",
      "AA : 13242 records (13.24%)\n",
      "AS : 3573 records (3.57%)\n",
      "B6 : 4551 records (4.55%)\n",
      "DL : 12496 records (12.50%)\n",
      "EV : 1933 records (1.93%)\n",
      "F9 : 2120 records (2.12%)\n",
      "G4 : 1528 records (1.53%)\n",
      "HA : 997 records (1.00%)\n",
      "MQ : 4548 records (4.55%)\n",
      "NK : 2762 records (2.76%)\n",
      "OH : 3844 records (3.84%)\n",
      "OO : 11081 records (11.08%)\n",
      "UA : 8882 records (8.88%)\n",
      "WN : 17675 records (17.68%)\n",
      "YV : 3088 records (3.09%)\n",
      "YX : 4320 records (4.32%)\n",
      "\n",
      "TAIL_NUM : 5666 unique values\n",
      "\n",
      "ORIGIN_CITY_MARKET_ID : 333 unique values\n",
      "\n",
      "ORIGIN : 359 unique values\n",
      "\n",
      "DEST_CITY_MARKET_ID : 331 unique values\n",
      "\n",
      "DEST : 357 unique values\n",
      "\n",
      "CRS_DEP_TIME : 1250 unique values\n",
      "\n",
      "DEP_TIME : 1373 unique values\n",
      "\n",
      "CRS_ARR_TIME : 1339 unique values\n",
      "\n",
      "ARR_DEL15 : 2 unique values\n",
      "0.0 : 50000 records (50.00%)\n",
      "1.0 : 50000 records (50.00%)\n",
      "\n",
      "CRS_ELAPSED_TIME : 481 unique values\n",
      "\n",
      "DISTANCE : 1514 unique values\n",
      "\n",
      "DISTANCE_GROUP : 11 unique values\n",
      "1 : 12371 records (12.37%)\n",
      "2 : 24154 records (24.15%)\n",
      "3 : 20417 records (20.42%)\n",
      "4 : 15391 records (15.39%)\n",
      "5 : 10601 records (10.60%)\n",
      "6 : 4382 records (4.38%)\n",
      "7 : 4316 records (4.32%)\n",
      "8 : 2135 records (2.14%)\n",
      "9 : 1568 records (1.57%)\n",
      "10 : 2648 records (2.65%)\n",
      "11 : 2017 records (2.02%)\n",
      "\n",
      "CARRIER_DELAY : 602 unique values\n",
      "\n",
      "WEATHER_DELAY : 336 unique values\n",
      "\n",
      "NAS_DELAY : 396 unique values\n",
      "\n",
      "SECURITY_DELAY : 56 unique values\n",
      "\n",
      "LATE_AIRCRAFT_DELAY : 449 unique values\n",
      "\n",
      "TAXI_OUT_median : 31 unique values\n",
      "5.0 : 2 records (0.00%)\n",
      "6.0 : 26 records (0.03%)\n",
      "7.0 : 36 records (0.04%)\n",
      "8.0 : 839 records (0.84%)\n",
      "8.5 : 6 records (0.01%)\n",
      "9.0 : 3749 records (3.75%)\n",
      "9.5 : 12 records (0.01%)\n",
      "10.0 : 7016 records (7.02%)\n",
      "10.5 : 1 records (0.00%)\n",
      "11.0 : 5174 records (5.17%)\n",
      "12.0 : 8046 records (8.05%)\n",
      "12.5 : 58 records (0.06%)\n",
      "13.0 : 7857 records (7.86%)\n",
      "13.5 : 44 records (0.04%)\n",
      "14.0 : 9106 records (9.11%)\n",
      "15.0 : 10761 records (10.76%)\n",
      "15.5 : 5 records (0.01%)\n",
      "16.0 : 12211 records (12.21%)\n",
      "16.5 : 9 records (0.01%)\n",
      "17.0 : 9463 records (9.46%)\n",
      "17.5 : 7 records (0.01%)\n",
      "18.0 : 4389 records (4.39%)\n",
      "19.0 : 5362 records (5.36%)\n",
      "20.0 : 4652 records (4.65%)\n",
      "21.0 : 4609 records (4.61%)\n",
      "22.0 : 2843 records (2.84%)\n",
      "23.0 : 1785 records (1.79%)\n",
      "24.0 : 986 records (0.99%)\n",
      "25.0 : 490 records (0.49%)\n",
      "26.0 : 75 records (0.07%)\n",
      "27.0 : 381 records (0.38%)\n",
      "\n",
      "TAXI_IN_median : 22 unique values\n",
      "2.0 : 407 records (0.41%)\n",
      "3.0 : 5856 records (5.86%)\n",
      "3.5 : 22 records (0.02%)\n",
      "4.0 : 17217 records (17.22%)\n",
      "4.5 : 3 records (0.00%)\n",
      "5.0 : 17029 records (17.03%)\n",
      "5.5 : 9 records (0.01%)\n",
      "6.0 : 14303 records (14.30%)\n",
      "6.5 : 6 records (0.01%)\n",
      "7.0 : 10176 records (10.18%)\n",
      "8.0 : 12360 records (12.36%)\n",
      "8.5 : 4 records (0.00%)\n",
      "9.0 : 8556 records (8.56%)\n",
      "9.5 : 1 records (0.00%)\n",
      "10.0 : 3061 records (3.06%)\n",
      "11.0 : 4012 records (4.01%)\n",
      "11.5 : 3 records (0.00%)\n",
      "12.0 : 2329 records (2.33%)\n",
      "13.0 : 3524 records (3.52%)\n",
      "14.0 : 1017 records (1.02%)\n",
      "15.0 : 101 records (0.10%)\n",
      "16.0 : 4 records (0.00%)\n",
      "\n",
      "Wall time: 725 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for col in df.columns:\n",
    "    print(col, ':', df[col].nunique(), 'unique values')\n",
    "    if df[col].nunique() < 50:\n",
    "        val_freq(col)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for col in X.columns:\n",
    "    a = df.groupby([col], as_index=False).agg(['sum'])['ARR_DEL15']\n",
    "    a.plot(legend=True)\n",
    "    plt.title(col)\n",
    "    b = df.groupby([col], as_index=False).agg(['count'])['ARR_DEL15']\n",
    "    b.plot(legend=True)\n",
    "    plt.title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "- En junio se concentra el mayor número de retrasos. Curiosamente, hay notablemente más vuelos en mayo, julio, agosto y octubre.\n",
    "- Los D, L, X y J se concentra el mayor número de retrasos (especialmente X). D y X es cuando más vuelos hay con diferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2836.60 MiB, increment: 0.14 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Guide to Scikit-learn Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the pipeline, let's split the data into a train and test set so that the performance of the model can be validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first step in building the pipeline is to define each transformer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, let's use the ColumnTransformer to apply the transformations to the correct columns in the dataframe. Before building this, the numeric and categorical columns shall be listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).drop(['ARR_DEL15'], axis=1).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a pipeline that combines the preprocessor created above with a classifier. In this case a simple RandomForestClassifier has been used to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(random_state=0))])\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A pipeline can also be used during the model selection process**. The following example code loops through a number of scikit-learn classifiers applying the transformations and training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n",
      "model score: 0.708\n",
      "0.6425848423320765 0.6799671142778844 0.619866093734386 0.7529740228210731 0.70805\n",
      "[[7958 2035]\n",
      " [3804 6203]] \n",
      "\n",
      "SVC(C=0.025, probability=True, random_state=0)\n",
      "model score: 0.941\n",
      "0.9031360026201587 0.9371780574584461 0.8817827520735485 1.0 0.94085\n",
      "[[9993    0]\n",
      " [1183 8824]] \n",
      "\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "model score: 1.000\n",
      "1.0 1.0 1.0 1.0 1.0\n",
      "[[ 9993     0]\n",
      " [    0 10007]] \n",
      "\n",
      "RandomForestClassifier(random_state=0)\n",
      "model score: 1.000\n",
      "0.9998201223168245 0.999850097436666 0.9998001399020685 0.9999000599640215 0.99985\n",
      "[[ 9992     1]\n",
      " [    2 10005]] \n",
      "\n",
      "AdaBoostClassifier(random_state=0)\n",
      "model score: 1.000\n",
      "1.0 1.0 1.0 1.0 1.0\n",
      "[[ 9993     0]\n",
      " [    0 10007]] \n",
      "\n",
      "GradientBoostingClassifier(random_state=0)\n",
      "model score: 1.000\n",
      "1.0 1.0 1.0 1.0 1.0\n",
      "[[ 9993     0]\n",
      " [    0 10007]] \n",
      "\n",
      "Wall time: 1h 7min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss, f1_score, fbeta_score, recall_score, precision_score, roc_auc_score, roc_curve, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True, random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    AdaBoostClassifier(random_state=0),\n",
    "    GradientBoostingClassifier(random_state=0)\n",
    "    ]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', classifier)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))    \n",
    "    # TEST !!!     \n",
    "    predictions = pipe.predict(X_test)\n",
    "    print(fbeta_score(y_test, predictions, beta=2), f1_score(y_test, predictions), recall_score(y_test, predictions), precision_score(y_test, predictions), accuracy_score(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions), \"\\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The pipeline can also be used in grid search** to find the best performing parameters. To do this, let's first create a parameter grid for the chosen model.\n",
    "\n",
    "*One important thing to note is that there is a need to append the name given to the classifier part of the pipeline to each parameter name. In the code above its name is ‘classifier’ so 'classifier__' has been added to each parameter.*\n",
    "\n",
    "Next a grid search object has been created, which includes the original pipeline. When fit is called, the transformations are applied to the data, before a cross-validated grid-search is performed over the parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__criterion': 'entropy', 'classifier__max_depth': 8, 'classifier__max_features': 'auto', 'classifier__n_estimators': 500}\n",
      "0.9399060952475031\n",
      "Wall time: 42min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = { \n",
    "    'classifier__n_estimators': [200, 500],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__max_depth' : [4,5,6,7,8],\n",
    "    'classifier__criterion' :['gini', 'entropy']}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'F1': 'f1', 'Precision': 'precision',\n",
    "           'Recall': 'recall', 'Accuracy': 'accuracy'}\n",
    "\n",
    "CV = GridSearchCV(rf, param_grid, n_jobs= 1, scoring=scoring, refit='F1')\n",
    "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
    "# parameter setting that has the best cross-validated AUC score.\n",
    "# That estimator is made available at ``gs.best_estimator_`` along with\n",
    "# parameters like ``gs.best_score_``, ``gs.best_params_`` and\n",
    "# ``gs.best_index_``\n",
    "\n",
    "CV.fit(X_train, y_train)  \n",
    "print(CV.best_params_)    \n",
    "print(CV.best_score_)\n",
    "CVscores = pd.DataFrame(CV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__criterion</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__max_features</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_AUC</th>\n",
       "      <th>split1_test_AUC</th>\n",
       "      <th>split2_test_AUC</th>\n",
       "      <th>split3_test_AUC</th>\n",
       "      <th>split4_test_AUC</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>std_test_AUC</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>split0_test_F1</th>\n",
       "      <th>split1_test_F1</th>\n",
       "      <th>split2_test_F1</th>\n",
       "      <th>split3_test_F1</th>\n",
       "      <th>split4_test_F1</th>\n",
       "      <th>mean_test_F1</th>\n",
       "      <th>std_test_F1</th>\n",
       "      <th>rank_test_F1</th>\n",
       "      <th>split0_test_Precision</th>\n",
       "      <th>split1_test_Precision</th>\n",
       "      <th>split2_test_Precision</th>\n",
       "      <th>split3_test_Precision</th>\n",
       "      <th>split4_test_Precision</th>\n",
       "      <th>mean_test_Precision</th>\n",
       "      <th>std_test_Precision</th>\n",
       "      <th>rank_test_Precision</th>\n",
       "      <th>split0_test_Recall</th>\n",
       "      <th>split1_test_Recall</th>\n",
       "      <th>split2_test_Recall</th>\n",
       "      <th>split3_test_Recall</th>\n",
       "      <th>split4_test_Recall</th>\n",
       "      <th>mean_test_Recall</th>\n",
       "      <th>std_test_Recall</th>\n",
       "      <th>rank_test_Recall</th>\n",
       "      <th>split0_test_Accuracy</th>\n",
       "      <th>split1_test_Accuracy</th>\n",
       "      <th>split2_test_Accuracy</th>\n",
       "      <th>split3_test_Accuracy</th>\n",
       "      <th>split4_test_Accuracy</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.488141</td>\n",
       "      <td>0.092392</td>\n",
       "      <td>0.802480</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.980038</td>\n",
       "      <td>0.989693</td>\n",
       "      <td>0.987174</td>\n",
       "      <td>0.985342</td>\n",
       "      <td>0.992402</td>\n",
       "      <td>0.986930</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>33</td>\n",
       "      <td>0.924417</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.926751</td>\n",
       "      <td>0.887157</td>\n",
       "      <td>0.922538</td>\n",
       "      <td>0.917887</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>39</td>\n",
       "      <td>0.996101</td>\n",
       "      <td>0.998418</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998875</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>37</td>\n",
       "      <td>0.862358</td>\n",
       "      <td>0.867858</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.797199</td>\n",
       "      <td>0.856214</td>\n",
       "      <td>0.849448</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>43</td>\n",
       "      <td>0.929500</td>\n",
       "      <td>0.933250</td>\n",
       "      <td>0.931750</td>\n",
       "      <td>0.898625</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.924250</td>\n",
       "      <td>0.012934</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.115060</td>\n",
       "      <td>0.102511</td>\n",
       "      <td>1.755488</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.987824</td>\n",
       "      <td>0.985908</td>\n",
       "      <td>0.999267</td>\n",
       "      <td>0.977656</td>\n",
       "      <td>0.992635</td>\n",
       "      <td>0.988658</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>29</td>\n",
       "      <td>0.925401</td>\n",
       "      <td>0.937670</td>\n",
       "      <td>0.951913</td>\n",
       "      <td>0.916966</td>\n",
       "      <td>0.926010</td>\n",
       "      <td>0.931592</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>19</td>\n",
       "      <td>0.999565</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>11</td>\n",
       "      <td>0.861483</td>\n",
       "      <td>0.882985</td>\n",
       "      <td>0.908239</td>\n",
       "      <td>0.847087</td>\n",
       "      <td>0.862216</td>\n",
       "      <td>0.872402</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>19</td>\n",
       "      <td>0.930562</td>\n",
       "      <td>0.941312</td>\n",
       "      <td>0.954125</td>\n",
       "      <td>0.923312</td>\n",
       "      <td>0.931125</td>\n",
       "      <td>0.936087</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.558100</td>\n",
       "      <td>0.055722</td>\n",
       "      <td>0.808039</td>\n",
       "      <td>0.008539</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.980038</td>\n",
       "      <td>0.989693</td>\n",
       "      <td>0.987174</td>\n",
       "      <td>0.985342</td>\n",
       "      <td>0.992402</td>\n",
       "      <td>0.986930</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>33</td>\n",
       "      <td>0.924417</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.926751</td>\n",
       "      <td>0.887157</td>\n",
       "      <td>0.922538</td>\n",
       "      <td>0.917887</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>39</td>\n",
       "      <td>0.996101</td>\n",
       "      <td>0.998418</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998875</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>37</td>\n",
       "      <td>0.862358</td>\n",
       "      <td>0.867858</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.797199</td>\n",
       "      <td>0.856214</td>\n",
       "      <td>0.849448</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>43</td>\n",
       "      <td>0.929500</td>\n",
       "      <td>0.933250</td>\n",
       "      <td>0.931750</td>\n",
       "      <td>0.898625</td>\n",
       "      <td>0.928125</td>\n",
       "      <td>0.924250</td>\n",
       "      <td>0.012934</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.179243</td>\n",
       "      <td>0.103143</td>\n",
       "      <td>1.763674</td>\n",
       "      <td>0.010803</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.987824</td>\n",
       "      <td>0.985908</td>\n",
       "      <td>0.999267</td>\n",
       "      <td>0.977656</td>\n",
       "      <td>0.992635</td>\n",
       "      <td>0.988658</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>29</td>\n",
       "      <td>0.925401</td>\n",
       "      <td>0.937670</td>\n",
       "      <td>0.951913</td>\n",
       "      <td>0.916966</td>\n",
       "      <td>0.926010</td>\n",
       "      <td>0.931592</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>19</td>\n",
       "      <td>0.999565</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>11</td>\n",
       "      <td>0.861483</td>\n",
       "      <td>0.882985</td>\n",
       "      <td>0.908239</td>\n",
       "      <td>0.847087</td>\n",
       "      <td>0.862216</td>\n",
       "      <td>0.872402</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>19</td>\n",
       "      <td>0.930562</td>\n",
       "      <td>0.941312</td>\n",
       "      <td>0.954125</td>\n",
       "      <td>0.923312</td>\n",
       "      <td>0.931125</td>\n",
       "      <td>0.936087</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.391912</td>\n",
       "      <td>0.245226</td>\n",
       "      <td>0.906746</td>\n",
       "      <td>0.079731</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.964750</td>\n",
       "      <td>0.965399</td>\n",
       "      <td>0.943888</td>\n",
       "      <td>0.770714</td>\n",
       "      <td>0.936039</td>\n",
       "      <td>0.916158</td>\n",
       "      <td>0.073626</td>\n",
       "      <td>60</td>\n",
       "      <td>0.832096</td>\n",
       "      <td>0.831511</td>\n",
       "      <td>0.875637</td>\n",
       "      <td>0.687545</td>\n",
       "      <td>0.856332</td>\n",
       "      <td>0.816624</td>\n",
       "      <td>0.066606</td>\n",
       "      <td>60</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.996855</td>\n",
       "      <td>0.958656</td>\n",
       "      <td>0.722230</td>\n",
       "      <td>0.959503</td>\n",
       "      <td>0.926716</td>\n",
       "      <td>0.103611</td>\n",
       "      <td>60</td>\n",
       "      <td>0.714339</td>\n",
       "      <td>0.713214</td>\n",
       "      <td>0.805851</td>\n",
       "      <td>0.656039</td>\n",
       "      <td>0.773193</td>\n",
       "      <td>0.732527</td>\n",
       "      <td>0.052124</td>\n",
       "      <td>60</td>\n",
       "      <td>0.855875</td>\n",
       "      <td>0.855500</td>\n",
       "      <td>0.885563</td>\n",
       "      <td>0.701937</td>\n",
       "      <td>0.870313</td>\n",
       "      <td>0.833838</td>\n",
       "      <td>0.066871</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.150817</td>\n",
       "      <td>0.144723</td>\n",
       "      <td>1.855787</td>\n",
       "      <td>0.120893</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.962033</td>\n",
       "      <td>0.964920</td>\n",
       "      <td>0.973272</td>\n",
       "      <td>0.974837</td>\n",
       "      <td>0.973774</td>\n",
       "      <td>0.969767</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>44</td>\n",
       "      <td>0.894993</td>\n",
       "      <td>0.905742</td>\n",
       "      <td>0.911496</td>\n",
       "      <td>0.884012</td>\n",
       "      <td>0.912803</td>\n",
       "      <td>0.901809</td>\n",
       "      <td>0.010894</td>\n",
       "      <td>48</td>\n",
       "      <td>0.989848</td>\n",
       "      <td>0.983876</td>\n",
       "      <td>0.984622</td>\n",
       "      <td>0.982716</td>\n",
       "      <td>0.978544</td>\n",
       "      <td>0.983921</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>45</td>\n",
       "      <td>0.816727</td>\n",
       "      <td>0.839105</td>\n",
       "      <td>0.848481</td>\n",
       "      <td>0.803326</td>\n",
       "      <td>0.855339</td>\n",
       "      <td>0.832596</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>48</td>\n",
       "      <td>0.904188</td>\n",
       "      <td>0.912687</td>\n",
       "      <td>0.917625</td>\n",
       "      <td>0.894625</td>\n",
       "      <td>0.918312</td>\n",
       "      <td>0.909488</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.355520</td>\n",
       "      <td>0.354599</td>\n",
       "      <td>0.993620</td>\n",
       "      <td>0.138960</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.984260</td>\n",
       "      <td>0.982880</td>\n",
       "      <td>0.992604</td>\n",
       "      <td>0.984915</td>\n",
       "      <td>0.987609</td>\n",
       "      <td>0.986454</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>35</td>\n",
       "      <td>0.932266</td>\n",
       "      <td>0.916052</td>\n",
       "      <td>0.932470</td>\n",
       "      <td>0.897588</td>\n",
       "      <td>0.917141</td>\n",
       "      <td>0.919103</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>0.998084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>21</td>\n",
       "      <td>0.873234</td>\n",
       "      <td>0.846481</td>\n",
       "      <td>0.873484</td>\n",
       "      <td>0.814204</td>\n",
       "      <td>0.846962</td>\n",
       "      <td>0.850873</td>\n",
       "      <td>0.021866</td>\n",
       "      <td>39</td>\n",
       "      <td>0.936562</td>\n",
       "      <td>0.922438</td>\n",
       "      <td>0.936750</td>\n",
       "      <td>0.907125</td>\n",
       "      <td>0.923500</td>\n",
       "      <td>0.925275</td>\n",
       "      <td>0.010952</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.634668</td>\n",
       "      <td>0.505099</td>\n",
       "      <td>1.968876</td>\n",
       "      <td>0.135414</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.987661</td>\n",
       "      <td>0.983131</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0.981209</td>\n",
       "      <td>0.996831</td>\n",
       "      <td>0.989454</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>25</td>\n",
       "      <td>0.928696</td>\n",
       "      <td>0.935505</td>\n",
       "      <td>0.946044</td>\n",
       "      <td>0.916317</td>\n",
       "      <td>0.926371</td>\n",
       "      <td>0.930587</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>23</td>\n",
       "      <td>0.998705</td>\n",
       "      <td>0.999148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999423</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>25</td>\n",
       "      <td>0.867858</td>\n",
       "      <td>0.879485</td>\n",
       "      <td>0.897612</td>\n",
       "      <td>0.846087</td>\n",
       "      <td>0.862841</td>\n",
       "      <td>0.870777</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>23</td>\n",
       "      <td>0.933375</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.948812</td>\n",
       "      <td>0.922750</td>\n",
       "      <td>0.931438</td>\n",
       "      <td>0.935150</td>\n",
       "      <td>0.008663</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.978940</td>\n",
       "      <td>0.120063</td>\n",
       "      <td>0.919668</td>\n",
       "      <td>0.079550</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.984260</td>\n",
       "      <td>0.982880</td>\n",
       "      <td>0.992604</td>\n",
       "      <td>0.984915</td>\n",
       "      <td>0.987609</td>\n",
       "      <td>0.986454</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>35</td>\n",
       "      <td>0.932266</td>\n",
       "      <td>0.916052</td>\n",
       "      <td>0.932470</td>\n",
       "      <td>0.897588</td>\n",
       "      <td>0.917141</td>\n",
       "      <td>0.919103</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>33</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>0.998084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>21</td>\n",
       "      <td>0.873234</td>\n",
       "      <td>0.846481</td>\n",
       "      <td>0.873484</td>\n",
       "      <td>0.814204</td>\n",
       "      <td>0.846962</td>\n",
       "      <td>0.850873</td>\n",
       "      <td>0.021866</td>\n",
       "      <td>39</td>\n",
       "      <td>0.936562</td>\n",
       "      <td>0.922438</td>\n",
       "      <td>0.936750</td>\n",
       "      <td>0.907125</td>\n",
       "      <td>0.923500</td>\n",
       "      <td>0.925275</td>\n",
       "      <td>0.010952</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.266565</td>\n",
       "      <td>0.761195</td>\n",
       "      <td>1.935856</td>\n",
       "      <td>0.111167</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.987661</td>\n",
       "      <td>0.983131</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0.981209</td>\n",
       "      <td>0.996831</td>\n",
       "      <td>0.989454</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>25</td>\n",
       "      <td>0.928696</td>\n",
       "      <td>0.935505</td>\n",
       "      <td>0.946044</td>\n",
       "      <td>0.916317</td>\n",
       "      <td>0.926371</td>\n",
       "      <td>0.930587</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>23</td>\n",
       "      <td>0.998705</td>\n",
       "      <td>0.999148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999423</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>25</td>\n",
       "      <td>0.867858</td>\n",
       "      <td>0.879485</td>\n",
       "      <td>0.897612</td>\n",
       "      <td>0.846087</td>\n",
       "      <td>0.862841</td>\n",
       "      <td>0.870777</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>23</td>\n",
       "      <td>0.933375</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.948812</td>\n",
       "      <td>0.922750</td>\n",
       "      <td>0.931438</td>\n",
       "      <td>0.935150</td>\n",
       "      <td>0.008663</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.363569</td>\n",
       "      <td>0.271059</td>\n",
       "      <td>0.839261</td>\n",
       "      <td>0.057591</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.939320</td>\n",
       "      <td>0.948704</td>\n",
       "      <td>0.934047</td>\n",
       "      <td>0.929644</td>\n",
       "      <td>0.959473</td>\n",
       "      <td>0.942237</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>56</td>\n",
       "      <td>0.850088</td>\n",
       "      <td>0.847182</td>\n",
       "      <td>0.861452</td>\n",
       "      <td>0.861331</td>\n",
       "      <td>0.881954</td>\n",
       "      <td>0.860401</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>57</td>\n",
       "      <td>0.979140</td>\n",
       "      <td>0.988496</td>\n",
       "      <td>0.923980</td>\n",
       "      <td>0.957906</td>\n",
       "      <td>0.951905</td>\n",
       "      <td>0.960285</td>\n",
       "      <td>0.022562</td>\n",
       "      <td>54</td>\n",
       "      <td>0.751094</td>\n",
       "      <td>0.741218</td>\n",
       "      <td>0.806851</td>\n",
       "      <td>0.782446</td>\n",
       "      <td>0.821580</td>\n",
       "      <td>0.780638</td>\n",
       "      <td>0.030963</td>\n",
       "      <td>58</td>\n",
       "      <td>0.867563</td>\n",
       "      <td>0.866313</td>\n",
       "      <td>0.870250</td>\n",
       "      <td>0.874062</td>\n",
       "      <td>0.890062</td>\n",
       "      <td>0.873650</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.914856</td>\n",
       "      <td>1.297999</td>\n",
       "      <td>2.286258</td>\n",
       "      <td>0.126297</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.963366</td>\n",
       "      <td>0.969604</td>\n",
       "      <td>0.951371</td>\n",
       "      <td>0.964205</td>\n",
       "      <td>0.968438</td>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>47</td>\n",
       "      <td>0.902579</td>\n",
       "      <td>0.916061</td>\n",
       "      <td>0.887743</td>\n",
       "      <td>0.872522</td>\n",
       "      <td>0.908920</td>\n",
       "      <td>0.897565</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>49</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.991411</td>\n",
       "      <td>0.942051</td>\n",
       "      <td>0.987828</td>\n",
       "      <td>0.981162</td>\n",
       "      <td>0.979169</td>\n",
       "      <td>0.019020</td>\n",
       "      <td>48</td>\n",
       "      <td>0.826978</td>\n",
       "      <td>0.851356</td>\n",
       "      <td>0.839355</td>\n",
       "      <td>0.781320</td>\n",
       "      <td>0.846587</td>\n",
       "      <td>0.829119</td>\n",
       "      <td>0.025273</td>\n",
       "      <td>49</td>\n",
       "      <td>0.910750</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.893875</td>\n",
       "      <td>0.885875</td>\n",
       "      <td>0.915188</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.013520</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.426586</td>\n",
       "      <td>1.120434</td>\n",
       "      <td>1.345236</td>\n",
       "      <td>0.076060</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.980402</td>\n",
       "      <td>0.989896</td>\n",
       "      <td>0.994966</td>\n",
       "      <td>0.984107</td>\n",
       "      <td>0.995775</td>\n",
       "      <td>0.989029</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>27</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.924390</td>\n",
       "      <td>0.936020</td>\n",
       "      <td>0.901791</td>\n",
       "      <td>0.936436</td>\n",
       "      <td>0.926228</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>31</td>\n",
       "      <td>0.996164</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999054</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>35</td>\n",
       "      <td>0.876485</td>\n",
       "      <td>0.859732</td>\n",
       "      <td>0.879735</td>\n",
       "      <td>0.821455</td>\n",
       "      <td>0.880470</td>\n",
       "      <td>0.863575</td>\n",
       "      <td>0.022370</td>\n",
       "      <td>31</td>\n",
       "      <td>0.936562</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.939875</td>\n",
       "      <td>0.910563</td>\n",
       "      <td>0.940250</td>\n",
       "      <td>0.931387</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.493801</td>\n",
       "      <td>1.999545</td>\n",
       "      <td>2.466302</td>\n",
       "      <td>0.436478</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.989283</td>\n",
       "      <td>0.990500</td>\n",
       "      <td>0.998647</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>0.996940</td>\n",
       "      <td>0.990392</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>17</td>\n",
       "      <td>0.929971</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.942491</td>\n",
       "      <td>0.917302</td>\n",
       "      <td>0.934665</td>\n",
       "      <td>0.931711</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>31</td>\n",
       "      <td>0.869109</td>\n",
       "      <td>0.876610</td>\n",
       "      <td>0.891236</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.877344</td>\n",
       "      <td>0.872752</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>17</td>\n",
       "      <td>0.934562</td>\n",
       "      <td>0.938187</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.923438</td>\n",
       "      <td>0.938688</td>\n",
       "      <td>0.936100</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.265116</td>\n",
       "      <td>0.181948</td>\n",
       "      <td>0.855811</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.980402</td>\n",
       "      <td>0.989896</td>\n",
       "      <td>0.994966</td>\n",
       "      <td>0.984107</td>\n",
       "      <td>0.995775</td>\n",
       "      <td>0.989029</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>27</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>0.924390</td>\n",
       "      <td>0.936020</td>\n",
       "      <td>0.901791</td>\n",
       "      <td>0.936436</td>\n",
       "      <td>0.926228</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>31</td>\n",
       "      <td>0.996164</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999054</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>35</td>\n",
       "      <td>0.876485</td>\n",
       "      <td>0.859732</td>\n",
       "      <td>0.879735</td>\n",
       "      <td>0.821455</td>\n",
       "      <td>0.880470</td>\n",
       "      <td>0.863575</td>\n",
       "      <td>0.022370</td>\n",
       "      <td>31</td>\n",
       "      <td>0.936562</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.939875</td>\n",
       "      <td>0.910563</td>\n",
       "      <td>0.940250</td>\n",
       "      <td>0.931387</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.998124</td>\n",
       "      <td>0.407744</td>\n",
       "      <td>1.926709</td>\n",
       "      <td>0.048040</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.989283</td>\n",
       "      <td>0.990500</td>\n",
       "      <td>0.998647</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>0.996940</td>\n",
       "      <td>0.990392</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>17</td>\n",
       "      <td>0.929971</td>\n",
       "      <td>0.934124</td>\n",
       "      <td>0.942491</td>\n",
       "      <td>0.917302</td>\n",
       "      <td>0.934665</td>\n",
       "      <td>0.931711</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999327</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>31</td>\n",
       "      <td>0.869109</td>\n",
       "      <td>0.876610</td>\n",
       "      <td>0.891236</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.877344</td>\n",
       "      <td>0.872752</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>17</td>\n",
       "      <td>0.934562</td>\n",
       "      <td>0.938187</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.923438</td>\n",
       "      <td>0.938688</td>\n",
       "      <td>0.936100</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.221535</td>\n",
       "      <td>0.062360</td>\n",
       "      <td>0.826723</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.936242</td>\n",
       "      <td>0.971230</td>\n",
       "      <td>0.930078</td>\n",
       "      <td>0.897042</td>\n",
       "      <td>0.955036</td>\n",
       "      <td>0.937926</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>58</td>\n",
       "      <td>0.855188</td>\n",
       "      <td>0.877426</td>\n",
       "      <td>0.860019</td>\n",
       "      <td>0.804484</td>\n",
       "      <td>0.897167</td>\n",
       "      <td>0.858857</td>\n",
       "      <td>0.030931</td>\n",
       "      <td>58</td>\n",
       "      <td>0.968528</td>\n",
       "      <td>0.993362</td>\n",
       "      <td>0.935617</td>\n",
       "      <td>0.907762</td>\n",
       "      <td>0.950861</td>\n",
       "      <td>0.951226</td>\n",
       "      <td>0.029009</td>\n",
       "      <td>56</td>\n",
       "      <td>0.765596</td>\n",
       "      <td>0.785723</td>\n",
       "      <td>0.795724</td>\n",
       "      <td>0.722306</td>\n",
       "      <td>0.849212</td>\n",
       "      <td>0.783712</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>56</td>\n",
       "      <td>0.870375</td>\n",
       "      <td>0.890250</td>\n",
       "      <td>0.870500</td>\n",
       "      <td>0.824500</td>\n",
       "      <td>0.902687</td>\n",
       "      <td>0.871663</td>\n",
       "      <td>0.026591</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.421788</td>\n",
       "      <td>0.060880</td>\n",
       "      <td>1.915855</td>\n",
       "      <td>0.173057</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.953849</td>\n",
       "      <td>0.981291</td>\n",
       "      <td>0.955820</td>\n",
       "      <td>0.964321</td>\n",
       "      <td>0.955463</td>\n",
       "      <td>0.962149</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>49</td>\n",
       "      <td>0.905681</td>\n",
       "      <td>0.927097</td>\n",
       "      <td>0.903234</td>\n",
       "      <td>0.887811</td>\n",
       "      <td>0.899377</td>\n",
       "      <td>0.904640</td>\n",
       "      <td>0.012793</td>\n",
       "      <td>46</td>\n",
       "      <td>0.983731</td>\n",
       "      <td>0.995837</td>\n",
       "      <td>0.963446</td>\n",
       "      <td>0.978759</td>\n",
       "      <td>0.969504</td>\n",
       "      <td>0.978255</td>\n",
       "      <td>0.011272</td>\n",
       "      <td>50</td>\n",
       "      <td>0.839105</td>\n",
       "      <td>0.867233</td>\n",
       "      <td>0.850106</td>\n",
       "      <td>0.812328</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.841496</td>\n",
       "      <td>0.017893</td>\n",
       "      <td>45</td>\n",
       "      <td>0.912625</td>\n",
       "      <td>0.931813</td>\n",
       "      <td>0.908937</td>\n",
       "      <td>0.897375</td>\n",
       "      <td>0.906188</td>\n",
       "      <td>0.911388</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.434280</td>\n",
       "      <td>0.028968</td>\n",
       "      <td>0.876324</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.987892</td>\n",
       "      <td>0.994484</td>\n",
       "      <td>0.997761</td>\n",
       "      <td>0.987837</td>\n",
       "      <td>0.991362</td>\n",
       "      <td>0.991867</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>13</td>\n",
       "      <td>0.936874</td>\n",
       "      <td>0.922403</td>\n",
       "      <td>0.934248</td>\n",
       "      <td>0.908731</td>\n",
       "      <td>0.936224</td>\n",
       "      <td>0.927696</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>27</td>\n",
       "      <td>0.998726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>7</td>\n",
       "      <td>0.882235</td>\n",
       "      <td>0.855982</td>\n",
       "      <td>0.876610</td>\n",
       "      <td>0.832833</td>\n",
       "      <td>0.880095</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.018837</td>\n",
       "      <td>27</td>\n",
       "      <td>0.940562</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.938312</td>\n",
       "      <td>0.916375</td>\n",
       "      <td>0.940063</td>\n",
       "      <td>0.932662</td>\n",
       "      <td>0.009339</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.515123</td>\n",
       "      <td>0.256169</td>\n",
       "      <td>1.966312</td>\n",
       "      <td>0.016123</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.990508</td>\n",
       "      <td>0.992176</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.985371</td>\n",
       "      <td>0.998855</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9</td>\n",
       "      <td>0.933227</td>\n",
       "      <td>0.925371</td>\n",
       "      <td>0.938147</td>\n",
       "      <td>0.925802</td>\n",
       "      <td>0.939187</td>\n",
       "      <td>0.932347</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>13</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999859</td>\n",
       "      <td>0.998842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>17</td>\n",
       "      <td>0.875359</td>\n",
       "      <td>0.861108</td>\n",
       "      <td>0.883610</td>\n",
       "      <td>0.862716</td>\n",
       "      <td>0.885346</td>\n",
       "      <td>0.873628</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>13</td>\n",
       "      <td>0.937375</td>\n",
       "      <td>0.930562</td>\n",
       "      <td>0.941750</td>\n",
       "      <td>0.930875</td>\n",
       "      <td>0.942688</td>\n",
       "      <td>0.936650</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.517164</td>\n",
       "      <td>0.088713</td>\n",
       "      <td>0.880323</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.987892</td>\n",
       "      <td>0.994484</td>\n",
       "      <td>0.997761</td>\n",
       "      <td>0.987837</td>\n",
       "      <td>0.991362</td>\n",
       "      <td>0.991867</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>13</td>\n",
       "      <td>0.936874</td>\n",
       "      <td>0.922403</td>\n",
       "      <td>0.934248</td>\n",
       "      <td>0.908731</td>\n",
       "      <td>0.936224</td>\n",
       "      <td>0.927696</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>27</td>\n",
       "      <td>0.998726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>7</td>\n",
       "      <td>0.882235</td>\n",
       "      <td>0.855982</td>\n",
       "      <td>0.876610</td>\n",
       "      <td>0.832833</td>\n",
       "      <td>0.880095</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.018837</td>\n",
       "      <td>27</td>\n",
       "      <td>0.940562</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.938312</td>\n",
       "      <td>0.916375</td>\n",
       "      <td>0.940063</td>\n",
       "      <td>0.932662</td>\n",
       "      <td>0.009339</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.515616</td>\n",
       "      <td>0.374850</td>\n",
       "      <td>1.980994</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.990508</td>\n",
       "      <td>0.992176</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>0.985371</td>\n",
       "      <td>0.998855</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9</td>\n",
       "      <td>0.933227</td>\n",
       "      <td>0.925371</td>\n",
       "      <td>0.938147</td>\n",
       "      <td>0.925802</td>\n",
       "      <td>0.939187</td>\n",
       "      <td>0.932347</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>13</td>\n",
       "      <td>0.999286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999859</td>\n",
       "      <td>0.998842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999597</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>17</td>\n",
       "      <td>0.875359</td>\n",
       "      <td>0.861108</td>\n",
       "      <td>0.883610</td>\n",
       "      <td>0.862716</td>\n",
       "      <td>0.885346</td>\n",
       "      <td>0.873628</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>13</td>\n",
       "      <td>0.937375</td>\n",
       "      <td>0.930562</td>\n",
       "      <td>0.941750</td>\n",
       "      <td>0.930875</td>\n",
       "      <td>0.942688</td>\n",
       "      <td>0.936650</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.347149</td>\n",
       "      <td>0.035619</td>\n",
       "      <td>0.908067</td>\n",
       "      <td>0.104872</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.931874</td>\n",
       "      <td>0.966468</td>\n",
       "      <td>0.914262</td>\n",
       "      <td>0.947041</td>\n",
       "      <td>0.966785</td>\n",
       "      <td>0.945286</td>\n",
       "      <td>0.020280</td>\n",
       "      <td>54</td>\n",
       "      <td>0.857948</td>\n",
       "      <td>0.883731</td>\n",
       "      <td>0.832467</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>0.909956</td>\n",
       "      <td>0.868435</td>\n",
       "      <td>0.026340</td>\n",
       "      <td>54</td>\n",
       "      <td>0.952686</td>\n",
       "      <td>0.987647</td>\n",
       "      <td>0.879171</td>\n",
       "      <td>0.936419</td>\n",
       "      <td>0.981061</td>\n",
       "      <td>0.947397</td>\n",
       "      <td>0.038876</td>\n",
       "      <td>58</td>\n",
       "      <td>0.780348</td>\n",
       "      <td>0.799600</td>\n",
       "      <td>0.790474</td>\n",
       "      <td>0.791823</td>\n",
       "      <td>0.848462</td>\n",
       "      <td>0.802141</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>54</td>\n",
       "      <td>0.870812</td>\n",
       "      <td>0.894813</td>\n",
       "      <td>0.840938</td>\n",
       "      <td>0.869062</td>\n",
       "      <td>0.916063</td>\n",
       "      <td>0.878337</td>\n",
       "      <td>0.025440</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.656598</td>\n",
       "      <td>0.096133</td>\n",
       "      <td>1.908187</td>\n",
       "      <td>0.061246</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.970587</td>\n",
       "      <td>0.979183</td>\n",
       "      <td>0.964560</td>\n",
       "      <td>0.969242</td>\n",
       "      <td>0.957812</td>\n",
       "      <td>0.968277</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>46</td>\n",
       "      <td>0.920669</td>\n",
       "      <td>0.925361</td>\n",
       "      <td>0.912616</td>\n",
       "      <td>0.907775</td>\n",
       "      <td>0.896406</td>\n",
       "      <td>0.912566</td>\n",
       "      <td>0.010134</td>\n",
       "      <td>44</td>\n",
       "      <td>0.994919</td>\n",
       "      <td>0.994966</td>\n",
       "      <td>0.973233</td>\n",
       "      <td>0.967861</td>\n",
       "      <td>0.983717</td>\n",
       "      <td>0.982939</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>46</td>\n",
       "      <td>0.856732</td>\n",
       "      <td>0.864858</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>0.854714</td>\n",
       "      <td>0.823331</td>\n",
       "      <td>0.851748</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>35</td>\n",
       "      <td>0.926188</td>\n",
       "      <td>0.930250</td>\n",
       "      <td>0.917750</td>\n",
       "      <td>0.913188</td>\n",
       "      <td>0.904875</td>\n",
       "      <td>0.918450</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.785684</td>\n",
       "      <td>0.060217</td>\n",
       "      <td>0.902096</td>\n",
       "      <td>0.008478</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.990959</td>\n",
       "      <td>0.996936</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.992687</td>\n",
       "      <td>0.995389</td>\n",
       "      <td>0.995102</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>5</td>\n",
       "      <td>0.941394</td>\n",
       "      <td>0.930329</td>\n",
       "      <td>0.953079</td>\n",
       "      <td>0.928528</td>\n",
       "      <td>0.940943</td>\n",
       "      <td>0.938855</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>3</td>\n",
       "      <td>0.889611</td>\n",
       "      <td>0.869734</td>\n",
       "      <td>0.910364</td>\n",
       "      <td>0.866592</td>\n",
       "      <td>0.888472</td>\n",
       "      <td>0.884954</td>\n",
       "      <td>0.015802</td>\n",
       "      <td>5</td>\n",
       "      <td>0.944625</td>\n",
       "      <td>0.934875</td>\n",
       "      <td>0.955187</td>\n",
       "      <td>0.933312</td>\n",
       "      <td>0.944250</td>\n",
       "      <td>0.942450</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11.166672</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>2.020614</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.995135</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>0.993399</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.996425</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939828</td>\n",
       "      <td>0.941861</td>\n",
       "      <td>0.944869</td>\n",
       "      <td>0.933600</td>\n",
       "      <td>0.939187</td>\n",
       "      <td>0.939869</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886486</td>\n",
       "      <td>0.890111</td>\n",
       "      <td>0.895612</td>\n",
       "      <td>0.875469</td>\n",
       "      <td>0.885346</td>\n",
       "      <td>0.886605</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>3</td>\n",
       "      <td>0.943250</td>\n",
       "      <td>0.945063</td>\n",
       "      <td>0.947750</td>\n",
       "      <td>0.937750</td>\n",
       "      <td>0.942688</td>\n",
       "      <td>0.943300</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.756356</td>\n",
       "      <td>0.065047</td>\n",
       "      <td>0.908038</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.990959</td>\n",
       "      <td>0.996936</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0.992687</td>\n",
       "      <td>0.995389</td>\n",
       "      <td>0.995102</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>5</td>\n",
       "      <td>0.941394</td>\n",
       "      <td>0.930329</td>\n",
       "      <td>0.953079</td>\n",
       "      <td>0.928528</td>\n",
       "      <td>0.940943</td>\n",
       "      <td>0.938855</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>3</td>\n",
       "      <td>0.889611</td>\n",
       "      <td>0.869734</td>\n",
       "      <td>0.910364</td>\n",
       "      <td>0.866592</td>\n",
       "      <td>0.888472</td>\n",
       "      <td>0.884954</td>\n",
       "      <td>0.015802</td>\n",
       "      <td>5</td>\n",
       "      <td>0.944625</td>\n",
       "      <td>0.934875</td>\n",
       "      <td>0.955187</td>\n",
       "      <td>0.933312</td>\n",
       "      <td>0.944250</td>\n",
       "      <td>0.942450</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11.196496</td>\n",
       "      <td>0.117142</td>\n",
       "      <td>2.045970</td>\n",
       "      <td>0.087114</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.995135</td>\n",
       "      <td>0.995504</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>0.993399</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.996425</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939828</td>\n",
       "      <td>0.941861</td>\n",
       "      <td>0.944869</td>\n",
       "      <td>0.933600</td>\n",
       "      <td>0.939187</td>\n",
       "      <td>0.939869</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886486</td>\n",
       "      <td>0.890111</td>\n",
       "      <td>0.895612</td>\n",
       "      <td>0.875469</td>\n",
       "      <td>0.885346</td>\n",
       "      <td>0.886605</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>3</td>\n",
       "      <td>0.943250</td>\n",
       "      <td>0.945063</td>\n",
       "      <td>0.947750</td>\n",
       "      <td>0.937750</td>\n",
       "      <td>0.942688</td>\n",
       "      <td>0.943300</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.417113</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>0.871325</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.951495</td>\n",
       "      <td>0.977023</td>\n",
       "      <td>0.921161</td>\n",
       "      <td>0.973759</td>\n",
       "      <td>0.954711</td>\n",
       "      <td>0.955630</td>\n",
       "      <td>0.019962</td>\n",
       "      <td>51</td>\n",
       "      <td>0.879351</td>\n",
       "      <td>0.886948</td>\n",
       "      <td>0.840981</td>\n",
       "      <td>0.900880</td>\n",
       "      <td>0.891451</td>\n",
       "      <td>0.879922</td>\n",
       "      <td>0.020680</td>\n",
       "      <td>51</td>\n",
       "      <td>0.987233</td>\n",
       "      <td>0.995333</td>\n",
       "      <td>0.908946</td>\n",
       "      <td>0.982428</td>\n",
       "      <td>0.948393</td>\n",
       "      <td>0.964466</td>\n",
       "      <td>0.032046</td>\n",
       "      <td>51</td>\n",
       "      <td>0.792724</td>\n",
       "      <td>0.799850</td>\n",
       "      <td>0.782473</td>\n",
       "      <td>0.831833</td>\n",
       "      <td>0.840960</td>\n",
       "      <td>0.809568</td>\n",
       "      <td>0.022775</td>\n",
       "      <td>51</td>\n",
       "      <td>0.891250</td>\n",
       "      <td>0.898062</td>\n",
       "      <td>0.852062</td>\n",
       "      <td>0.908500</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.889500</td>\n",
       "      <td>0.019519</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.972149</td>\n",
       "      <td>0.116195</td>\n",
       "      <td>1.945083</td>\n",
       "      <td>0.026592</td>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'gini', 'classifier_...</td>\n",
       "      <td>0.962318</td>\n",
       "      <td>0.982019</td>\n",
       "      <td>0.969416</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>0.963613</td>\n",
       "      <td>0.970972</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>41</td>\n",
       "      <td>0.913745</td>\n",
       "      <td>0.925265</td>\n",
       "      <td>0.917192</td>\n",
       "      <td>0.918374</td>\n",
       "      <td>0.899074</td>\n",
       "      <td>0.914730</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>42</td>\n",
       "      <td>0.993829</td>\n",
       "      <td>0.998407</td>\n",
       "      <td>0.976426</td>\n",
       "      <td>0.984968</td>\n",
       "      <td>0.987287</td>\n",
       "      <td>0.988183</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>41</td>\n",
       "      <td>0.845606</td>\n",
       "      <td>0.862108</td>\n",
       "      <td>0.864733</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.825331</td>\n",
       "      <td>0.851599</td>\n",
       "      <td>0.014718</td>\n",
       "      <td>36</td>\n",
       "      <td>0.920188</td>\n",
       "      <td>0.930375</td>\n",
       "      <td>0.921937</td>\n",
       "      <td>0.923562</td>\n",
       "      <td>0.907375</td>\n",
       "      <td>0.920687</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.537754</td>\n",
       "      <td>0.074109</td>\n",
       "      <td>0.805731</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.976082</td>\n",
       "      <td>0.990090</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.982853</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.985327</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>39</td>\n",
       "      <td>0.924229</td>\n",
       "      <td>0.932009</td>\n",
       "      <td>0.925690</td>\n",
       "      <td>0.886693</td>\n",
       "      <td>0.924349</td>\n",
       "      <td>0.918594</td>\n",
       "      <td>0.016204</td>\n",
       "      <td>37</td>\n",
       "      <td>0.993673</td>\n",
       "      <td>0.998286</td>\n",
       "      <td>0.999565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998305</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>39</td>\n",
       "      <td>0.863858</td>\n",
       "      <td>0.873984</td>\n",
       "      <td>0.861983</td>\n",
       "      <td>0.796449</td>\n",
       "      <td>0.859340</td>\n",
       "      <td>0.851123</td>\n",
       "      <td>0.027783</td>\n",
       "      <td>37</td>\n",
       "      <td>0.929188</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>0.930813</td>\n",
       "      <td>0.898250</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.924837</td>\n",
       "      <td>0.013530</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8.209700</td>\n",
       "      <td>0.106726</td>\n",
       "      <td>1.779850</td>\n",
       "      <td>0.008959</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.986427</td>\n",
       "      <td>0.985445</td>\n",
       "      <td>0.999198</td>\n",
       "      <td>0.978642</td>\n",
       "      <td>0.992775</td>\n",
       "      <td>0.988497</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>31</td>\n",
       "      <td>0.926234</td>\n",
       "      <td>0.938172</td>\n",
       "      <td>0.951157</td>\n",
       "      <td>0.918053</td>\n",
       "      <td>0.926659</td>\n",
       "      <td>0.932055</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>15</td>\n",
       "      <td>0.998987</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>19</td>\n",
       "      <td>0.863358</td>\n",
       "      <td>0.883985</td>\n",
       "      <td>0.906863</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.863341</td>\n",
       "      <td>0.873277</td>\n",
       "      <td>0.020185</td>\n",
       "      <td>15</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.941750</td>\n",
       "      <td>0.953438</td>\n",
       "      <td>0.924250</td>\n",
       "      <td>0.931688</td>\n",
       "      <td>0.936475</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.562919</td>\n",
       "      <td>0.090732</td>\n",
       "      <td>0.810300</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.976082</td>\n",
       "      <td>0.990090</td>\n",
       "      <td>0.986801</td>\n",
       "      <td>0.982853</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.985327</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>39</td>\n",
       "      <td>0.924229</td>\n",
       "      <td>0.932009</td>\n",
       "      <td>0.925690</td>\n",
       "      <td>0.886693</td>\n",
       "      <td>0.924349</td>\n",
       "      <td>0.918594</td>\n",
       "      <td>0.016204</td>\n",
       "      <td>37</td>\n",
       "      <td>0.993673</td>\n",
       "      <td>0.998286</td>\n",
       "      <td>0.999565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998305</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>39</td>\n",
       "      <td>0.863858</td>\n",
       "      <td>0.873984</td>\n",
       "      <td>0.861983</td>\n",
       "      <td>0.796449</td>\n",
       "      <td>0.859340</td>\n",
       "      <td>0.851123</td>\n",
       "      <td>0.027783</td>\n",
       "      <td>37</td>\n",
       "      <td>0.929188</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>0.930813</td>\n",
       "      <td>0.898250</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.924837</td>\n",
       "      <td>0.013530</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8.239986</td>\n",
       "      <td>0.126649</td>\n",
       "      <td>1.766291</td>\n",
       "      <td>0.017286</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.986427</td>\n",
       "      <td>0.985445</td>\n",
       "      <td>0.999198</td>\n",
       "      <td>0.978642</td>\n",
       "      <td>0.992775</td>\n",
       "      <td>0.988497</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>31</td>\n",
       "      <td>0.926234</td>\n",
       "      <td>0.938172</td>\n",
       "      <td>0.951157</td>\n",
       "      <td>0.918053</td>\n",
       "      <td>0.926659</td>\n",
       "      <td>0.932055</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>15</td>\n",
       "      <td>0.998987</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>19</td>\n",
       "      <td>0.863358</td>\n",
       "      <td>0.883985</td>\n",
       "      <td>0.906863</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.863341</td>\n",
       "      <td>0.873277</td>\n",
       "      <td>0.020185</td>\n",
       "      <td>15</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.941750</td>\n",
       "      <td>0.953438</td>\n",
       "      <td>0.924250</td>\n",
       "      <td>0.931688</td>\n",
       "      <td>0.936475</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.016032</td>\n",
       "      <td>0.020733</td>\n",
       "      <td>0.801226</td>\n",
       "      <td>0.023881</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.963338</td>\n",
       "      <td>0.966672</td>\n",
       "      <td>0.944452</td>\n",
       "      <td>0.770783</td>\n",
       "      <td>0.936888</td>\n",
       "      <td>0.916427</td>\n",
       "      <td>0.073677</td>\n",
       "      <td>59</td>\n",
       "      <td>0.830879</td>\n",
       "      <td>0.831682</td>\n",
       "      <td>0.878360</td>\n",
       "      <td>0.689108</td>\n",
       "      <td>0.858669</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.066728</td>\n",
       "      <td>59</td>\n",
       "      <td>0.996503</td>\n",
       "      <td>0.996856</td>\n",
       "      <td>0.960939</td>\n",
       "      <td>0.725076</td>\n",
       "      <td>0.964030</td>\n",
       "      <td>0.928681</td>\n",
       "      <td>0.102949</td>\n",
       "      <td>59</td>\n",
       "      <td>0.712464</td>\n",
       "      <td>0.713464</td>\n",
       "      <td>0.808851</td>\n",
       "      <td>0.656539</td>\n",
       "      <td>0.774069</td>\n",
       "      <td>0.733077</td>\n",
       "      <td>0.053084</td>\n",
       "      <td>59</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.855625</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.703875</td>\n",
       "      <td>0.872625</td>\n",
       "      <td>0.835025</td>\n",
       "      <td>0.066699</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.824350</td>\n",
       "      <td>0.029113</td>\n",
       "      <td>1.710575</td>\n",
       "      <td>0.016521</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.960968</td>\n",
       "      <td>0.965016</td>\n",
       "      <td>0.973502</td>\n",
       "      <td>0.975616</td>\n",
       "      <td>0.974889</td>\n",
       "      <td>0.969998</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>43</td>\n",
       "      <td>0.894600</td>\n",
       "      <td>0.906845</td>\n",
       "      <td>0.912311</td>\n",
       "      <td>0.884224</td>\n",
       "      <td>0.913786</td>\n",
       "      <td>0.902353</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>47</td>\n",
       "      <td>0.989989</td>\n",
       "      <td>0.985620</td>\n",
       "      <td>0.984506</td>\n",
       "      <td>0.983614</td>\n",
       "      <td>0.979823</td>\n",
       "      <td>0.984710</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>43</td>\n",
       "      <td>0.815977</td>\n",
       "      <td>0.839730</td>\n",
       "      <td>0.849981</td>\n",
       "      <td>0.803076</td>\n",
       "      <td>0.856089</td>\n",
       "      <td>0.832971</td>\n",
       "      <td>0.020258</td>\n",
       "      <td>47</td>\n",
       "      <td>0.903875</td>\n",
       "      <td>0.913750</td>\n",
       "      <td>0.918312</td>\n",
       "      <td>0.894875</td>\n",
       "      <td>0.919250</td>\n",
       "      <td>0.910013</td>\n",
       "      <td>0.009327</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.775889</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>0.826089</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.984297</td>\n",
       "      <td>0.980256</td>\n",
       "      <td>0.992083</td>\n",
       "      <td>0.985053</td>\n",
       "      <td>0.985151</td>\n",
       "      <td>0.985368</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>37</td>\n",
       "      <td>0.930661</td>\n",
       "      <td>0.914901</td>\n",
       "      <td>0.932542</td>\n",
       "      <td>0.899484</td>\n",
       "      <td>0.917163</td>\n",
       "      <td>0.918950</td>\n",
       "      <td>0.012003</td>\n",
       "      <td>35</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.997785</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>29</td>\n",
       "      <td>0.870859</td>\n",
       "      <td>0.844731</td>\n",
       "      <td>0.873609</td>\n",
       "      <td>0.817329</td>\n",
       "      <td>0.847212</td>\n",
       "      <td>0.850748</td>\n",
       "      <td>0.020458</td>\n",
       "      <td>41</td>\n",
       "      <td>0.935125</td>\n",
       "      <td>0.921438</td>\n",
       "      <td>0.936813</td>\n",
       "      <td>0.908687</td>\n",
       "      <td>0.923500</td>\n",
       "      <td>0.925113</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8.877163</td>\n",
       "      <td>0.212326</td>\n",
       "      <td>1.855652</td>\n",
       "      <td>0.030644</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.986178</td>\n",
       "      <td>0.985267</td>\n",
       "      <td>0.998583</td>\n",
       "      <td>0.981253</td>\n",
       "      <td>0.997039</td>\n",
       "      <td>0.989664</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>21</td>\n",
       "      <td>0.928653</td>\n",
       "      <td>0.933777</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.919120</td>\n",
       "      <td>0.926299</td>\n",
       "      <td>0.931070</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>21</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999364</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>27</td>\n",
       "      <td>0.868109</td>\n",
       "      <td>0.876110</td>\n",
       "      <td>0.900238</td>\n",
       "      <td>0.851088</td>\n",
       "      <td>0.862716</td>\n",
       "      <td>0.871652</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>21</td>\n",
       "      <td>0.933312</td>\n",
       "      <td>0.937875</td>\n",
       "      <td>0.950125</td>\n",
       "      <td>0.925125</td>\n",
       "      <td>0.931375</td>\n",
       "      <td>0.935562</td>\n",
       "      <td>0.008354</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.782334</td>\n",
       "      <td>0.067291</td>\n",
       "      <td>0.829088</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.984297</td>\n",
       "      <td>0.980256</td>\n",
       "      <td>0.992083</td>\n",
       "      <td>0.985053</td>\n",
       "      <td>0.985151</td>\n",
       "      <td>0.985368</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>37</td>\n",
       "      <td>0.930661</td>\n",
       "      <td>0.914901</td>\n",
       "      <td>0.932542</td>\n",
       "      <td>0.899484</td>\n",
       "      <td>0.917163</td>\n",
       "      <td>0.918950</td>\n",
       "      <td>0.012003</td>\n",
       "      <td>35</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.997785</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>0.999355</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>29</td>\n",
       "      <td>0.870859</td>\n",
       "      <td>0.844731</td>\n",
       "      <td>0.873609</td>\n",
       "      <td>0.817329</td>\n",
       "      <td>0.847212</td>\n",
       "      <td>0.850748</td>\n",
       "      <td>0.020458</td>\n",
       "      <td>41</td>\n",
       "      <td>0.935125</td>\n",
       "      <td>0.921438</td>\n",
       "      <td>0.936813</td>\n",
       "      <td>0.908687</td>\n",
       "      <td>0.923500</td>\n",
       "      <td>0.925113</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>8.909877</td>\n",
       "      <td>0.237272</td>\n",
       "      <td>1.843813</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.986178</td>\n",
       "      <td>0.985267</td>\n",
       "      <td>0.998583</td>\n",
       "      <td>0.981253</td>\n",
       "      <td>0.997039</td>\n",
       "      <td>0.989664</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>21</td>\n",
       "      <td>0.928653</td>\n",
       "      <td>0.933777</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.919120</td>\n",
       "      <td>0.926299</td>\n",
       "      <td>0.931070</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>21</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999364</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>27</td>\n",
       "      <td>0.868109</td>\n",
       "      <td>0.876110</td>\n",
       "      <td>0.900238</td>\n",
       "      <td>0.851088</td>\n",
       "      <td>0.862716</td>\n",
       "      <td>0.871652</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>21</td>\n",
       "      <td>0.933312</td>\n",
       "      <td>0.937875</td>\n",
       "      <td>0.950125</td>\n",
       "      <td>0.925125</td>\n",
       "      <td>0.931375</td>\n",
       "      <td>0.935562</td>\n",
       "      <td>0.008354</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.098478</td>\n",
       "      <td>0.034502</td>\n",
       "      <td>0.802732</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.939148</td>\n",
       "      <td>0.950637</td>\n",
       "      <td>0.935500</td>\n",
       "      <td>0.929631</td>\n",
       "      <td>0.959239</td>\n",
       "      <td>0.942831</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>55</td>\n",
       "      <td>0.851739</td>\n",
       "      <td>0.846924</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.861151</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.861480</td>\n",
       "      <td>0.012813</td>\n",
       "      <td>55</td>\n",
       "      <td>0.977803</td>\n",
       "      <td>0.989801</td>\n",
       "      <td>0.928767</td>\n",
       "      <td>0.956901</td>\n",
       "      <td>0.953953</td>\n",
       "      <td>0.961445</td>\n",
       "      <td>0.021054</td>\n",
       "      <td>53</td>\n",
       "      <td>0.754469</td>\n",
       "      <td>0.740093</td>\n",
       "      <td>0.806851</td>\n",
       "      <td>0.782821</td>\n",
       "      <td>0.823706</td>\n",
       "      <td>0.781588</td>\n",
       "      <td>0.031212</td>\n",
       "      <td>57</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.873812</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.874650</td>\n",
       "      <td>0.009082</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.095641</td>\n",
       "      <td>0.092030</td>\n",
       "      <td>1.772958</td>\n",
       "      <td>0.014540</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.957785</td>\n",
       "      <td>0.963944</td>\n",
       "      <td>0.952292</td>\n",
       "      <td>0.964435</td>\n",
       "      <td>0.967645</td>\n",
       "      <td>0.961220</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>50</td>\n",
       "      <td>0.901010</td>\n",
       "      <td>0.906595</td>\n",
       "      <td>0.890358</td>\n",
       "      <td>0.871863</td>\n",
       "      <td>0.908273</td>\n",
       "      <td>0.895620</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>50</td>\n",
       "      <td>0.992480</td>\n",
       "      <td>0.987622</td>\n",
       "      <td>0.945107</td>\n",
       "      <td>0.988743</td>\n",
       "      <td>0.980998</td>\n",
       "      <td>0.978990</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>49</td>\n",
       "      <td>0.824978</td>\n",
       "      <td>0.837855</td>\n",
       "      <td>0.841605</td>\n",
       "      <td>0.779695</td>\n",
       "      <td>0.845586</td>\n",
       "      <td>0.825944</td>\n",
       "      <td>0.024137</td>\n",
       "      <td>50</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.913687</td>\n",
       "      <td>0.896375</td>\n",
       "      <td>0.885437</td>\n",
       "      <td>0.914625</td>\n",
       "      <td>0.903900</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5.103720</td>\n",
       "      <td>0.067396</td>\n",
       "      <td>0.861566</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.982535</td>\n",
       "      <td>0.986480</td>\n",
       "      <td>0.992666</td>\n",
       "      <td>0.988515</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.989470</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>23</td>\n",
       "      <td>0.932730</td>\n",
       "      <td>0.921751</td>\n",
       "      <td>0.938702</td>\n",
       "      <td>0.910725</td>\n",
       "      <td>0.939117</td>\n",
       "      <td>0.928605</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>25</td>\n",
       "      <td>0.997013</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999198</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>33</td>\n",
       "      <td>0.876235</td>\n",
       "      <td>0.855607</td>\n",
       "      <td>0.884486</td>\n",
       "      <td>0.836084</td>\n",
       "      <td>0.885221</td>\n",
       "      <td>0.867526</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>25</td>\n",
       "      <td>0.936813</td>\n",
       "      <td>0.927375</td>\n",
       "      <td>0.942250</td>\n",
       "      <td>0.918063</td>\n",
       "      <td>0.942625</td>\n",
       "      <td>0.933425</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>9.459021</td>\n",
       "      <td>0.111687</td>\n",
       "      <td>1.881864</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.990652</td>\n",
       "      <td>0.987734</td>\n",
       "      <td>0.998686</td>\n",
       "      <td>0.979649</td>\n",
       "      <td>0.997492</td>\n",
       "      <td>0.990842</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>15</td>\n",
       "      <td>0.934470</td>\n",
       "      <td>0.928916</td>\n",
       "      <td>0.947638</td>\n",
       "      <td>0.918101</td>\n",
       "      <td>0.936860</td>\n",
       "      <td>0.933197</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>11</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>0.999712</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997945</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999503</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>23</td>\n",
       "      <td>0.877110</td>\n",
       "      <td>0.867483</td>\n",
       "      <td>0.900488</td>\n",
       "      <td>0.850088</td>\n",
       "      <td>0.881220</td>\n",
       "      <td>0.875278</td>\n",
       "      <td>0.016550</td>\n",
       "      <td>11</td>\n",
       "      <td>0.938500</td>\n",
       "      <td>0.933625</td>\n",
       "      <td>0.950250</td>\n",
       "      <td>0.924188</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.937438</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.094890</td>\n",
       "      <td>0.123939</td>\n",
       "      <td>0.853474</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.982535</td>\n",
       "      <td>0.986480</td>\n",
       "      <td>0.992666</td>\n",
       "      <td>0.988515</td>\n",
       "      <td>0.997152</td>\n",
       "      <td>0.989470</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>23</td>\n",
       "      <td>0.932730</td>\n",
       "      <td>0.921751</td>\n",
       "      <td>0.938702</td>\n",
       "      <td>0.910725</td>\n",
       "      <td>0.939117</td>\n",
       "      <td>0.928605</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>25</td>\n",
       "      <td>0.997013</td>\n",
       "      <td>0.998978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999198</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>33</td>\n",
       "      <td>0.876235</td>\n",
       "      <td>0.855607</td>\n",
       "      <td>0.884486</td>\n",
       "      <td>0.836084</td>\n",
       "      <td>0.885221</td>\n",
       "      <td>0.867526</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>25</td>\n",
       "      <td>0.936813</td>\n",
       "      <td>0.927375</td>\n",
       "      <td>0.942250</td>\n",
       "      <td>0.918063</td>\n",
       "      <td>0.942625</td>\n",
       "      <td>0.933425</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9.477933</td>\n",
       "      <td>0.075013</td>\n",
       "      <td>1.896061</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.990652</td>\n",
       "      <td>0.987734</td>\n",
       "      <td>0.998686</td>\n",
       "      <td>0.979649</td>\n",
       "      <td>0.997492</td>\n",
       "      <td>0.990842</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>15</td>\n",
       "      <td>0.934470</td>\n",
       "      <td>0.928916</td>\n",
       "      <td>0.947638</td>\n",
       "      <td>0.918101</td>\n",
       "      <td>0.936860</td>\n",
       "      <td>0.933197</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>11</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>0.999712</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997945</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999503</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>23</td>\n",
       "      <td>0.877110</td>\n",
       "      <td>0.867483</td>\n",
       "      <td>0.900488</td>\n",
       "      <td>0.850088</td>\n",
       "      <td>0.881220</td>\n",
       "      <td>0.875278</td>\n",
       "      <td>0.016550</td>\n",
       "      <td>11</td>\n",
       "      <td>0.938500</td>\n",
       "      <td>0.933625</td>\n",
       "      <td>0.950250</td>\n",
       "      <td>0.924188</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.937438</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4.216424</td>\n",
       "      <td>0.037076</td>\n",
       "      <td>0.834483</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.936672</td>\n",
       "      <td>0.971889</td>\n",
       "      <td>0.931568</td>\n",
       "      <td>0.894419</td>\n",
       "      <td>0.962850</td>\n",
       "      <td>0.939480</td>\n",
       "      <td>0.027193</td>\n",
       "      <td>57</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>0.876128</td>\n",
       "      <td>0.863578</td>\n",
       "      <td>0.800526</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>0.860507</td>\n",
       "      <td>0.034695</td>\n",
       "      <td>56</td>\n",
       "      <td>0.967951</td>\n",
       "      <td>0.994443</td>\n",
       "      <td>0.940760</td>\n",
       "      <td>0.896589</td>\n",
       "      <td>0.967399</td>\n",
       "      <td>0.953428</td>\n",
       "      <td>0.033104</td>\n",
       "      <td>55</td>\n",
       "      <td>0.766471</td>\n",
       "      <td>0.782973</td>\n",
       "      <td>0.798100</td>\n",
       "      <td>0.723056</td>\n",
       "      <td>0.853338</td>\n",
       "      <td>0.784788</td>\n",
       "      <td>0.042488</td>\n",
       "      <td>55</td>\n",
       "      <td>0.870563</td>\n",
       "      <td>0.889312</td>\n",
       "      <td>0.873938</td>\n",
       "      <td>0.819875</td>\n",
       "      <td>0.912312</td>\n",
       "      <td>0.873200</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7.328495</td>\n",
       "      <td>0.077116</td>\n",
       "      <td>1.815097</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.954598</td>\n",
       "      <td>0.980162</td>\n",
       "      <td>0.956577</td>\n",
       "      <td>0.962389</td>\n",
       "      <td>0.960418</td>\n",
       "      <td>0.962829</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>48</td>\n",
       "      <td>0.907765</td>\n",
       "      <td>0.927116</td>\n",
       "      <td>0.904214</td>\n",
       "      <td>0.887797</td>\n",
       "      <td>0.902429</td>\n",
       "      <td>0.905864</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>45</td>\n",
       "      <td>0.986933</td>\n",
       "      <td>0.995552</td>\n",
       "      <td>0.966970</td>\n",
       "      <td>0.977457</td>\n",
       "      <td>0.980211</td>\n",
       "      <td>0.981425</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>47</td>\n",
       "      <td>0.840355</td>\n",
       "      <td>0.867483</td>\n",
       "      <td>0.849106</td>\n",
       "      <td>0.813203</td>\n",
       "      <td>0.836084</td>\n",
       "      <td>0.841246</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>46</td>\n",
       "      <td>0.914625</td>\n",
       "      <td>0.931813</td>\n",
       "      <td>0.910062</td>\n",
       "      <td>0.897250</td>\n",
       "      <td>0.909625</td>\n",
       "      <td>0.912675</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.373900</td>\n",
       "      <td>0.061011</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.008795</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.987535</td>\n",
       "      <td>0.992152</td>\n",
       "      <td>0.997639</td>\n",
       "      <td>0.988266</td>\n",
       "      <td>0.983577</td>\n",
       "      <td>0.989834</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>19</td>\n",
       "      <td>0.940274</td>\n",
       "      <td>0.924649</td>\n",
       "      <td>0.935100</td>\n",
       "      <td>0.912662</td>\n",
       "      <td>0.923626</td>\n",
       "      <td>0.927262</td>\n",
       "      <td>0.009633</td>\n",
       "      <td>29</td>\n",
       "      <td>0.998315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999633</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>13</td>\n",
       "      <td>0.888611</td>\n",
       "      <td>0.859857</td>\n",
       "      <td>0.878110</td>\n",
       "      <td>0.839460</td>\n",
       "      <td>0.858090</td>\n",
       "      <td>0.864826</td>\n",
       "      <td>0.017063</td>\n",
       "      <td>29</td>\n",
       "      <td>0.943562</td>\n",
       "      <td>0.929937</td>\n",
       "      <td>0.939063</td>\n",
       "      <td>0.919687</td>\n",
       "      <td>0.929063</td>\n",
       "      <td>0.932262</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10.177126</td>\n",
       "      <td>0.087513</td>\n",
       "      <td>1.964977</td>\n",
       "      <td>0.026292</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.994576</td>\n",
       "      <td>0.993943</td>\n",
       "      <td>0.999060</td>\n",
       "      <td>0.987311</td>\n",
       "      <td>0.998806</td>\n",
       "      <td>0.994739</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>7</td>\n",
       "      <td>0.937151</td>\n",
       "      <td>0.926885</td>\n",
       "      <td>0.945627</td>\n",
       "      <td>0.925245</td>\n",
       "      <td>0.938976</td>\n",
       "      <td>0.934777</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>9</td>\n",
       "      <td>0.881735</td>\n",
       "      <td>0.863733</td>\n",
       "      <td>0.896862</td>\n",
       "      <td>0.861965</td>\n",
       "      <td>0.884971</td>\n",
       "      <td>0.877853</td>\n",
       "      <td>0.013258</td>\n",
       "      <td>9</td>\n",
       "      <td>0.940875</td>\n",
       "      <td>0.931875</td>\n",
       "      <td>0.948438</td>\n",
       "      <td>0.930375</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.938812</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.339844</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>0.880717</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.987535</td>\n",
       "      <td>0.992152</td>\n",
       "      <td>0.997639</td>\n",
       "      <td>0.988266</td>\n",
       "      <td>0.983577</td>\n",
       "      <td>0.989834</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>19</td>\n",
       "      <td>0.940274</td>\n",
       "      <td>0.924649</td>\n",
       "      <td>0.935100</td>\n",
       "      <td>0.912662</td>\n",
       "      <td>0.923626</td>\n",
       "      <td>0.927262</td>\n",
       "      <td>0.009633</td>\n",
       "      <td>29</td>\n",
       "      <td>0.998315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999633</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>13</td>\n",
       "      <td>0.888611</td>\n",
       "      <td>0.859857</td>\n",
       "      <td>0.878110</td>\n",
       "      <td>0.839460</td>\n",
       "      <td>0.858090</td>\n",
       "      <td>0.864826</td>\n",
       "      <td>0.017063</td>\n",
       "      <td>29</td>\n",
       "      <td>0.943562</td>\n",
       "      <td>0.929937</td>\n",
       "      <td>0.939063</td>\n",
       "      <td>0.919687</td>\n",
       "      <td>0.929063</td>\n",
       "      <td>0.932262</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10.195288</td>\n",
       "      <td>0.134301</td>\n",
       "      <td>1.990035</td>\n",
       "      <td>0.035959</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.994576</td>\n",
       "      <td>0.993943</td>\n",
       "      <td>0.999060</td>\n",
       "      <td>0.987311</td>\n",
       "      <td>0.998806</td>\n",
       "      <td>0.994739</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>7</td>\n",
       "      <td>0.937151</td>\n",
       "      <td>0.926885</td>\n",
       "      <td>0.945627</td>\n",
       "      <td>0.925245</td>\n",
       "      <td>0.938976</td>\n",
       "      <td>0.934777</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>9</td>\n",
       "      <td>0.881735</td>\n",
       "      <td>0.863733</td>\n",
       "      <td>0.896862</td>\n",
       "      <td>0.861965</td>\n",
       "      <td>0.884971</td>\n",
       "      <td>0.877853</td>\n",
       "      <td>0.013258</td>\n",
       "      <td>9</td>\n",
       "      <td>0.940875</td>\n",
       "      <td>0.931875</td>\n",
       "      <td>0.948438</td>\n",
       "      <td>0.930375</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.938812</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4.292925</td>\n",
       "      <td>0.028797</td>\n",
       "      <td>0.852541</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.938495</td>\n",
       "      <td>0.966244</td>\n",
       "      <td>0.912893</td>\n",
       "      <td>0.949891</td>\n",
       "      <td>0.967044</td>\n",
       "      <td>0.946913</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>53</td>\n",
       "      <td>0.870283</td>\n",
       "      <td>0.884145</td>\n",
       "      <td>0.832701</td>\n",
       "      <td>0.863232</td>\n",
       "      <td>0.909872</td>\n",
       "      <td>0.872047</td>\n",
       "      <td>0.025322</td>\n",
       "      <td>53</td>\n",
       "      <td>0.958083</td>\n",
       "      <td>0.988110</td>\n",
       "      <td>0.873884</td>\n",
       "      <td>0.944172</td>\n",
       "      <td>0.982879</td>\n",
       "      <td>0.949426</td>\n",
       "      <td>0.041048</td>\n",
       "      <td>57</td>\n",
       "      <td>0.797225</td>\n",
       "      <td>0.799975</td>\n",
       "      <td>0.795224</td>\n",
       "      <td>0.795074</td>\n",
       "      <td>0.846962</td>\n",
       "      <td>0.806892</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>53</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.895188</td>\n",
       "      <td>0.840250</td>\n",
       "      <td>0.874062</td>\n",
       "      <td>0.916125</td>\n",
       "      <td>0.881363</td>\n",
       "      <td>0.025072</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>7.943525</td>\n",
       "      <td>0.834985</td>\n",
       "      <td>1.879598</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.969864</td>\n",
       "      <td>0.980100</td>\n",
       "      <td>0.965342</td>\n",
       "      <td>0.969961</td>\n",
       "      <td>0.958828</td>\n",
       "      <td>0.968819</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>45</td>\n",
       "      <td>0.922922</td>\n",
       "      <td>0.927585</td>\n",
       "      <td>0.915011</td>\n",
       "      <td>0.908909</td>\n",
       "      <td>0.894898</td>\n",
       "      <td>0.913865</td>\n",
       "      <td>0.011453</td>\n",
       "      <td>43</td>\n",
       "      <td>0.996809</td>\n",
       "      <td>0.994989</td>\n",
       "      <td>0.976596</td>\n",
       "      <td>0.971412</td>\n",
       "      <td>0.982942</td>\n",
       "      <td>0.984550</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>44</td>\n",
       "      <td>0.859232</td>\n",
       "      <td>0.868734</td>\n",
       "      <td>0.860733</td>\n",
       "      <td>0.853963</td>\n",
       "      <td>0.821330</td>\n",
       "      <td>0.852798</td>\n",
       "      <td>0.016431</td>\n",
       "      <td>34</td>\n",
       "      <td>0.928250</td>\n",
       "      <td>0.932187</td>\n",
       "      <td>0.920063</td>\n",
       "      <td>0.914438</td>\n",
       "      <td>0.903563</td>\n",
       "      <td>0.919700</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5.663845</td>\n",
       "      <td>0.032125</td>\n",
       "      <td>0.901674</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.989164</td>\n",
       "      <td>0.993355</td>\n",
       "      <td>0.999116</td>\n",
       "      <td>0.990359</td>\n",
       "      <td>0.987868</td>\n",
       "      <td>0.991972</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>11</td>\n",
       "      <td>0.935752</td>\n",
       "      <td>0.927120</td>\n",
       "      <td>0.954516</td>\n",
       "      <td>0.925938</td>\n",
       "      <td>0.933893</td>\n",
       "      <td>0.935444</td>\n",
       "      <td>0.010255</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998582</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>15</td>\n",
       "      <td>0.880360</td>\n",
       "      <td>0.864358</td>\n",
       "      <td>0.912989</td>\n",
       "      <td>0.862091</td>\n",
       "      <td>0.876094</td>\n",
       "      <td>0.879178</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>7</td>\n",
       "      <td>0.939562</td>\n",
       "      <td>0.932063</td>\n",
       "      <td>0.956500</td>\n",
       "      <td>0.931063</td>\n",
       "      <td>0.938000</td>\n",
       "      <td>0.939438</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>11.055161</td>\n",
       "      <td>0.174318</td>\n",
       "      <td>2.070759</td>\n",
       "      <td>0.059206</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.994705</td>\n",
       "      <td>0.995807</td>\n",
       "      <td>0.999269</td>\n",
       "      <td>0.989668</td>\n",
       "      <td>0.998103</td>\n",
       "      <td>0.995510</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>3</td>\n",
       "      <td>0.943267</td>\n",
       "      <td>0.934106</td>\n",
       "      <td>0.954385</td>\n",
       "      <td>0.931124</td>\n",
       "      <td>0.936648</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>5</td>\n",
       "      <td>0.892737</td>\n",
       "      <td>0.876360</td>\n",
       "      <td>0.912864</td>\n",
       "      <td>0.871343</td>\n",
       "      <td>0.880845</td>\n",
       "      <td>0.886830</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>1</td>\n",
       "      <td>0.946313</td>\n",
       "      <td>0.938187</td>\n",
       "      <td>0.956375</td>\n",
       "      <td>0.935562</td>\n",
       "      <td>0.940438</td>\n",
       "      <td>0.943375</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.717195</td>\n",
       "      <td>0.069847</td>\n",
       "      <td>0.926227</td>\n",
       "      <td>0.018247</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.989164</td>\n",
       "      <td>0.993355</td>\n",
       "      <td>0.999116</td>\n",
       "      <td>0.990359</td>\n",
       "      <td>0.987868</td>\n",
       "      <td>0.991972</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>11</td>\n",
       "      <td>0.935752</td>\n",
       "      <td>0.927120</td>\n",
       "      <td>0.954516</td>\n",
       "      <td>0.925938</td>\n",
       "      <td>0.933893</td>\n",
       "      <td>0.935444</td>\n",
       "      <td>0.010255</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998582</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999857</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>15</td>\n",
       "      <td>0.880360</td>\n",
       "      <td>0.864358</td>\n",
       "      <td>0.912989</td>\n",
       "      <td>0.862091</td>\n",
       "      <td>0.876094</td>\n",
       "      <td>0.879178</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>7</td>\n",
       "      <td>0.939562</td>\n",
       "      <td>0.932063</td>\n",
       "      <td>0.956500</td>\n",
       "      <td>0.931063</td>\n",
       "      <td>0.938000</td>\n",
       "      <td>0.939438</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>11.117205</td>\n",
       "      <td>0.120570</td>\n",
       "      <td>2.041305</td>\n",
       "      <td>0.013117</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.994705</td>\n",
       "      <td>0.995807</td>\n",
       "      <td>0.999269</td>\n",
       "      <td>0.989668</td>\n",
       "      <td>0.998103</td>\n",
       "      <td>0.995510</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>3</td>\n",
       "      <td>0.943267</td>\n",
       "      <td>0.934106</td>\n",
       "      <td>0.954385</td>\n",
       "      <td>0.931124</td>\n",
       "      <td>0.936648</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>5</td>\n",
       "      <td>0.892737</td>\n",
       "      <td>0.876360</td>\n",
       "      <td>0.912864</td>\n",
       "      <td>0.871343</td>\n",
       "      <td>0.880845</td>\n",
       "      <td>0.886830</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>1</td>\n",
       "      <td>0.946313</td>\n",
       "      <td>0.938187</td>\n",
       "      <td>0.956375</td>\n",
       "      <td>0.935562</td>\n",
       "      <td>0.940438</td>\n",
       "      <td>0.943375</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4.435808</td>\n",
       "      <td>0.081239</td>\n",
       "      <td>0.875261</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.947900</td>\n",
       "      <td>0.977558</td>\n",
       "      <td>0.920050</td>\n",
       "      <td>0.976697</td>\n",
       "      <td>0.955433</td>\n",
       "      <td>0.955528</td>\n",
       "      <td>0.021215</td>\n",
       "      <td>52</td>\n",
       "      <td>0.871466</td>\n",
       "      <td>0.886762</td>\n",
       "      <td>0.841252</td>\n",
       "      <td>0.899069</td>\n",
       "      <td>0.892426</td>\n",
       "      <td>0.878195</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>52</td>\n",
       "      <td>0.983498</td>\n",
       "      <td>0.995640</td>\n",
       "      <td>0.906557</td>\n",
       "      <td>0.984959</td>\n",
       "      <td>0.950282</td>\n",
       "      <td>0.964187</td>\n",
       "      <td>0.032583</td>\n",
       "      <td>52</td>\n",
       "      <td>0.782348</td>\n",
       "      <td>0.799350</td>\n",
       "      <td>0.784723</td>\n",
       "      <td>0.826957</td>\n",
       "      <td>0.841210</td>\n",
       "      <td>0.806918</td>\n",
       "      <td>0.023371</td>\n",
       "      <td>52</td>\n",
       "      <td>0.884625</td>\n",
       "      <td>0.897938</td>\n",
       "      <td>0.851938</td>\n",
       "      <td>0.907188</td>\n",
       "      <td>0.898625</td>\n",
       "      <td>0.888062</td>\n",
       "      <td>0.019451</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>7.881266</td>\n",
       "      <td>0.052365</td>\n",
       "      <td>1.937086</td>\n",
       "      <td>0.022375</td>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
       "      <td>0.962419</td>\n",
       "      <td>0.979128</td>\n",
       "      <td>0.968802</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.965718</td>\n",
       "      <td>0.970928</td>\n",
       "      <td>0.006778</td>\n",
       "      <td>42</td>\n",
       "      <td>0.912333</td>\n",
       "      <td>0.926875</td>\n",
       "      <td>0.917844</td>\n",
       "      <td>0.920557</td>\n",
       "      <td>0.898570</td>\n",
       "      <td>0.915236</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>41</td>\n",
       "      <td>0.992214</td>\n",
       "      <td>0.996978</td>\n",
       "      <td>0.977266</td>\n",
       "      <td>0.984756</td>\n",
       "      <td>0.986252</td>\n",
       "      <td>0.987493</td>\n",
       "      <td>0.006721</td>\n",
       "      <td>42</td>\n",
       "      <td>0.844356</td>\n",
       "      <td>0.865983</td>\n",
       "      <td>0.865233</td>\n",
       "      <td>0.864216</td>\n",
       "      <td>0.825206</td>\n",
       "      <td>0.852999</td>\n",
       "      <td>0.016070</td>\n",
       "      <td>33</td>\n",
       "      <td>0.918875</td>\n",
       "      <td>0.931688</td>\n",
       "      <td>0.922562</td>\n",
       "      <td>0.925438</td>\n",
       "      <td>0.906875</td>\n",
       "      <td>0.921088</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        4.488141      0.092392         0.802480        0.005857   \n",
       "1        8.115060      0.102511         1.755488        0.021333   \n",
       "2        4.558100      0.055722         0.808039        0.008539   \n",
       "3        8.179243      0.103143         1.763674        0.010803   \n",
       "4        4.391912      0.245226         0.906746        0.079731   \n",
       "5        7.150817      0.144723         1.855787        0.120893   \n",
       "6        5.355520      0.354599         0.993620        0.138960   \n",
       "7        9.634668      0.505099         1.968876        0.135414   \n",
       "8        4.978940      0.120063         0.919668        0.079550   \n",
       "9        9.266565      0.761195         1.935856        0.111167   \n",
       "10       4.363569      0.271059         0.839261        0.057591   \n",
       "11       9.914856      1.297999         2.286258        0.126297   \n",
       "12       8.426586      1.120434         1.345236        0.076060   \n",
       "13      12.493801      1.999545         2.466302        0.436478   \n",
       "14       5.265116      0.181948         0.855811        0.005823   \n",
       "15       9.998124      0.407744         1.926709        0.048040   \n",
       "16       4.221535      0.062360         0.826723        0.007758   \n",
       "17       7.421788      0.060880         1.915855        0.173057   \n",
       "18       5.434280      0.028968         0.876324        0.003696   \n",
       "19      10.515123      0.256169         1.966312        0.016123   \n",
       "20       5.517164      0.088713         0.880323        0.009300   \n",
       "21      10.515616      0.374850         1.980994        0.041600   \n",
       "22       4.347149      0.035619         0.908067        0.104872   \n",
       "23       7.656598      0.096133         1.908187        0.061246   \n",
       "24       5.785684      0.060217         0.902096        0.008478   \n",
       "25      11.166672      0.131882         2.020614        0.022137   \n",
       "26       5.756356      0.065047         0.908038        0.002726   \n",
       "27      11.196496      0.117142         2.045970        0.087114   \n",
       "28       4.417113      0.021015         0.871325        0.005254   \n",
       "29       7.972149      0.116195         1.945083        0.026592   \n",
       "30       4.537754      0.074109         0.805731        0.009538   \n",
       "31       8.209700      0.106726         1.779850        0.008959   \n",
       "32       4.562919      0.090732         0.810300        0.006700   \n",
       "33       8.239986      0.126649         1.766291        0.017286   \n",
       "34       4.016032      0.020733         0.801226        0.023881   \n",
       "35       6.824350      0.029113         1.710575        0.016521   \n",
       "36       4.775889      0.053238         0.826089        0.001625   \n",
       "37       8.877163      0.212326         1.855652        0.030644   \n",
       "38       4.782334      0.067291         0.829088        0.004076   \n",
       "39       8.909877      0.237272         1.843813        0.024250   \n",
       "40       4.098478      0.034502         0.802732        0.005512   \n",
       "41       7.095641      0.092030         1.772958        0.014540   \n",
       "42       5.103720      0.067396         0.861566        0.005888   \n",
       "43       9.459021      0.111687         1.881864        0.011118   \n",
       "44       5.094890      0.123939         0.853474        0.003344   \n",
       "45       9.477933      0.075013         1.896061        0.017742   \n",
       "46       4.216424      0.037076         0.834483        0.010328   \n",
       "47       7.328495      0.077116         1.815097        0.009996   \n",
       "48       5.373900      0.061011         0.882979        0.008795   \n",
       "49      10.177126      0.087513         1.964977        0.026292   \n",
       "50       5.339844      0.043696         0.880717        0.013058   \n",
       "51      10.195288      0.134301         1.990035        0.035959   \n",
       "52       4.292925      0.028797         0.852541        0.007439   \n",
       "53       7.943525      0.834985         1.879598        0.013841   \n",
       "54       5.663845      0.032125         0.901674        0.011502   \n",
       "55      11.055161      0.174318         2.070759        0.059206   \n",
       "56       5.717195      0.069847         0.926227        0.018247   \n",
       "57      11.117205      0.120570         2.041305        0.013117   \n",
       "58       4.435808      0.081239         0.875261        0.005519   \n",
       "59       7.881266      0.052365         1.937086        0.022375   \n",
       "\n",
       "   param_classifier__criterion param_classifier__max_depth  \\\n",
       "0                         gini                           4   \n",
       "1                         gini                           4   \n",
       "2                         gini                           4   \n",
       "3                         gini                           4   \n",
       "4                         gini                           4   \n",
       "5                         gini                           4   \n",
       "6                         gini                           5   \n",
       "7                         gini                           5   \n",
       "8                         gini                           5   \n",
       "9                         gini                           5   \n",
       "10                        gini                           5   \n",
       "11                        gini                           5   \n",
       "12                        gini                           6   \n",
       "13                        gini                           6   \n",
       "14                        gini                           6   \n",
       "15                        gini                           6   \n",
       "16                        gini                           6   \n",
       "17                        gini                           6   \n",
       "18                        gini                           7   \n",
       "19                        gini                           7   \n",
       "20                        gini                           7   \n",
       "21                        gini                           7   \n",
       "22                        gini                           7   \n",
       "23                        gini                           7   \n",
       "24                        gini                           8   \n",
       "25                        gini                           8   \n",
       "26                        gini                           8   \n",
       "27                        gini                           8   \n",
       "28                        gini                           8   \n",
       "29                        gini                           8   \n",
       "30                     entropy                           4   \n",
       "31                     entropy                           4   \n",
       "32                     entropy                           4   \n",
       "33                     entropy                           4   \n",
       "34                     entropy                           4   \n",
       "35                     entropy                           4   \n",
       "36                     entropy                           5   \n",
       "37                     entropy                           5   \n",
       "38                     entropy                           5   \n",
       "39                     entropy                           5   \n",
       "40                     entropy                           5   \n",
       "41                     entropy                           5   \n",
       "42                     entropy                           6   \n",
       "43                     entropy                           6   \n",
       "44                     entropy                           6   \n",
       "45                     entropy                           6   \n",
       "46                     entropy                           6   \n",
       "47                     entropy                           6   \n",
       "48                     entropy                           7   \n",
       "49                     entropy                           7   \n",
       "50                     entropy                           7   \n",
       "51                     entropy                           7   \n",
       "52                     entropy                           7   \n",
       "53                     entropy                           7   \n",
       "54                     entropy                           8   \n",
       "55                     entropy                           8   \n",
       "56                     entropy                           8   \n",
       "57                     entropy                           8   \n",
       "58                     entropy                           8   \n",
       "59                     entropy                           8   \n",
       "\n",
       "   param_classifier__max_features param_classifier__n_estimators  \\\n",
       "0                            auto                            200   \n",
       "1                            auto                            500   \n",
       "2                            sqrt                            200   \n",
       "3                            sqrt                            500   \n",
       "4                            log2                            200   \n",
       "5                            log2                            500   \n",
       "6                            auto                            200   \n",
       "7                            auto                            500   \n",
       "8                            sqrt                            200   \n",
       "9                            sqrt                            500   \n",
       "10                           log2                            200   \n",
       "11                           log2                            500   \n",
       "12                           auto                            200   \n",
       "13                           auto                            500   \n",
       "14                           sqrt                            200   \n",
       "15                           sqrt                            500   \n",
       "16                           log2                            200   \n",
       "17                           log2                            500   \n",
       "18                           auto                            200   \n",
       "19                           auto                            500   \n",
       "20                           sqrt                            200   \n",
       "21                           sqrt                            500   \n",
       "22                           log2                            200   \n",
       "23                           log2                            500   \n",
       "24                           auto                            200   \n",
       "25                           auto                            500   \n",
       "26                           sqrt                            200   \n",
       "27                           sqrt                            500   \n",
       "28                           log2                            200   \n",
       "29                           log2                            500   \n",
       "30                           auto                            200   \n",
       "31                           auto                            500   \n",
       "32                           sqrt                            200   \n",
       "33                           sqrt                            500   \n",
       "34                           log2                            200   \n",
       "35                           log2                            500   \n",
       "36                           auto                            200   \n",
       "37                           auto                            500   \n",
       "38                           sqrt                            200   \n",
       "39                           sqrt                            500   \n",
       "40                           log2                            200   \n",
       "41                           log2                            500   \n",
       "42                           auto                            200   \n",
       "43                           auto                            500   \n",
       "44                           sqrt                            200   \n",
       "45                           sqrt                            500   \n",
       "46                           log2                            200   \n",
       "47                           log2                            500   \n",
       "48                           auto                            200   \n",
       "49                           auto                            500   \n",
       "50                           sqrt                            200   \n",
       "51                           sqrt                            500   \n",
       "52                           log2                            200   \n",
       "53                           log2                            500   \n",
       "54                           auto                            200   \n",
       "55                           auto                            500   \n",
       "56                           sqrt                            200   \n",
       "57                           sqrt                            500   \n",
       "58                           log2                            200   \n",
       "59                           log2                            500   \n",
       "\n",
       "                                               params  split0_test_AUC  \\\n",
       "0   {'classifier__criterion': 'gini', 'classifier_...         0.980038   \n",
       "1   {'classifier__criterion': 'gini', 'classifier_...         0.987824   \n",
       "2   {'classifier__criterion': 'gini', 'classifier_...         0.980038   \n",
       "3   {'classifier__criterion': 'gini', 'classifier_...         0.987824   \n",
       "4   {'classifier__criterion': 'gini', 'classifier_...         0.964750   \n",
       "5   {'classifier__criterion': 'gini', 'classifier_...         0.962033   \n",
       "6   {'classifier__criterion': 'gini', 'classifier_...         0.984260   \n",
       "7   {'classifier__criterion': 'gini', 'classifier_...         0.987661   \n",
       "8   {'classifier__criterion': 'gini', 'classifier_...         0.984260   \n",
       "9   {'classifier__criterion': 'gini', 'classifier_...         0.987661   \n",
       "10  {'classifier__criterion': 'gini', 'classifier_...         0.939320   \n",
       "11  {'classifier__criterion': 'gini', 'classifier_...         0.963366   \n",
       "12  {'classifier__criterion': 'gini', 'classifier_...         0.980402   \n",
       "13  {'classifier__criterion': 'gini', 'classifier_...         0.989283   \n",
       "14  {'classifier__criterion': 'gini', 'classifier_...         0.980402   \n",
       "15  {'classifier__criterion': 'gini', 'classifier_...         0.989283   \n",
       "16  {'classifier__criterion': 'gini', 'classifier_...         0.936242   \n",
       "17  {'classifier__criterion': 'gini', 'classifier_...         0.953849   \n",
       "18  {'classifier__criterion': 'gini', 'classifier_...         0.987892   \n",
       "19  {'classifier__criterion': 'gini', 'classifier_...         0.990508   \n",
       "20  {'classifier__criterion': 'gini', 'classifier_...         0.987892   \n",
       "21  {'classifier__criterion': 'gini', 'classifier_...         0.990508   \n",
       "22  {'classifier__criterion': 'gini', 'classifier_...         0.931874   \n",
       "23  {'classifier__criterion': 'gini', 'classifier_...         0.970587   \n",
       "24  {'classifier__criterion': 'gini', 'classifier_...         0.990959   \n",
       "25  {'classifier__criterion': 'gini', 'classifier_...         0.995135   \n",
       "26  {'classifier__criterion': 'gini', 'classifier_...         0.990959   \n",
       "27  {'classifier__criterion': 'gini', 'classifier_...         0.995135   \n",
       "28  {'classifier__criterion': 'gini', 'classifier_...         0.951495   \n",
       "29  {'classifier__criterion': 'gini', 'classifier_...         0.962318   \n",
       "30  {'classifier__criterion': 'entropy', 'classifi...         0.976082   \n",
       "31  {'classifier__criterion': 'entropy', 'classifi...         0.986427   \n",
       "32  {'classifier__criterion': 'entropy', 'classifi...         0.976082   \n",
       "33  {'classifier__criterion': 'entropy', 'classifi...         0.986427   \n",
       "34  {'classifier__criterion': 'entropy', 'classifi...         0.963338   \n",
       "35  {'classifier__criterion': 'entropy', 'classifi...         0.960968   \n",
       "36  {'classifier__criterion': 'entropy', 'classifi...         0.984297   \n",
       "37  {'classifier__criterion': 'entropy', 'classifi...         0.986178   \n",
       "38  {'classifier__criterion': 'entropy', 'classifi...         0.984297   \n",
       "39  {'classifier__criterion': 'entropy', 'classifi...         0.986178   \n",
       "40  {'classifier__criterion': 'entropy', 'classifi...         0.939148   \n",
       "41  {'classifier__criterion': 'entropy', 'classifi...         0.957785   \n",
       "42  {'classifier__criterion': 'entropy', 'classifi...         0.982535   \n",
       "43  {'classifier__criterion': 'entropy', 'classifi...         0.990652   \n",
       "44  {'classifier__criterion': 'entropy', 'classifi...         0.982535   \n",
       "45  {'classifier__criterion': 'entropy', 'classifi...         0.990652   \n",
       "46  {'classifier__criterion': 'entropy', 'classifi...         0.936672   \n",
       "47  {'classifier__criterion': 'entropy', 'classifi...         0.954598   \n",
       "48  {'classifier__criterion': 'entropy', 'classifi...         0.987535   \n",
       "49  {'classifier__criterion': 'entropy', 'classifi...         0.994576   \n",
       "50  {'classifier__criterion': 'entropy', 'classifi...         0.987535   \n",
       "51  {'classifier__criterion': 'entropy', 'classifi...         0.994576   \n",
       "52  {'classifier__criterion': 'entropy', 'classifi...         0.938495   \n",
       "53  {'classifier__criterion': 'entropy', 'classifi...         0.969864   \n",
       "54  {'classifier__criterion': 'entropy', 'classifi...         0.989164   \n",
       "55  {'classifier__criterion': 'entropy', 'classifi...         0.994705   \n",
       "56  {'classifier__criterion': 'entropy', 'classifi...         0.989164   \n",
       "57  {'classifier__criterion': 'entropy', 'classifi...         0.994705   \n",
       "58  {'classifier__criterion': 'entropy', 'classifi...         0.947900   \n",
       "59  {'classifier__criterion': 'entropy', 'classifi...         0.962419   \n",
       "\n",
       "    split1_test_AUC  split2_test_AUC  split3_test_AUC  split4_test_AUC  \\\n",
       "0          0.989693         0.987174         0.985342         0.992402   \n",
       "1          0.985908         0.999267         0.977656         0.992635   \n",
       "2          0.989693         0.987174         0.985342         0.992402   \n",
       "3          0.985908         0.999267         0.977656         0.992635   \n",
       "4          0.965399         0.943888         0.770714         0.936039   \n",
       "5          0.964920         0.973272         0.974837         0.973774   \n",
       "6          0.982880         0.992604         0.984915         0.987609   \n",
       "7          0.983131         0.998436         0.981209         0.996831   \n",
       "8          0.982880         0.992604         0.984915         0.987609   \n",
       "9          0.983131         0.998436         0.981209         0.996831   \n",
       "10         0.948704         0.934047         0.929644         0.959473   \n",
       "11         0.969604         0.951371         0.964205         0.968438   \n",
       "12         0.989896         0.994966         0.984107         0.995775   \n",
       "13         0.990500         0.998647         0.976589         0.996940   \n",
       "14         0.989896         0.994966         0.984107         0.995775   \n",
       "15         0.990500         0.998647         0.976589         0.996940   \n",
       "16         0.971230         0.930078         0.897042         0.955036   \n",
       "17         0.981291         0.955820         0.964321         0.955463   \n",
       "18         0.994484         0.997761         0.987837         0.991362   \n",
       "19         0.992176         0.999077         0.985371         0.998855   \n",
       "20         0.994484         0.997761         0.987837         0.991362   \n",
       "21         0.992176         0.999077         0.985371         0.998855   \n",
       "22         0.966468         0.914262         0.947041         0.966785   \n",
       "23         0.979183         0.964560         0.969242         0.957812   \n",
       "24         0.996936         0.999540         0.992687         0.995389   \n",
       "25         0.995504         0.999350         0.993399         0.998734   \n",
       "26         0.996936         0.999540         0.992687         0.995389   \n",
       "27         0.995504         0.999350         0.993399         0.998734   \n",
       "28         0.977023         0.921161         0.973759         0.954711   \n",
       "29         0.982019         0.969416         0.977492         0.963613   \n",
       "30         0.990090         0.986801         0.982853         0.990811   \n",
       "31         0.985445         0.999198         0.978642         0.992775   \n",
       "32         0.990090         0.986801         0.982853         0.990811   \n",
       "33         0.985445         0.999198         0.978642         0.992775   \n",
       "34         0.966672         0.944452         0.770783         0.936888   \n",
       "35         0.965016         0.973502         0.975616         0.974889   \n",
       "36         0.980256         0.992083         0.985053         0.985151   \n",
       "37         0.985267         0.998583         0.981253         0.997039   \n",
       "38         0.980256         0.992083         0.985053         0.985151   \n",
       "39         0.985267         0.998583         0.981253         0.997039   \n",
       "40         0.950637         0.935500         0.929631         0.959239   \n",
       "41         0.963944         0.952292         0.964435         0.967645   \n",
       "42         0.986480         0.992666         0.988515         0.997152   \n",
       "43         0.987734         0.998686         0.979649         0.997492   \n",
       "44         0.986480         0.992666         0.988515         0.997152   \n",
       "45         0.987734         0.998686         0.979649         0.997492   \n",
       "46         0.971889         0.931568         0.894419         0.962850   \n",
       "47         0.980162         0.956577         0.962389         0.960418   \n",
       "48         0.992152         0.997639         0.988266         0.983577   \n",
       "49         0.993943         0.999060         0.987311         0.998806   \n",
       "50         0.992152         0.997639         0.988266         0.983577   \n",
       "51         0.993943         0.999060         0.987311         0.998806   \n",
       "52         0.966244         0.912893         0.949891         0.967044   \n",
       "53         0.980100         0.965342         0.969961         0.958828   \n",
       "54         0.993355         0.999116         0.990359         0.987868   \n",
       "55         0.995807         0.999269         0.989668         0.998103   \n",
       "56         0.993355         0.999116         0.990359         0.987868   \n",
       "57         0.995807         0.999269         0.989668         0.998103   \n",
       "58         0.977558         0.920050         0.976697         0.955433   \n",
       "59         0.979128         0.968802         0.978571         0.965718   \n",
       "\n",
       "    mean_test_AUC  std_test_AUC  rank_test_AUC  split0_test_F1  \\\n",
       "0        0.986930      0.004187             33        0.924417   \n",
       "1        0.988658      0.007179             29        0.925401   \n",
       "2        0.986930      0.004187             33        0.924417   \n",
       "3        0.988658      0.007179             29        0.925401   \n",
       "4        0.916158      0.073626             60        0.832096   \n",
       "5        0.969767      0.005241             44        0.894993   \n",
       "6        0.986454      0.003438             35        0.932266   \n",
       "7        0.989454      0.007018             25        0.928696   \n",
       "8        0.986454      0.003438             35        0.932266   \n",
       "9        0.989454      0.007018             25        0.928696   \n",
       "10       0.942237      0.010706             56        0.850088   \n",
       "11       0.963397      0.006469             47        0.902579   \n",
       "12       0.989029      0.006002             27        0.932500   \n",
       "13       0.990392      0.007782             17        0.929971   \n",
       "14       0.989029      0.006002             27        0.932500   \n",
       "15       0.990392      0.007782             17        0.929971   \n",
       "16       0.937926      0.025051             58        0.855188   \n",
       "17       0.962149      0.010245             49        0.905681   \n",
       "18       0.991867      0.003844             13        0.936874   \n",
       "19       0.993197      0.005217              9        0.933227   \n",
       "20       0.991867      0.003844             13        0.936874   \n",
       "21       0.993197      0.005217              9        0.933227   \n",
       "22       0.945286      0.020280             54        0.857948   \n",
       "23       0.968277      0.007051             46        0.920669   \n",
       "24       0.995102      0.003038              5        0.941394   \n",
       "25       0.996425      0.002261              1        0.939828   \n",
       "26       0.995102      0.003038              5        0.941394   \n",
       "27       0.996425      0.002261              1        0.939828   \n",
       "28       0.955630      0.019962             51        0.879351   \n",
       "29       0.970972      0.007694             41        0.913745   \n",
       "30       0.985327      0.005413             39        0.924229   \n",
       "31       0.988497      0.006979             31        0.926234   \n",
       "32       0.985327      0.005413             39        0.924229   \n",
       "33       0.988497      0.006979             31        0.926234   \n",
       "34       0.916427      0.073677             59        0.830879   \n",
       "35       0.969998      0.005901             43        0.894600   \n",
       "36       0.985368      0.003808             37        0.930661   \n",
       "37       0.989664      0.006873             21        0.928653   \n",
       "38       0.985368      0.003808             37        0.930661   \n",
       "39       0.989664      0.006873             21        0.928653   \n",
       "40       0.942831      0.010693             55        0.851739   \n",
       "41       0.961220      0.005487             50        0.901010   \n",
       "42       0.989470      0.005043             23        0.932730   \n",
       "43       0.990842      0.006939             15        0.934470   \n",
       "44       0.989470      0.005043             23        0.932730   \n",
       "45       0.990842      0.006939             15        0.934470   \n",
       "46       0.939480      0.027193             57        0.855508   \n",
       "47       0.962829      0.009091             48        0.907765   \n",
       "48       0.989834      0.004758             19        0.940274   \n",
       "49       0.994739      0.004267              7        0.937151   \n",
       "50       0.989834      0.004758             19        0.940274   \n",
       "51       0.994739      0.004267              7        0.937151   \n",
       "52       0.946913      0.020080             53        0.870283   \n",
       "53       0.968819      0.006950             45        0.922922   \n",
       "54       0.991972      0.004007             11        0.935752   \n",
       "55       0.995510      0.003338              3        0.943267   \n",
       "56       0.991972      0.004007             11        0.935752   \n",
       "57       0.995510      0.003338              3        0.943267   \n",
       "58       0.955528      0.021215             52        0.871466   \n",
       "59       0.970928      0.006778             42        0.912333   \n",
       "\n",
       "    split1_test_F1  split2_test_F1  split3_test_F1  split4_test_F1  \\\n",
       "0         0.928571        0.926751        0.887157        0.922538   \n",
       "1         0.937670        0.951913        0.916966        0.926010   \n",
       "2         0.928571        0.926751        0.887157        0.922538   \n",
       "3         0.937670        0.951913        0.916966        0.926010   \n",
       "4         0.831511        0.875637        0.687545        0.856332   \n",
       "5         0.905742        0.911496        0.884012        0.912803   \n",
       "6         0.916052        0.932470        0.897588        0.917141   \n",
       "7         0.935505        0.946044        0.916317        0.926371   \n",
       "8         0.916052        0.932470        0.897588        0.917141   \n",
       "9         0.935505        0.946044        0.916317        0.926371   \n",
       "10        0.847182        0.861452        0.861331        0.881954   \n",
       "11        0.916061        0.887743        0.872522        0.908920   \n",
       "12        0.924390        0.936020        0.901791        0.936436   \n",
       "13        0.934124        0.942491        0.917302        0.934665   \n",
       "14        0.924390        0.936020        0.901791        0.936436   \n",
       "15        0.934124        0.942491        0.917302        0.934665   \n",
       "16        0.877426        0.860019        0.804484        0.897167   \n",
       "17        0.927097        0.903234        0.887811        0.899377   \n",
       "18        0.922403        0.934248        0.908731        0.936224   \n",
       "19        0.925371        0.938147        0.925802        0.939187   \n",
       "20        0.922403        0.934248        0.908731        0.936224   \n",
       "21        0.925371        0.938147        0.925802        0.939187   \n",
       "22        0.883731        0.832467        0.858072        0.909956   \n",
       "23        0.925361        0.912616        0.907775        0.896406   \n",
       "24        0.930329        0.953079        0.928528        0.940943   \n",
       "25        0.941861        0.944869        0.933600        0.939187   \n",
       "26        0.930329        0.953079        0.928528        0.940943   \n",
       "27        0.941861        0.944869        0.933600        0.939187   \n",
       "28        0.886948        0.840981        0.900880        0.891451   \n",
       "29        0.925265        0.917192        0.918374        0.899074   \n",
       "30        0.932009        0.925690        0.886693        0.924349   \n",
       "31        0.938172        0.951157        0.918053        0.926659   \n",
       "32        0.932009        0.925690        0.886693        0.924349   \n",
       "33        0.938172        0.951157        0.918053        0.926659   \n",
       "34        0.831682        0.878360        0.689108        0.858669   \n",
       "35        0.906845        0.912311        0.884224        0.913786   \n",
       "36        0.914901        0.932542        0.899484        0.917163   \n",
       "37        0.933777        0.947500        0.919120        0.926299   \n",
       "38        0.914901        0.932542        0.899484        0.917163   \n",
       "39        0.933777        0.947500        0.919120        0.926299   \n",
       "40        0.846924        0.863527        0.861151        0.884058   \n",
       "41        0.906595        0.890358        0.871863        0.908273   \n",
       "42        0.921751        0.938702        0.910725        0.939117   \n",
       "43        0.928916        0.947638        0.918101        0.936860   \n",
       "44        0.921751        0.938702        0.910725        0.939117   \n",
       "45        0.928916        0.947638        0.918101        0.936860   \n",
       "46        0.876128        0.863578        0.800526        0.906796   \n",
       "47        0.927116        0.904214        0.887797        0.902429   \n",
       "48        0.924649        0.935100        0.912662        0.923626   \n",
       "49        0.926885        0.945627        0.925245        0.938976   \n",
       "50        0.924649        0.935100        0.912662        0.923626   \n",
       "51        0.926885        0.945627        0.925245        0.938976   \n",
       "52        0.884145        0.832701        0.863232        0.909872   \n",
       "53        0.927585        0.915011        0.908909        0.894898   \n",
       "54        0.927120        0.954516        0.925938        0.933893   \n",
       "55        0.934106        0.954385        0.931124        0.936648   \n",
       "56        0.927120        0.954516        0.925938        0.933893   \n",
       "57        0.934106        0.954385        0.931124        0.936648   \n",
       "58        0.886762        0.841252        0.899069        0.892426   \n",
       "59        0.926875        0.917844        0.920557        0.898570   \n",
       "\n",
       "    mean_test_F1  std_test_F1  rank_test_F1  split0_test_Precision  \\\n",
       "0       0.917887     0.015500            39               0.996101   \n",
       "1       0.931592     0.012110            19               0.999565   \n",
       "2       0.917887     0.015500            39               0.996101   \n",
       "3       0.931592     0.012110            19               0.999565   \n",
       "4       0.816624     0.066606            60               0.996338   \n",
       "5       0.901809     0.010894            48               0.989848   \n",
       "6       0.919103     0.012869            33               0.999857   \n",
       "7       0.930587     0.009880            23               0.998705   \n",
       "8       0.919103     0.012869            33               0.999857   \n",
       "9       0.930587     0.009880            23               0.998705   \n",
       "10      0.860401     0.012228            57               0.979140   \n",
       "11      0.897565     0.015619            49               0.993392   \n",
       "12      0.926228     0.012961            31               0.996164   \n",
       "13      0.931711     0.008263            17               1.000000   \n",
       "14      0.926228     0.012961            31               0.996164   \n",
       "15      0.931711     0.008263            17               1.000000   \n",
       "16      0.858857     0.030931            58               0.968528   \n",
       "17      0.904640     0.012793            46               0.983731   \n",
       "18      0.927696     0.010840            27               0.998726   \n",
       "19      0.932347     0.005877            13               0.999286   \n",
       "20      0.927696     0.010840            27               0.998726   \n",
       "21      0.932347     0.005877            13               0.999286   \n",
       "22      0.868435     0.026340            54               0.952686   \n",
       "23      0.912566     0.010134            44               0.994919   \n",
       "24      0.938855     0.008860             5               0.999579   \n",
       "25      0.939869     0.003708             3               1.000000   \n",
       "26      0.938855     0.008860             5               0.999579   \n",
       "27      0.939869     0.003708             3               1.000000   \n",
       "28      0.879922     0.020680            51               0.987233   \n",
       "29      0.914730     0.008677            42               0.993829   \n",
       "30      0.918594     0.016204            37               0.993673   \n",
       "31      0.932055     0.011501            15               0.998987   \n",
       "32      0.918594     0.016204            37               0.993673   \n",
       "33      0.932055     0.011501            15               0.998987   \n",
       "34      0.817739     0.066728            59               0.996503   \n",
       "35      0.902353     0.011304            47               0.989989   \n",
       "36      0.918950     0.012003            35               0.999283   \n",
       "37      0.931070     0.009473            21               0.998275   \n",
       "38      0.918950     0.012003            35               0.999283   \n",
       "39      0.931070     0.009473            21               0.998275   \n",
       "40      0.861480     0.012813            55               0.977803   \n",
       "41      0.895620     0.013429            50               0.992480   \n",
       "42      0.928605     0.010919            25               0.997013   \n",
       "43      0.933197     0.009693            11               0.999857   \n",
       "44      0.928605     0.010919            25               0.997013   \n",
       "45      0.933197     0.009693            11               0.999857   \n",
       "46      0.860507     0.034695            56               0.967951   \n",
       "47      0.905864     0.012619            45               0.986933   \n",
       "48      0.927262     0.009633            29               0.998315   \n",
       "49      0.934777     0.007670             9               1.000000   \n",
       "50      0.927262     0.009633            29               0.998315   \n",
       "51      0.934777     0.007670             9               1.000000   \n",
       "52      0.872047     0.025322            53               0.958083   \n",
       "53      0.913865     0.011453            43               0.996809   \n",
       "54      0.935444     0.010255             7               0.998582   \n",
       "55      0.939906     0.008274             1               0.999860   \n",
       "56      0.935444     0.010255             7               0.998582   \n",
       "57      0.939906     0.008274             1               0.999860   \n",
       "58      0.878195     0.020600            52               0.983498   \n",
       "59      0.915236     0.009558            41               0.992214   \n",
       "\n",
       "    split1_test_Precision  split2_test_Precision  split3_test_Precision  \\\n",
       "0                0.998418               0.999855               1.000000   \n",
       "1                0.999575               1.000000               0.999410   \n",
       "2                0.998418               0.999855               1.000000   \n",
       "3                0.999575               1.000000               0.999410   \n",
       "4                0.996855               0.958656               0.722230   \n",
       "5                0.983876               0.984622               0.982716   \n",
       "6                0.998084               1.000000               1.000000   \n",
       "7                0.999148               1.000000               0.999262   \n",
       "8                0.998084               1.000000               1.000000   \n",
       "9                0.999148               1.000000               0.999262   \n",
       "10               0.988496               0.923980               0.957906   \n",
       "11               0.991411               0.942051               0.987828   \n",
       "12               0.999564               1.000000               0.999544   \n",
       "13               0.999715               1.000000               0.996919   \n",
       "14               0.999564               1.000000               0.999544   \n",
       "15               0.999715               1.000000               0.996919   \n",
       "16               0.993362               0.935617               0.907762   \n",
       "17               0.995837               0.963446               0.978759   \n",
       "18               1.000000               1.000000               0.999850   \n",
       "19               1.000000               0.999859               0.998842   \n",
       "20               1.000000               1.000000               0.999850   \n",
       "21               1.000000               0.999859               0.998842   \n",
       "22               0.987647               0.879171               0.936419   \n",
       "23               0.994966               0.973233               0.967861   \n",
       "24               1.000000               1.000000               1.000000   \n",
       "25               1.000000               0.999860               1.000000   \n",
       "26               1.000000               1.000000               1.000000   \n",
       "27               1.000000               0.999860               1.000000   \n",
       "28               0.995333               0.908946               0.982428   \n",
       "29               0.998407               0.976426               0.984968   \n",
       "30               0.998286               0.999565               1.000000   \n",
       "31               0.999435               1.000000               0.999558   \n",
       "32               0.998286               0.999565               1.000000   \n",
       "33               0.999435               1.000000               0.999558   \n",
       "34               0.996856               0.960939               0.725076   \n",
       "35               0.985620               0.984506               0.983614   \n",
       "36               0.997785               1.000000               1.000000   \n",
       "37               0.999572               1.000000               0.998973   \n",
       "38               0.997785               1.000000               1.000000   \n",
       "39               0.999572               1.000000               0.998973   \n",
       "40               0.989801               0.928767               0.956901   \n",
       "41               0.987622               0.945107               0.988743   \n",
       "42               0.998978               1.000000               1.000000   \n",
       "43               0.999712               1.000000               0.997945   \n",
       "44               0.998978               1.000000               1.000000   \n",
       "45               0.999712               1.000000               0.997945   \n",
       "46               0.994443               0.940760               0.896589   \n",
       "47               0.995552               0.966970               0.977457   \n",
       "48               1.000000               1.000000               0.999851   \n",
       "49               1.000000               1.000000               0.998552   \n",
       "50               1.000000               1.000000               0.999851   \n",
       "51               1.000000               1.000000               0.998552   \n",
       "52               0.988110               0.873884               0.944172   \n",
       "53               0.994989               0.976596               0.971412   \n",
       "54               0.999711               1.000000               1.000000   \n",
       "55               1.000000               0.999863               0.999713   \n",
       "56               0.999711               1.000000               1.000000   \n",
       "57               1.000000               0.999863               0.999713   \n",
       "58               0.995640               0.906557               0.984959   \n",
       "59               0.996978               0.977266               0.984756   \n",
       "\n",
       "    split4_test_Precision  mean_test_Precision  std_test_Precision  \\\n",
       "0                1.000000             0.998875            0.001510   \n",
       "1                1.000000             0.999710            0.000244   \n",
       "2                1.000000             0.998875            0.001510   \n",
       "3                1.000000             0.999710            0.000244   \n",
       "4                0.959503             0.926716            0.103611   \n",
       "5                0.978544             0.983921            0.003633   \n",
       "6                1.000000             0.999588            0.000754   \n",
       "7                1.000000             0.999423            0.000507   \n",
       "8                1.000000             0.999588            0.000754   \n",
       "9                1.000000             0.999423            0.000507   \n",
       "10               0.951905             0.960285            0.022562   \n",
       "11               0.981162             0.979169            0.019020   \n",
       "12               1.000000             0.999054            0.001459   \n",
       "13               1.000000             0.999327            0.001209   \n",
       "14               1.000000             0.999054            0.001459   \n",
       "15               1.000000             0.999327            0.001209   \n",
       "16               0.950861             0.951226            0.029009   \n",
       "17               0.969504             0.978255            0.011272   \n",
       "18               1.000000             0.999715            0.000498   \n",
       "19               1.000000             0.999597            0.000460   \n",
       "20               1.000000             0.999715            0.000498   \n",
       "21               1.000000             0.999597            0.000460   \n",
       "22               0.981061             0.947397            0.038876   \n",
       "23               0.983717             0.982939            0.011048   \n",
       "24               1.000000             0.999916            0.000169   \n",
       "25               1.000000             0.999972            0.000056   \n",
       "26               1.000000             0.999916            0.000169   \n",
       "27               1.000000             0.999972            0.000056   \n",
       "28               0.948393             0.964466            0.032046   \n",
       "29               0.987287             0.988183            0.007560   \n",
       "30               1.000000             0.998305            0.002400   \n",
       "31               1.000000             0.999596            0.000381   \n",
       "32               1.000000             0.998305            0.002400   \n",
       "33               1.000000             0.999596            0.000381   \n",
       "34               0.964030             0.928681            0.102949   \n",
       "35               0.979823             0.984710            0.003281   \n",
       "36               0.999705             0.999355            0.000828   \n",
       "37               1.000000             0.999364            0.000662   \n",
       "38               0.999705             0.999355            0.000828   \n",
       "39               1.000000             0.999364            0.000662   \n",
       "40               0.953953             0.961445            0.021054   \n",
       "41               0.980998             0.978990            0.017342   \n",
       "42               1.000000             0.999198            0.001162   \n",
       "43               1.000000             0.999503            0.000786   \n",
       "44               1.000000             0.999198            0.001162   \n",
       "45               1.000000             0.999503            0.000786   \n",
       "46               0.967399             0.953428            0.033104   \n",
       "47               0.980211             0.981425            0.009551   \n",
       "48               1.000000             0.999633            0.000662   \n",
       "49               1.000000             0.999710            0.000579   \n",
       "50               1.000000             0.999633            0.000662   \n",
       "51               1.000000             0.999710            0.000579   \n",
       "52               0.982879             0.949426            0.041048   \n",
       "53               0.982942             0.984550            0.009977   \n",
       "54               0.999857             0.999630            0.000535   \n",
       "55               1.000000             0.999887            0.000107   \n",
       "56               0.999857             0.999630            0.000535   \n",
       "57               1.000000             0.999887            0.000107   \n",
       "58               0.950282             0.964187            0.032583   \n",
       "59               0.986252             0.987493            0.006721   \n",
       "\n",
       "    rank_test_Precision  split0_test_Recall  split1_test_Recall  \\\n",
       "0                    37            0.862358            0.867858   \n",
       "1                    11            0.861483            0.882985   \n",
       "2                    37            0.862358            0.867858   \n",
       "3                    11            0.861483            0.882985   \n",
       "4                    60            0.714339            0.713214   \n",
       "5                    45            0.816727            0.839105   \n",
       "6                    21            0.873234            0.846481   \n",
       "7                    25            0.867858            0.879485   \n",
       "8                    21            0.873234            0.846481   \n",
       "9                    25            0.867858            0.879485   \n",
       "10                   54            0.751094            0.741218   \n",
       "11                   48            0.826978            0.851356   \n",
       "12                   35            0.876485            0.859732   \n",
       "13                   31            0.869109            0.876610   \n",
       "14                   35            0.876485            0.859732   \n",
       "15                   31            0.869109            0.876610   \n",
       "16                   56            0.765596            0.785723   \n",
       "17                   50            0.839105            0.867233   \n",
       "18                    7            0.882235            0.855982   \n",
       "19                   17            0.875359            0.861108   \n",
       "20                    7            0.882235            0.855982   \n",
       "21                   17            0.875359            0.861108   \n",
       "22                   58            0.780348            0.799600   \n",
       "23                   46            0.856732            0.864858   \n",
       "24                    3            0.889611            0.869734   \n",
       "25                    1            0.886486            0.890111   \n",
       "26                    3            0.889611            0.869734   \n",
       "27                    1            0.886486            0.890111   \n",
       "28                   51            0.792724            0.799850   \n",
       "29                   41            0.845606            0.862108   \n",
       "30                   39            0.863858            0.873984   \n",
       "31                   19            0.863358            0.883985   \n",
       "32                   39            0.863858            0.873984   \n",
       "33                   19            0.863358            0.883985   \n",
       "34                   59            0.712464            0.713464   \n",
       "35                   43            0.815977            0.839730   \n",
       "36                   29            0.870859            0.844731   \n",
       "37                   27            0.868109            0.876110   \n",
       "38                   29            0.870859            0.844731   \n",
       "39                   27            0.868109            0.876110   \n",
       "40                   53            0.754469            0.740093   \n",
       "41                   49            0.824978            0.837855   \n",
       "42                   33            0.876235            0.855607   \n",
       "43                   23            0.877110            0.867483   \n",
       "44                   33            0.876235            0.855607   \n",
       "45                   23            0.877110            0.867483   \n",
       "46                   55            0.766471            0.782973   \n",
       "47                   47            0.840355            0.867483   \n",
       "48                   13            0.888611            0.859857   \n",
       "49                    9            0.881735            0.863733   \n",
       "50                   13            0.888611            0.859857   \n",
       "51                    9            0.881735            0.863733   \n",
       "52                   57            0.797225            0.799975   \n",
       "53                   44            0.859232            0.868734   \n",
       "54                   15            0.880360            0.864358   \n",
       "55                    5            0.892737            0.876360   \n",
       "56                   15            0.880360            0.864358   \n",
       "57                    5            0.892737            0.876360   \n",
       "58                   52            0.782348            0.799350   \n",
       "59                   42            0.844356            0.865983   \n",
       "\n",
       "    split2_test_Recall  split3_test_Recall  split4_test_Recall  \\\n",
       "0             0.863608            0.797199            0.856214   \n",
       "1             0.908239            0.847087            0.862216   \n",
       "2             0.863608            0.797199            0.856214   \n",
       "3             0.908239            0.847087            0.862216   \n",
       "4             0.805851            0.656039            0.773193   \n",
       "5             0.848481            0.803326            0.855339   \n",
       "6             0.873484            0.814204            0.846962   \n",
       "7             0.897612            0.846087            0.862841   \n",
       "8             0.873484            0.814204            0.846962   \n",
       "9             0.897612            0.846087            0.862841   \n",
       "10            0.806851            0.782446            0.821580   \n",
       "11            0.839355            0.781320            0.846587   \n",
       "12            0.879735            0.821455            0.880470   \n",
       "13            0.891236            0.849462            0.877344   \n",
       "14            0.879735            0.821455            0.880470   \n",
       "15            0.891236            0.849462            0.877344   \n",
       "16            0.795724            0.722306            0.849212   \n",
       "17            0.850106            0.812328            0.838710   \n",
       "18            0.876610            0.832833            0.880095   \n",
       "19            0.883610            0.862716            0.885346   \n",
       "20            0.876610            0.832833            0.880095   \n",
       "21            0.883610            0.862716            0.885346   \n",
       "22            0.790474            0.791823            0.848462   \n",
       "23            0.859107            0.854714            0.823331   \n",
       "24            0.910364            0.866592            0.888472   \n",
       "25            0.895612            0.875469            0.885346   \n",
       "26            0.910364            0.866592            0.888472   \n",
       "27            0.895612            0.875469            0.885346   \n",
       "28            0.782473            0.831833            0.840960   \n",
       "29            0.864733            0.860215            0.825331   \n",
       "30            0.861983            0.796449            0.859340   \n",
       "31            0.906863            0.848837            0.863341   \n",
       "32            0.861983            0.796449            0.859340   \n",
       "33            0.906863            0.848837            0.863341   \n",
       "34            0.808851            0.656539            0.774069   \n",
       "35            0.849981            0.803076            0.856089   \n",
       "36            0.873609            0.817329            0.847212   \n",
       "37            0.900238            0.851088            0.862716   \n",
       "38            0.873609            0.817329            0.847212   \n",
       "39            0.900238            0.851088            0.862716   \n",
       "40            0.806851            0.782821            0.823706   \n",
       "41            0.841605            0.779695            0.845586   \n",
       "42            0.884486            0.836084            0.885221   \n",
       "43            0.900488            0.850088            0.881220   \n",
       "44            0.884486            0.836084            0.885221   \n",
       "45            0.900488            0.850088            0.881220   \n",
       "46            0.798100            0.723056            0.853338   \n",
       "47            0.849106            0.813203            0.836084   \n",
       "48            0.878110            0.839460            0.858090   \n",
       "49            0.896862            0.861965            0.884971   \n",
       "50            0.878110            0.839460            0.858090   \n",
       "51            0.896862            0.861965            0.884971   \n",
       "52            0.795224            0.795074            0.846962   \n",
       "53            0.860733            0.853963            0.821330   \n",
       "54            0.912989            0.862091            0.876094   \n",
       "55            0.912864            0.871343            0.880845   \n",
       "56            0.912989            0.862091            0.876094   \n",
       "57            0.912864            0.871343            0.880845   \n",
       "58            0.784723            0.826957            0.841210   \n",
       "59            0.865233            0.864216            0.825206   \n",
       "\n",
       "    mean_test_Recall  std_test_Recall  rank_test_Recall  split0_test_Accuracy  \\\n",
       "0           0.849448         0.026389                43              0.929500   \n",
       "1           0.872402         0.021261                19              0.930562   \n",
       "2           0.849448         0.026389                43              0.929500   \n",
       "3           0.872402         0.021261                19              0.930562   \n",
       "4           0.732527         0.052124                60              0.855875   \n",
       "5           0.832596         0.019598                48              0.904188   \n",
       "6           0.850873         0.021866                39              0.936562   \n",
       "7           0.870777         0.017188                23              0.933375   \n",
       "8           0.850873         0.021866                39              0.936562   \n",
       "9           0.870777         0.017188                23              0.933375   \n",
       "10          0.780638         0.030963                58              0.867563   \n",
       "11          0.829119         0.025273                49              0.910750   \n",
       "12          0.863575         0.022370                31              0.936562   \n",
       "13          0.872752         0.013663                17              0.934562   \n",
       "14          0.863575         0.022370                31              0.936562   \n",
       "15          0.872752         0.013663                17              0.934562   \n",
       "16          0.783712         0.041322                56              0.870375   \n",
       "17          0.841496         0.017893                45              0.912625   \n",
       "18          0.865551         0.018837                27              0.940562   \n",
       "19          0.873628         0.010157                13              0.937375   \n",
       "20          0.865551         0.018837                27              0.940562   \n",
       "21          0.873628         0.010157                13              0.937375   \n",
       "22          0.802141         0.023957                54              0.870812   \n",
       "23          0.851748         0.014610                35              0.926188   \n",
       "24          0.884954         0.015802                 5              0.944625   \n",
       "25          0.886605         0.006619                 3              0.943250   \n",
       "26          0.884954         0.015802                 5              0.944625   \n",
       "27          0.886605         0.006619                 3              0.943250   \n",
       "28          0.809568         0.022775                51              0.891250   \n",
       "29          0.851599         0.014718                36              0.920188   \n",
       "30          0.851123         0.027783                37              0.929188   \n",
       "31          0.873277         0.020185                15              0.931250   \n",
       "32          0.851123         0.027783                37              0.929188   \n",
       "33          0.873277         0.020185                15              0.931250   \n",
       "34          0.733077         0.053084                59              0.855000   \n",
       "35          0.832971         0.020258                47              0.903875   \n",
       "36          0.850748         0.020458                41              0.935125   \n",
       "37          0.871652         0.016446                21              0.933312   \n",
       "38          0.850748         0.020458                41              0.935125   \n",
       "39          0.871652         0.016446                21              0.933312   \n",
       "40          0.781588         0.031212                57              0.868687   \n",
       "41          0.825944         0.024137                50              0.909375   \n",
       "42          0.867526         0.019012                25              0.936813   \n",
       "43          0.875278         0.016550                11              0.938500   \n",
       "44          0.867526         0.019012                25              0.936813   \n",
       "45          0.875278         0.016550                11              0.938500   \n",
       "46          0.784788         0.042488                55              0.870563   \n",
       "47          0.841246         0.017686                46              0.914625   \n",
       "48          0.864826         0.017063                29              0.943562   \n",
       "49          0.877853         0.013258                 9              0.940875   \n",
       "50          0.864826         0.017063                29              0.943562   \n",
       "51          0.877853         0.013258                 9              0.940875   \n",
       "52          0.806892         0.020113                53              0.881188   \n",
       "53          0.852798         0.016431                34              0.928250   \n",
       "54          0.879178         0.018252                 7              0.939562   \n",
       "55          0.886830         0.014819                 1              0.946313   \n",
       "56          0.879178         0.018252                 7              0.939562   \n",
       "57          0.886830         0.014819                 1              0.946313   \n",
       "58          0.806918         0.023371                52              0.884625   \n",
       "59          0.852999         0.016070                33              0.918875   \n",
       "\n",
       "    split1_test_Accuracy  split2_test_Accuracy  split3_test_Accuracy  \\\n",
       "0               0.933250              0.931750              0.898625   \n",
       "1               0.941312              0.954125              0.923312   \n",
       "2               0.933250              0.931750              0.898625   \n",
       "3               0.941312              0.954125              0.923312   \n",
       "4               0.855500              0.885563              0.701937   \n",
       "5               0.912687              0.917625              0.894625   \n",
       "6               0.922438              0.936750              0.907125   \n",
       "7               0.939375              0.948812              0.922750   \n",
       "8               0.922438              0.936750              0.907125   \n",
       "9               0.939375              0.948812              0.922750   \n",
       "10              0.866313              0.870250              0.874062   \n",
       "11              0.922000              0.893875              0.885875   \n",
       "12              0.929688              0.939875              0.910563   \n",
       "13              0.938187              0.945625              0.923438   \n",
       "14              0.929688              0.939875              0.910563   \n",
       "15              0.938187              0.945625              0.923438   \n",
       "16              0.890250              0.870500              0.824500   \n",
       "17              0.931813              0.908937              0.897375   \n",
       "18              0.928000              0.938312              0.916375   \n",
       "19              0.930562              0.941750              0.930875   \n",
       "20              0.928000              0.938312              0.916375   \n",
       "21              0.930562              0.941750              0.930875   \n",
       "22              0.894813              0.840938              0.869062   \n",
       "23              0.930250              0.917750              0.913188   \n",
       "24              0.934875              0.955187              0.933312   \n",
       "25              0.945063              0.947750              0.937750   \n",
       "26              0.934875              0.955187              0.933312   \n",
       "27              0.945063              0.947750              0.937750   \n",
       "28              0.898062              0.852062              0.908500   \n",
       "29              0.930375              0.921937              0.923562   \n",
       "30              0.936250              0.930813              0.898250   \n",
       "31              0.941750              0.953438              0.924250   \n",
       "32              0.936250              0.930813              0.898250   \n",
       "33              0.941750              0.953438              0.924250   \n",
       "34              0.855625              0.888000              0.703875   \n",
       "35              0.913750              0.918312              0.894875   \n",
       "36              0.921438              0.936813              0.908687   \n",
       "37              0.937875              0.950125              0.925125   \n",
       "38              0.921438              0.936813              0.908687   \n",
       "39              0.937875              0.950125              0.925125   \n",
       "40              0.866250              0.872500              0.873812   \n",
       "41              0.913687              0.896375              0.885437   \n",
       "42              0.927375              0.942250              0.918063   \n",
       "43              0.933625              0.950250              0.924188   \n",
       "44              0.927375              0.942250              0.918063   \n",
       "45              0.933625              0.950250              0.924188   \n",
       "46              0.889312              0.873938              0.819875   \n",
       "47              0.931813              0.910062              0.897250   \n",
       "48              0.929937              0.939063              0.919687   \n",
       "49              0.931875              0.948438              0.930375   \n",
       "50              0.929937              0.939063              0.919687   \n",
       "51              0.931875              0.948438              0.930375   \n",
       "52              0.895188              0.840250              0.874062   \n",
       "53              0.932187              0.920063              0.914438   \n",
       "54              0.932063              0.956500              0.931063   \n",
       "55              0.938187              0.956375              0.935562   \n",
       "56              0.932063              0.956500              0.931063   \n",
       "57              0.938187              0.956375              0.935562   \n",
       "58              0.897938              0.851938              0.907188   \n",
       "59              0.931688              0.922562              0.925438   \n",
       "\n",
       "    split4_test_Accuracy  mean_test_Accuracy  std_test_Accuracy  \\\n",
       "0               0.928125            0.924250           0.012934   \n",
       "1               0.931125            0.936087           0.010686   \n",
       "2               0.928125            0.924250           0.012934   \n",
       "3               0.931125            0.936087           0.010686   \n",
       "4               0.870313            0.833838           0.066871   \n",
       "5               0.918312            0.909488           0.008981   \n",
       "6               0.923500            0.925275           0.010952   \n",
       "7               0.931438            0.935150           0.008663   \n",
       "8               0.923500            0.925275           0.010952   \n",
       "9               0.931438            0.935150           0.008663   \n",
       "10              0.890062            0.873650           0.008626   \n",
       "11              0.915188            0.905537           0.013520   \n",
       "12              0.940250            0.931387           0.011081   \n",
       "13              0.938688            0.936100           0.007273   \n",
       "14              0.940250            0.931387           0.011081   \n",
       "15              0.938688            0.936100           0.007273   \n",
       "16              0.902687            0.871663           0.026591   \n",
       "17              0.906188            0.911388           0.011385   \n",
       "18              0.940063            0.932662           0.009339   \n",
       "19              0.942688            0.936650           0.005165   \n",
       "20              0.940063            0.932662           0.009339   \n",
       "21              0.942688            0.936650           0.005165   \n",
       "22              0.916063            0.878337           0.025440   \n",
       "23              0.904875            0.918450           0.009073   \n",
       "24              0.944250            0.942450           0.007888   \n",
       "25              0.942688            0.943300           0.003289   \n",
       "26              0.944250            0.942450           0.007888   \n",
       "27              0.942688            0.943300           0.003289   \n",
       "28              0.897625            0.889500           0.019519   \n",
       "29              0.907375            0.920687           0.007499   \n",
       "30              0.929688            0.924837           0.013530   \n",
       "31              0.931688            0.936475           0.010151   \n",
       "32              0.929688            0.924837           0.013530   \n",
       "33              0.931688            0.936475           0.010151   \n",
       "34              0.872625            0.835025           0.066699   \n",
       "35              0.919250            0.910013           0.009327   \n",
       "36              0.923500            0.925113           0.010228   \n",
       "37              0.931375            0.935562           0.008354   \n",
       "38              0.923500            0.925113           0.010228   \n",
       "39              0.931375            0.935562           0.008354   \n",
       "40              0.892000            0.874650           0.009082   \n",
       "41              0.914625            0.903900           0.011299   \n",
       "42              0.942625            0.933425           0.009451   \n",
       "43              0.940625            0.937438           0.008550   \n",
       "44              0.942625            0.933425           0.009451   \n",
       "45              0.940625            0.937438           0.008550   \n",
       "46              0.912312            0.873200           0.030465   \n",
       "47              0.909625            0.912675           0.011172   \n",
       "48              0.929063            0.932262           0.008339   \n",
       "49              0.942500            0.938812           0.006780   \n",
       "50              0.929063            0.932262           0.008339   \n",
       "51              0.942500            0.938812           0.006780   \n",
       "52              0.916125            0.881363           0.025072   \n",
       "53              0.903563            0.919700           0.010171   \n",
       "54              0.938000            0.939438           0.009140   \n",
       "55              0.940438            0.943375           0.007405   \n",
       "56              0.938000            0.939438           0.009140   \n",
       "57              0.940438            0.943375           0.007405   \n",
       "58              0.898625            0.888062           0.019451   \n",
       "59              0.906875            0.921088           0.008250   \n",
       "\n",
       "    rank_test_Accuracy  \n",
       "0                   39  \n",
       "1                   19  \n",
       "2                   39  \n",
       "3                   19  \n",
       "4                   60  \n",
       "5                   48  \n",
       "6                   33  \n",
       "7                   23  \n",
       "8                   33  \n",
       "9                   23  \n",
       "10                  56  \n",
       "11                  49  \n",
       "12                  31  \n",
       "13                  17  \n",
       "14                  31  \n",
       "15                  17  \n",
       "16                  58  \n",
       "17                  46  \n",
       "18                  27  \n",
       "19                  13  \n",
       "20                  27  \n",
       "21                  13  \n",
       "22                  54  \n",
       "23                  44  \n",
       "24                   5  \n",
       "25                   3  \n",
       "26                   5  \n",
       "27                   3  \n",
       "28                  51  \n",
       "29                  42  \n",
       "30                  37  \n",
       "31                  15  \n",
       "32                  37  \n",
       "33                  15  \n",
       "34                  59  \n",
       "35                  47  \n",
       "36                  35  \n",
       "37                  21  \n",
       "38                  35  \n",
       "39                  21  \n",
       "40                  55  \n",
       "41                  50  \n",
       "42                  25  \n",
       "43                  11  \n",
       "44                  25  \n",
       "45                  11  \n",
       "46                  57  \n",
       "47                  45  \n",
       "48                  29  \n",
       "49                   9  \n",
       "50                  29  \n",
       "51                   9  \n",
       "52                  53  \n",
       "53                  43  \n",
       "54                   7  \n",
       "55                   1  \n",
       "56                   7  \n",
       "57                   1  \n",
       "58                  52  \n",
       "59                  41  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = CV.predict(X_test)\n",
    "probabilities = CV.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8993218463807906 0.9345326804343197 0.877285899870091 0.9997722355084843 0.9385\n",
      "[[9991    2]\n",
      " [1228 8779]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, f1_score, recall_score, precision_score, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "tpr, fpr, thresolds = roc_curve(y_test, probabilities[:, 1])\n",
    "plt.plot(tpr, fpr)\n",
    "print(fbeta_score(y_test, predictions, beta=2), f1_score(y_test, predictions), recall_score(y_test, predictions), precision_score(y_test, predictions), accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>ORIGIN_CITY_MARKET_ID</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST_CITY_MARKET_ID</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>TAXI_OUT_median</th>\n",
       "      <th>TAXI_IN_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3151323</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>AS</td>\n",
       "      <td>N287AK</td>\n",
       "      <td>30559</td>\n",
       "      <td>SEA</td>\n",
       "      <td>30466</td>\n",
       "      <td>PHX</td>\n",
       "      <td>945</td>\n",
       "      <td>938.0</td>\n",
       "      <td>1235</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281361</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>AA</td>\n",
       "      <td>N111US</td>\n",
       "      <td>35096</td>\n",
       "      <td>SYR</td>\n",
       "      <td>31057</td>\n",
       "      <td>CLT</td>\n",
       "      <td>606</td>\n",
       "      <td>600.0</td>\n",
       "      <td>824</td>\n",
       "      <td>138.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119182</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>UA</td>\n",
       "      <td>N62895</td>\n",
       "      <td>30977</td>\n",
       "      <td>ORD</td>\n",
       "      <td>31453</td>\n",
       "      <td>IAH</td>\n",
       "      <td>1425</td>\n",
       "      <td>1423.0</td>\n",
       "      <td>1715</td>\n",
       "      <td>170.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694514</th>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>AA</td>\n",
       "      <td>N934NN</td>\n",
       "      <td>30194</td>\n",
       "      <td>DFW</td>\n",
       "      <td>30852</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1024</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>1429</td>\n",
       "      <td>185.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017438</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8569Z</td>\n",
       "      <td>30721</td>\n",
       "      <td>BOS</td>\n",
       "      <td>30852</td>\n",
       "      <td>BWI</td>\n",
       "      <td>1430</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>1605</td>\n",
       "      <td>95.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MONTH  DAY_OF_MONTH  DAY_OF_WEEK OP_UNIQUE_CARRIER TAIL_NUM  \\\n",
       "3151323      6             5            3                AS   N287AK   \n",
       "1281361      3            24            7                AA   N111US   \n",
       "5119182      9            13            5                UA   N62895   \n",
       "3694514      7            21            7                AA   N934NN   \n",
       "1017438      2             7            4                WN   N8569Z   \n",
       "\n",
       "         ORIGIN_CITY_MARKET_ID ORIGIN  DEST_CITY_MARKET_ID DEST  CRS_DEP_TIME  \\\n",
       "3151323                  30559    SEA                30466  PHX           945   \n",
       "1281361                  35096    SYR                31057  CLT           606   \n",
       "5119182                  30977    ORD                31453  IAH          1425   \n",
       "3694514                  30194    DFW                30852  DCA          1024   \n",
       "1017438                  30721    BOS                30852  BWI          1430   \n",
       "\n",
       "         DEP_TIME  CRS_ARR_TIME  CRS_ELAPSED_TIME  DISTANCE  DISTANCE_GROUP  \\\n",
       "3151323     938.0          1235             170.0    1107.0               5   \n",
       "1281361     600.0           824             138.0     603.0               3   \n",
       "5119182    1423.0          1715             170.0     925.0               4   \n",
       "3694514    1207.0          1429             185.0    1192.0               5   \n",
       "1017438    1440.0          1605              95.0     369.0               2   \n",
       "\n",
       "         CARRIER_DELAY  WEATHER_DELAY  NAS_DELAY  SECURITY_DELAY  \\\n",
       "3151323            0.0            0.0        0.0             0.0   \n",
       "1281361            0.0            0.0        0.0             0.0   \n",
       "5119182            0.0            0.0        0.0             0.0   \n",
       "3694514           34.0            0.0        0.0             0.0   \n",
       "1017438            0.0            0.0        0.0             0.0   \n",
       "\n",
       "         LATE_AIRCRAFT_DELAY  TAXI_OUT_median  TAXI_IN_median  \n",
       "3151323                  0.0             20.0             6.0  \n",
       "1281361                  0.0             12.0             9.0  \n",
       "5119182                  0.0             21.0             7.0  \n",
       "3694514                 64.0             16.0             5.0  \n",
       "1017438                  0.0             16.0             4.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation = df_validation.drop('ARR_DEL15', axis=1)\n",
    "X_validation.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184606     0.0\n",
       "6719256    0.0\n",
       "1010042    1.0\n",
       "4463508    0.0\n",
       "2146575    0.0\n",
       "Name: ARR_DEL15, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation = df_validation['ARR_DEL15']\n",
    "y_validation.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = CV.predict(X_validation)\n",
    "probabilities = CV.predict_proba(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8968942099404216 0.9329587128735748 0.8743613043987954 0.99997438133048 0.9765225232665461\n",
      "[[5828949      30]\n",
      " [ 168262 1170991]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, f1_score, recall_score, precision_score, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "tpr, fpr, thresolds = roc_curve(y_validation, probabilities[:, 1])\n",
    "plt.plot(tpr, fpr)\n",
    "print(fbeta_score(y_validation, predictions, beta=2), f1_score(y_validation, predictions), recall_score(y_validation, predictions), precision_score(y_validation, predictions), accuracy_score(y_validation, predictions))\n",
    "print(confusion_matrix(y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacer aquí la confusion plot matrix !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2c24d086bb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(rf, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2c24d086a30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(rf, X_validation, y_validation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  8300.2631642\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter() - t0\n",
    "print(\"Time elapsed: \", t1) # CPU seconds elapsed (floating point)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Time elapsed:  548.8254737"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Classification Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)\n",
    "\n",
    "- Binary classification (only):\n",
    "    - [precision_recall_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve): Compute precision-recall pairs for different probability thresholds.\n",
    "        - The precision is the ratio `tp / (tp + fp)` where `tp` is the number of true positives and `fp` the number of false positives. The **precision** is intuitively the ability of the classifier **not to label as positive a sample that is negative**.\n",
    "        - The recall is the ratio `tp / (tp + fn)` where `tp` is the number of true positives and `fn` the number of false negatives. The **recall** is intuitively the ability of the classifier to **find all the positive samples**.\n",
    "\n",
    "    ### RECALL could be a potentially strong metric for this case; \"from all the flights classified as delayed, the actual (true) number delyed flights is as high as possible.\"\n",
    "\n",
    "    - [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve): A receiver operating characteristic (ROC), or simply ROC curve, is a graphical plot which illustrates the performance of a binary classifier system as its discrimination threshold is varied. It is created by plotting the fraction of true positives out of the positives (TPR = true positive rate) vs. the fraction of false positives out of the negatives (FPR = false positive rate), at various threshold settings. TPR is also known as sensitivity, and FPR is one minus the specificity or true negative rate.\n",
    "        \n",
    "- Multi-class classification (or binary):\n",
    "    - [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix): Compute confusion matrix to evaluate the accuracy of a classification.\n",
    "    ![IMG_Confusion_Matrix](https://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_0011.png)\n",
    "    - [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score): Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
    "\n",
    "- Multi-label classification (or binary or multi-class):\n",
    "    - [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score): Accuracy classification score.\n",
    "        - It is the ratio of number of correct predictions to the total number of input samples.\n",
    "        - **It works well only if there are equal number of samples belonging to each class.**\n",
    "    - [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report): Build a text report showing the main classification metrics.\n",
    "    - [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score): Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "        - The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal: `F1 = 2 * (precision * recall) / (precision + recall)`\n",
    "    - [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "    - [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which metric should be used then?\n",
    "##### Bear in mind that it's a clear case of imbalanced data\n",
    "\n",
    "Nomenclature:\n",
    "- Delayed = Positive\n",
    "- On-time = Negative \n",
    "\n",
    "Considering this:\n",
    "- False positive (Type I error) → Wrongly classifying an On-time flight as a Delayed flight → Not significantly relevant\n",
    "- **False negative (Type II error) → Wrongly classifying a Delayed flight as an On-time flight → Highly relevant**\n",
    "\n",
    "**F-beta** score (\\$ F_\\beta \\$):\n",
    "![F-beta score](https://wikimedia.org/api/rest_v1/media/math/render/svg/136f45612c08805f4254f63d2f2524bc25075fff)\n",
    "\n",
    "Two commonly used values for β are:\n",
    "- **2 : weighs recall higher than precision**\n",
    "- 0.5 : weighs recall lower than precision.\n",
    "\n",
    "\n",
    "<em>Probably most people in the industry would accept that an **OTP of 80%* or above is pretty good***. That’s 4 in 5 flights arriving within 15 minutes of their scheduled arrival time. The very best airlines and airports succeed in punctuality closer to 90% - but they remain the exception rather than the rule.</em>  \n",
    "(Source: [OAG](https://www.oag.com/on-time-performance-airlines-airports))\n",
    "\n",
    "The actual data from the 7268232 records comprising the OTP dataset accurately confirm this hypothesis:\n",
    "```\n",
    "Delays: 5878979 (80.89%)\n",
    "On-time: 1389253 (19.11%)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some rare cases, the calculation of Precision or Recall can cause a division by 0. Regarding the precision, this can happen if there are no results inside the answer of an annotator and, thus, the true as well as the false positives are 0. For these special cases, we have defined that **if the true positives, false positives and false negatives are all 0, the precision, recall and F1-measure are 1**. This might occur in cases in which the gold standard contains a document without any annotations and the annotator (correctly) returns no annotations. **If true positives are 0 and one of the two other counters is larger than 0, the precision, recall and F1-measure are 0.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A Gentle Introduction to Imbalanced Classification](https://machinelearningmastery.com/what-is-imbalanced-classification/)  \n",
    "**Imbalanced classifications** pose a challenge for predictive modeling as **most of the machine learning algorithms used for classification were designed around the assumption of an equal number of examples for each class**. This results in models that have poor predictive performance, specifically for the minority class. This is a problem because typically, the minority class is more important and therefore **the problem is more sensitive to classification errors for the minority class than the majority class**.\n",
    "\n",
    "[Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)  \n",
    "1. Try Changing Your Performance Metric:\n",
    "    - Confusion Matrix\n",
    "    - Precision: \n",
    "    - Recall: \n",
    "    - F1 Score\n",
    "    - Kappa\n",
    "    - ROC Curves\n",
    "2. Try Resampling Your Dataset:\n",
    "    - You can add copies of instances from the under-represented class called **over-sampling** (or more formally **sampling with replacement**) → when you don’t have a lot of data (tens of thousands of records or less)\n",
    "    - You can delete instances from the over-represented class, called **under-sampling** → when you have an a lot data (tens- or hundreds of thousands of instances or more)\n",
    "3. Try Different Algorithms:\n",
    "    - That being said, **decision trees often perform well on imbalanced datasets**. The splitting rules that look at the class variable used in the creation of the trees, can force both classes to be addressed.  \n",
    "    If in doubt, try a few popular decision tree algorithms like C4.5, C5.0, CART, and Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Guide to Classification on Imbalanced Datasets](https://towardsdatascience.com/guide-to-classification-on-imbalanced-datasets-d6653aa5fa23)  \n",
    "There are two main types of techniques to handle imbalanced datasets:\n",
    "- ### Sampling methods:\n",
    "    - #### Oversampling\n",
    "        - How do we generate these samples? The most common way is to generate points that are close in dataspace proximity to existing samples or are ‘between’ two samples, as illustrated below\n",
    "        - There are some downsides to adding false data points:\n",
    "            - **Overfitting** risk\n",
    "            - In addition, adding these values randomly can also contribute **additional noise to our model**\n",
    "        - Techniques:\n",
    "            - **SMOTE** (Synthetic minority oversampling technique) → SMOTE generates new samples in between existing data points based on their local density and their borders with the other class. Algorithm:\n",
    "                - Find its k-nearest minority neighbours\n",
    "                – Randomly select j of these neighbours\n",
    "                – Randomly generate synthetic samples along the lines joining the minority sample and its j selected neighbours (j depends on the amount of oversampling desired)\n",
    "    - #### Undersampling\n",
    "        - Is undersampling a good idea? Undersampling is recommended by many statistical researchers but is **only good if enough data points are available on the undersampled class**\n",
    "        - Is undersampling a good idea? Undersampling is recommended by many statistical researchers but is only good if enough data points are available on the undersampled class\n",
    "- ### Cost-sensitive methods\n",
    "    - #### Upweighting\n",
    "    Upweighting is analogous to over-sampling and works by increasing the weight of one of the classes keeping the weight of the other class at one\n",
    "    - #### Down-weighting\n",
    "    Down-weighting is analogous to under-sampling and works by decreasing the weight of one of the classes keeping the weight of the other class at one\n",
    "\n",
    "```python\n",
    "# Example of how to implement cost-sensitive learning:\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "model.fit(X_train, y_train, class_weight=class_weights)\n",
    "```\n",
    "\n",
    "- Benefits of cost-sensitive learning:\n",
    "    - It is much simpler to implement\n",
    "    - Easier to communicate to individuals\n",
    "\n",
    "### Assessment Metrics\n",
    "- #### F1-score\n",
    "    - What does a high F1 score mean? It suggests that both the precision and recall have high values — this is good and is what you would hope to see upon generating a well-functioning classification model on an imbalanced dataset. A low value indicates that either precision or recall is low, and maybe a call for concern\n",
    "    - Good F1 scores are generally lower than good accuracies (in many situations, an **F1 score of 0.5 would be considered pretty good**)\n",
    "\n",
    "- #### Receiver Operating Characteristic (ROC) Curve\n",
    "   - Depending on your application, you may be very averse to false positives as they may be very costly (e.g. launches of nuclear missiles) and thus **would like a classifier that has a very low false-positive rate**.\n",
    "\n",
    "- #### Area Under Curve (AUC)\n",
    "   - If a particular classifier has an ROC of 0.6 and another has an ROC of 0.8, the latter is clearly a better classifier. The AUC has the benefit that it is independent of the decision criteria — the classification threshold — and thus makes it easier to compare these classifiers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
